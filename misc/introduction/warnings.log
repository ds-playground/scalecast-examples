WARNING:root:lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
WARNING:root:lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
WARNING:root:`base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.
WARNING:root:lbfgs failed to converge (status=2):
ABNORMAL_TERMINATION_IN_LNSRCH.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
WARNING:root:lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
WARNING:root:`base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.
WARNING:root:lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
WARNING:root:lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
WARNING:root:lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
WARNING:root:lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
WARNING:root:`base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.
WARNING:root:lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
WARNING:root:lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
WARNING:root:lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
WARNING:root:`base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.
WARNING:root:lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
WARNING:root:lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
WARNING:root:Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.
WARNING:root:Non-invertible starting MA parameters found. Using zeros as starting parameters.
WARNING:root:Too few observations to estimate starting parameters for seasonal ARMA. All parameters except for variances will be set to zeros.
WARNING:root:Maximum Likelihood optimization failed to converge. Check mle_retvals
WARNING:root:Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.
WARNING:root:Non-invertible starting MA parameters found. Using zeros as starting parameters.
WARNING:root:Too few observations to estimate starting parameters for seasonal ARMA. All parameters except for variances will be set to zeros.
WARNING:root:Maximum Likelihood optimization failed to converge. Check mle_retvals
INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.
INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.
DEBUG:cmdstanpy:input tempfile: /var/folders/fy/sqs6tqlj7930n5fpnhhjqq3w0000gn/T/tmpbjd1y85d/el7o9gvx.json
DEBUG:cmdstanpy:input tempfile: /var/folders/fy/sqs6tqlj7930n5fpnhhjqq3w0000gn/T/tmpbjd1y85d/u40brzui.json
DEBUG:cmdstanpy:idx 0
DEBUG:cmdstanpy:running CmdStan, num_threads: None
DEBUG:cmdstanpy:CmdStan args: ['/Users/uger7/opt/anaconda3/lib/python3.9/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=60488', 'data', 'file=/var/folders/fy/sqs6tqlj7930n5fpnhhjqq3w0000gn/T/tmpbjd1y85d/el7o9gvx.json', 'init=/var/folders/fy/sqs6tqlj7930n5fpnhhjqq3w0000gn/T/tmpbjd1y85d/u40brzui.json', 'output', 'file=/var/folders/fy/sqs6tqlj7930n5fpnhhjqq3w0000gn/T/tmpbjd1y85d/prophet_model0s39l75o/prophet_model-20230222221627.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']
INFO:cmdstanpy:Chain [1] start processing
INFO:cmdstanpy:Chain [1] done processing
INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.
INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.
DEBUG:cmdstanpy:input tempfile: /var/folders/fy/sqs6tqlj7930n5fpnhhjqq3w0000gn/T/tmpbjd1y85d/441hysje.json
DEBUG:cmdstanpy:input tempfile: /var/folders/fy/sqs6tqlj7930n5fpnhhjqq3w0000gn/T/tmpbjd1y85d/xs8eynyo.json
DEBUG:cmdstanpy:idx 0
DEBUG:cmdstanpy:running CmdStan, num_threads: None
DEBUG:cmdstanpy:CmdStan args: ['/Users/uger7/opt/anaconda3/lib/python3.9/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=91340', 'data', 'file=/var/folders/fy/sqs6tqlj7930n5fpnhhjqq3w0000gn/T/tmpbjd1y85d/441hysje.json', 'init=/var/folders/fy/sqs6tqlj7930n5fpnhhjqq3w0000gn/T/tmpbjd1y85d/xs8eynyo.json', 'output', 'file=/var/folders/fy/sqs6tqlj7930n5fpnhhjqq3w0000gn/T/tmpbjd1y85d/prophet_modeldua4oq27/prophet_model-20230222221627.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']
INFO:cmdstanpy:Chain [1] start processing
INFO:cmdstanpy:Chain [1] done processing
WARNING:root:`base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.
WARNING:root:`base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.
WARNING:root:`base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.
WARNING:root:`base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of -0.5 cannot be evaluated. error: 0.0 cannot be raised to a negative power
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:Lambda value of 0 cannot be evaluated. error: Input X contains NaN.
ElasticNet does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of 0.5 cannot be evaluated. error: Input contains NaN.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.812e+01, tolerance: 6.145e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.902e+01, tolerance: 6.145e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.837e+01, tolerance: 6.145e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.938e+01, tolerance: 6.145e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.853e+01, tolerance: 6.145e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.960e+01, tolerance: 6.145e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.865e+01, tolerance: 6.145e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.976e+01, tolerance: 6.145e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.875e+01, tolerance: 6.145e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.988e+01, tolerance: 6.145e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.883e+01, tolerance: 6.145e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.997e+01, tolerance: 6.145e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.891e+01, tolerance: 6.145e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.004e+01, tolerance: 6.145e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.897e+01, tolerance: 6.145e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.010e+01, tolerance: 6.145e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.903e+01, tolerance: 6.145e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.015e+01, tolerance: 6.145e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.908e+01, tolerance: 6.145e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.020e+01, tolerance: 6.145e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.913e+01, tolerance: 6.145e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.023e+01, tolerance: 6.145e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.918e+01, tolerance: 6.145e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.027e+01, tolerance: 6.145e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.922e+01, tolerance: 6.145e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.029e+01, tolerance: 6.145e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.926e+01, tolerance: 6.145e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.032e+01, tolerance: 6.145e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.930e+01, tolerance: 6.145e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.034e+01, tolerance: 6.145e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.933e+01, tolerance: 6.145e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.036e+01, tolerance: 6.145e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.937e+01, tolerance: 6.145e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.038e+01, tolerance: 6.145e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.940e+01, tolerance: 6.145e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.039e+01, tolerance: 6.145e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.943e+01, tolerance: 6.145e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.041e+01, tolerance: 6.145e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.946e+01, tolerance: 6.145e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.042e+01, tolerance: 6.145e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.667e+01, tolerance: 4.586e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.809e+01, tolerance: 4.586e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.699e+01, tolerance: 4.586e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.897e+01, tolerance: 4.586e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.723e+01, tolerance: 4.586e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.958e+01, tolerance: 4.586e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.744e+01, tolerance: 4.586e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.002e+01, tolerance: 4.586e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.762e+01, tolerance: 4.586e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.036e+01, tolerance: 4.586e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.778e+01, tolerance: 4.586e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.063e+01, tolerance: 4.586e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.794e+01, tolerance: 4.586e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.084e+01, tolerance: 4.586e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.808e+01, tolerance: 4.586e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.102e+01, tolerance: 4.586e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.822e+01, tolerance: 4.586e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.117e+01, tolerance: 4.586e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.834e+01, tolerance: 4.586e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.130e+01, tolerance: 4.586e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.846e+01, tolerance: 4.586e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.141e+01, tolerance: 4.586e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.858e+01, tolerance: 4.586e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.151e+01, tolerance: 4.586e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.869e+01, tolerance: 4.586e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.160e+01, tolerance: 4.586e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+01, tolerance: 4.586e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.167e+01, tolerance: 4.586e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.888e+01, tolerance: 4.586e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.174e+01, tolerance: 4.586e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.898e+01, tolerance: 4.586e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.180e+01, tolerance: 4.586e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.907e+01, tolerance: 4.586e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.186e+01, tolerance: 4.586e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.915e+01, tolerance: 4.586e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.190e+01, tolerance: 4.586e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.923e+01, tolerance: 4.586e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.195e+01, tolerance: 4.586e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.931e+01, tolerance: 4.586e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.199e+01, tolerance: 4.586e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.703e+00, tolerance: 2.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.093e+01, tolerance: 2.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.020e+01, tolerance: 2.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.104e+01, tolerance: 2.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.043e+01, tolerance: 2.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.108e+01, tolerance: 2.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.056e+01, tolerance: 2.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.110e+01, tolerance: 2.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.065e+01, tolerance: 2.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.112e+01, tolerance: 2.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.072e+01, tolerance: 2.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.113e+01, tolerance: 2.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.076e+01, tolerance: 2.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.114e+01, tolerance: 2.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.080e+01, tolerance: 2.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.114e+01, tolerance: 2.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.083e+01, tolerance: 2.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.115e+01, tolerance: 2.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.086e+01, tolerance: 2.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.115e+01, tolerance: 2.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.088e+01, tolerance: 2.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.115e+01, tolerance: 2.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.090e+01, tolerance: 2.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.116e+01, tolerance: 2.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.092e+01, tolerance: 2.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.116e+01, tolerance: 2.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.093e+01, tolerance: 2.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.116e+01, tolerance: 2.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.094e+01, tolerance: 2.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.116e+01, tolerance: 2.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.096e+01, tolerance: 2.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.116e+01, tolerance: 2.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.097e+01, tolerance: 2.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.117e+01, tolerance: 2.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.098e+01, tolerance: 2.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.117e+01, tolerance: 2.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.098e+01, tolerance: 2.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.117e+01, tolerance: 2.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.099e+01, tolerance: 2.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.117e+01, tolerance: 2.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 70}. error: Expected n_neighbors <= n_samples,  but n_samples = 69, n_neighbors = 70
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 72}. error: Expected n_neighbors <= n_samples,  but n_samples = 69, n_neighbors = 72
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 74}. error: Expected n_neighbors <= n_samples,  but n_samples = 69, n_neighbors = 74
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 76}. error: Expected n_neighbors <= n_samples,  but n_samples = 69, n_neighbors = 76
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 78}. error: Expected n_neighbors <= n_samples,  but n_samples = 69, n_neighbors = 78
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 80}. error: Expected n_neighbors <= n_samples,  but n_samples = 69, n_neighbors = 80
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 82}. error: Expected n_neighbors <= n_samples,  but n_samples = 69, n_neighbors = 82
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 84}. error: Expected n_neighbors <= n_samples,  but n_samples = 69, n_neighbors = 84
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 86}. error: Expected n_neighbors <= n_samples,  but n_samples = 69, n_neighbors = 86
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 88}. error: Expected n_neighbors <= n_samples,  but n_samples = 69, n_neighbors = 88
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 90}. error: Expected n_neighbors <= n_samples,  but n_samples = 69, n_neighbors = 90
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 92}. error: Expected n_neighbors <= n_samples,  but n_samples = 69, n_neighbors = 92
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 94}. error: Expected n_neighbors <= n_samples,  but n_samples = 69, n_neighbors = 94
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 96}. error: Expected n_neighbors <= n_samples,  but n_samples = 69, n_neighbors = 96
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 98}. error: Expected n_neighbors <= n_samples,  but n_samples = 69, n_neighbors = 98
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: Expected n_neighbors <= n_samples,  but n_samples = 69, n_neighbors = 100
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 47}. error: Expected n_neighbors <= n_samples,  but n_samples = 46, n_neighbors = 47
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 49}. error: Expected n_neighbors <= n_samples,  but n_samples = 46, n_neighbors = 49
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 51}. error: Expected n_neighbors <= n_samples,  but n_samples = 46, n_neighbors = 51
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 53}. error: Expected n_neighbors <= n_samples,  but n_samples = 46, n_neighbors = 53
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 55}. error: Expected n_neighbors <= n_samples,  but n_samples = 46, n_neighbors = 55
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 57}. error: Expected n_neighbors <= n_samples,  but n_samples = 46, n_neighbors = 57
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 59}. error: Expected n_neighbors <= n_samples,  but n_samples = 46, n_neighbors = 59
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 61}. error: Expected n_neighbors <= n_samples,  but n_samples = 46, n_neighbors = 61
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 63}. error: Expected n_neighbors <= n_samples,  but n_samples = 46, n_neighbors = 63
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 65}. error: Expected n_neighbors <= n_samples,  but n_samples = 46, n_neighbors = 65
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 67}. error: Expected n_neighbors <= n_samples,  but n_samples = 46, n_neighbors = 67
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 69}. error: Expected n_neighbors <= n_samples,  but n_samples = 46, n_neighbors = 69
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 71}. error: Expected n_neighbors <= n_samples,  but n_samples = 46, n_neighbors = 71
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 73}. error: Expected n_neighbors <= n_samples,  but n_samples = 46, n_neighbors = 73
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 75}. error: Expected n_neighbors <= n_samples,  but n_samples = 46, n_neighbors = 75
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 77}. error: Expected n_neighbors <= n_samples,  but n_samples = 46, n_neighbors = 77
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 79}. error: Expected n_neighbors <= n_samples,  but n_samples = 46, n_neighbors = 79
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 81}. error: Expected n_neighbors <= n_samples,  but n_samples = 46, n_neighbors = 81
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 83}. error: Expected n_neighbors <= n_samples,  but n_samples = 46, n_neighbors = 83
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 85}. error: Expected n_neighbors <= n_samples,  but n_samples = 46, n_neighbors = 85
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 87}. error: Expected n_neighbors <= n_samples,  but n_samples = 46, n_neighbors = 87
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 89}. error: Expected n_neighbors <= n_samples,  but n_samples = 46, n_neighbors = 89
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 91}. error: Expected n_neighbors <= n_samples,  but n_samples = 46, n_neighbors = 91
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 93}. error: Expected n_neighbors <= n_samples,  but n_samples = 46, n_neighbors = 93
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 95}. error: Expected n_neighbors <= n_samples,  but n_samples = 46, n_neighbors = 95
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 97}. error: Expected n_neighbors <= n_samples,  but n_samples = 46, n_neighbors = 97
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: Expected n_neighbors <= n_samples,  but n_samples = 46, n_neighbors = 99
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 24}. error: Expected n_neighbors <= n_samples,  but n_samples = 23, n_neighbors = 24
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 26}. error: Expected n_neighbors <= n_samples,  but n_samples = 23, n_neighbors = 26
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 28}. error: Expected n_neighbors <= n_samples,  but n_samples = 23, n_neighbors = 28
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 30}. error: Expected n_neighbors <= n_samples,  but n_samples = 23, n_neighbors = 30
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 32}. error: Expected n_neighbors <= n_samples,  but n_samples = 23, n_neighbors = 32
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 34}. error: Expected n_neighbors <= n_samples,  but n_samples = 23, n_neighbors = 34
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 36}. error: Expected n_neighbors <= n_samples,  but n_samples = 23, n_neighbors = 36
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 38}. error: Expected n_neighbors <= n_samples,  but n_samples = 23, n_neighbors = 38
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 40}. error: Expected n_neighbors <= n_samples,  but n_samples = 23, n_neighbors = 40
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 42}. error: Expected n_neighbors <= n_samples,  but n_samples = 23, n_neighbors = 42
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 44}. error: Expected n_neighbors <= n_samples,  but n_samples = 23, n_neighbors = 44
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 46}. error: Expected n_neighbors <= n_samples,  but n_samples = 23, n_neighbors = 46
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 48}. error: Expected n_neighbors <= n_samples,  but n_samples = 23, n_neighbors = 48
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 50}. error: Expected n_neighbors <= n_samples,  but n_samples = 23, n_neighbors = 50
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 52}. error: Expected n_neighbors <= n_samples,  but n_samples = 23, n_neighbors = 52
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 54}. error: Expected n_neighbors <= n_samples,  but n_samples = 23, n_neighbors = 54
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 56}. error: Expected n_neighbors <= n_samples,  but n_samples = 23, n_neighbors = 56
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 58}. error: Expected n_neighbors <= n_samples,  but n_samples = 23, n_neighbors = 58
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 60}. error: Expected n_neighbors <= n_samples,  but n_samples = 23, n_neighbors = 60
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 62}. error: Expected n_neighbors <= n_samples,  but n_samples = 23, n_neighbors = 62
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 64}. error: Expected n_neighbors <= n_samples,  but n_samples = 23, n_neighbors = 64
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 66}. error: Expected n_neighbors <= n_samples,  but n_samples = 23, n_neighbors = 66
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 68}. error: Expected n_neighbors <= n_samples,  but n_samples = 23, n_neighbors = 68
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 70}. error: Expected n_neighbors <= n_samples,  but n_samples = 23, n_neighbors = 70
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 72}. error: Expected n_neighbors <= n_samples,  but n_samples = 23, n_neighbors = 72
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 74}. error: Expected n_neighbors <= n_samples,  but n_samples = 23, n_neighbors = 74
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 76}. error: Expected n_neighbors <= n_samples,  but n_samples = 23, n_neighbors = 76
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 78}. error: Expected n_neighbors <= n_samples,  but n_samples = 23, n_neighbors = 78
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 80}. error: Expected n_neighbors <= n_samples,  but n_samples = 23, n_neighbors = 80
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 82}. error: Expected n_neighbors <= n_samples,  but n_samples = 23, n_neighbors = 82
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 84}. error: Expected n_neighbors <= n_samples,  but n_samples = 23, n_neighbors = 84
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 86}. error: Expected n_neighbors <= n_samples,  but n_samples = 23, n_neighbors = 86
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 88}. error: Expected n_neighbors <= n_samples,  but n_samples = 23, n_neighbors = 88
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 90}. error: Expected n_neighbors <= n_samples,  but n_samples = 23, n_neighbors = 90
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 92}. error: Expected n_neighbors <= n_samples,  but n_samples = 23, n_neighbors = 92
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 94}. error: Expected n_neighbors <= n_samples,  but n_samples = 23, n_neighbors = 94
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 96}. error: Expected n_neighbors <= n_samples,  but n_samples = 23, n_neighbors = 96
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 98}. error: Expected n_neighbors <= n_samples,  but n_samples = 23, n_neighbors = 98
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: Expected n_neighbors <= n_samples,  but n_samples = 23, n_neighbors = 100
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.519e+01, tolerance: 5.561e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.713e+01, tolerance: 5.561e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.536e+01, tolerance: 5.561e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.742e+01, tolerance: 5.561e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.550e+01, tolerance: 5.561e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.754e+01, tolerance: 5.561e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.563e+01, tolerance: 5.561e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.760e+01, tolerance: 5.561e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.574e+01, tolerance: 5.561e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.764e+01, tolerance: 5.561e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.585e+01, tolerance: 5.561e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.766e+01, tolerance: 5.561e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+01, tolerance: 5.561e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.768e+01, tolerance: 5.561e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.602e+01, tolerance: 5.561e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.770e+01, tolerance: 5.561e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.610e+01, tolerance: 5.561e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+01, tolerance: 5.561e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.617e+01, tolerance: 5.561e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.772e+01, tolerance: 5.561e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.623e+01, tolerance: 5.561e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.773e+01, tolerance: 5.561e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.629e+01, tolerance: 5.561e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.773e+01, tolerance: 5.561e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.634e+01, tolerance: 5.561e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.774e+01, tolerance: 5.561e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.640e+01, tolerance: 5.561e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.774e+01, tolerance: 5.561e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.644e+01, tolerance: 5.561e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.775e+01, tolerance: 5.561e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.649e+01, tolerance: 5.561e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.775e+01, tolerance: 5.561e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.653e+01, tolerance: 5.561e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.775e+01, tolerance: 5.561e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.657e+01, tolerance: 5.561e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.776e+01, tolerance: 5.561e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.660e+01, tolerance: 5.561e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.776e+01, tolerance: 5.561e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.664e+01, tolerance: 5.561e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.776e+01, tolerance: 5.561e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.234e+01, tolerance: 2.768e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.360e+01, tolerance: 2.768e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.249e+01, tolerance: 2.768e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.371e+01, tolerance: 2.768e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.261e+01, tolerance: 2.768e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.375e+01, tolerance: 2.768e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.271e+01, tolerance: 2.768e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.377e+01, tolerance: 2.768e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.279e+01, tolerance: 2.768e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.379e+01, tolerance: 2.768e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.286e+01, tolerance: 2.768e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.380e+01, tolerance: 2.768e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.293e+01, tolerance: 2.768e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.380e+01, tolerance: 2.768e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.298e+01, tolerance: 2.768e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.381e+01, tolerance: 2.768e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.303e+01, tolerance: 2.768e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.381e+01, tolerance: 2.768e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.307e+01, tolerance: 2.768e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.381e+01, tolerance: 2.768e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.311e+01, tolerance: 2.768e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.382e+01, tolerance: 2.768e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.315e+01, tolerance: 2.768e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.382e+01, tolerance: 2.768e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.318e+01, tolerance: 2.768e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.382e+01, tolerance: 2.768e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.321e+01, tolerance: 2.768e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.382e+01, tolerance: 2.768e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.323e+01, tolerance: 2.768e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.382e+01, tolerance: 2.768e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.326e+01, tolerance: 2.768e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.382e+01, tolerance: 2.768e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.328e+01, tolerance: 2.768e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.382e+01, tolerance: 2.768e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.330e+01, tolerance: 2.768e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.383e+01, tolerance: 2.768e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.332e+01, tolerance: 2.768e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.383e+01, tolerance: 2.768e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.334e+01, tolerance: 2.768e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.383e+01, tolerance: 2.768e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.548e+00, tolerance: 2.148e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.980e+00, tolerance: 2.148e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.207e+00, tolerance: 2.148e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.032e+01, tolerance: 2.148e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.660e+00, tolerance: 2.148e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.045e+01, tolerance: 2.148e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.996e+00, tolerance: 2.148e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.052e+01, tolerance: 2.148e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.260e+00, tolerance: 2.148e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.056e+01, tolerance: 2.148e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.473e+00, tolerance: 2.148e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.059e+01, tolerance: 2.148e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.649e+00, tolerance: 2.148e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.061e+01, tolerance: 2.148e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.799e+00, tolerance: 2.148e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.063e+01, tolerance: 2.148e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.927e+00, tolerance: 2.148e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.064e+01, tolerance: 2.148e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.039e+00, tolerance: 2.148e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.065e+01, tolerance: 2.148e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.137e+00, tolerance: 2.148e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.066e+01, tolerance: 2.148e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.224e+00, tolerance: 2.148e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.066e+01, tolerance: 2.148e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.302e+00, tolerance: 2.148e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.067e+01, tolerance: 2.148e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.372e+00, tolerance: 2.148e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.067e+01, tolerance: 2.148e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.435e+00, tolerance: 2.148e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.068e+01, tolerance: 2.148e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.492e+00, tolerance: 2.148e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.068e+01, tolerance: 2.148e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.545e+00, tolerance: 2.148e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 2.148e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.593e+00, tolerance: 2.148e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 2.148e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.637e+00, tolerance: 2.148e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 2.148e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.678e+00, tolerance: 2.148e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 2.148e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 57}. error: Expected n_neighbors <= n_samples,  but n_samples = 56, n_neighbors = 57
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 59}. error: Expected n_neighbors <= n_samples,  but n_samples = 56, n_neighbors = 59
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 61}. error: Expected n_neighbors <= n_samples,  but n_samples = 56, n_neighbors = 61
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 63}. error: Expected n_neighbors <= n_samples,  but n_samples = 56, n_neighbors = 63
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 65}. error: Expected n_neighbors <= n_samples,  but n_samples = 56, n_neighbors = 65
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 67}. error: Expected n_neighbors <= n_samples,  but n_samples = 56, n_neighbors = 67
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 69}. error: Expected n_neighbors <= n_samples,  but n_samples = 56, n_neighbors = 69
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 71}. error: Expected n_neighbors <= n_samples,  but n_samples = 56, n_neighbors = 71
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 73}. error: Expected n_neighbors <= n_samples,  but n_samples = 56, n_neighbors = 73
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 75}. error: Expected n_neighbors <= n_samples,  but n_samples = 56, n_neighbors = 75
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 77}. error: Expected n_neighbors <= n_samples,  but n_samples = 56, n_neighbors = 77
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 79}. error: Expected n_neighbors <= n_samples,  but n_samples = 56, n_neighbors = 79
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 81}. error: Expected n_neighbors <= n_samples,  but n_samples = 56, n_neighbors = 81
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 83}. error: Expected n_neighbors <= n_samples,  but n_samples = 56, n_neighbors = 83
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 85}. error: Expected n_neighbors <= n_samples,  but n_samples = 56, n_neighbors = 85
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 87}. error: Expected n_neighbors <= n_samples,  but n_samples = 56, n_neighbors = 87
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 89}. error: Expected n_neighbors <= n_samples,  but n_samples = 56, n_neighbors = 89
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 91}. error: Expected n_neighbors <= n_samples,  but n_samples = 56, n_neighbors = 91
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 93}. error: Expected n_neighbors <= n_samples,  but n_samples = 56, n_neighbors = 93
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 95}. error: Expected n_neighbors <= n_samples,  but n_samples = 56, n_neighbors = 95
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 97}. error: Expected n_neighbors <= n_samples,  but n_samples = 56, n_neighbors = 97
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: Expected n_neighbors <= n_samples,  but n_samples = 56, n_neighbors = 99
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 39}. error: Expected n_neighbors <= n_samples,  but n_samples = 38, n_neighbors = 39
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 41}. error: Expected n_neighbors <= n_samples,  but n_samples = 38, n_neighbors = 41
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 43}. error: Expected n_neighbors <= n_samples,  but n_samples = 38, n_neighbors = 43
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 45}. error: Expected n_neighbors <= n_samples,  but n_samples = 38, n_neighbors = 45
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 47}. error: Expected n_neighbors <= n_samples,  but n_samples = 38, n_neighbors = 47
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 49}. error: Expected n_neighbors <= n_samples,  but n_samples = 38, n_neighbors = 49
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 51}. error: Expected n_neighbors <= n_samples,  but n_samples = 38, n_neighbors = 51
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 53}. error: Expected n_neighbors <= n_samples,  but n_samples = 38, n_neighbors = 53
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 55}. error: Expected n_neighbors <= n_samples,  but n_samples = 38, n_neighbors = 55
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 57}. error: Expected n_neighbors <= n_samples,  but n_samples = 38, n_neighbors = 57
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 59}. error: Expected n_neighbors <= n_samples,  but n_samples = 38, n_neighbors = 59
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 61}. error: Expected n_neighbors <= n_samples,  but n_samples = 38, n_neighbors = 61
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 63}. error: Expected n_neighbors <= n_samples,  but n_samples = 38, n_neighbors = 63
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 65}. error: Expected n_neighbors <= n_samples,  but n_samples = 38, n_neighbors = 65
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 67}. error: Expected n_neighbors <= n_samples,  but n_samples = 38, n_neighbors = 67
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 69}. error: Expected n_neighbors <= n_samples,  but n_samples = 38, n_neighbors = 69
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 71}. error: Expected n_neighbors <= n_samples,  but n_samples = 38, n_neighbors = 71
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 73}. error: Expected n_neighbors <= n_samples,  but n_samples = 38, n_neighbors = 73
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 75}. error: Expected n_neighbors <= n_samples,  but n_samples = 38, n_neighbors = 75
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 77}. error: Expected n_neighbors <= n_samples,  but n_samples = 38, n_neighbors = 77
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 79}. error: Expected n_neighbors <= n_samples,  but n_samples = 38, n_neighbors = 79
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 81}. error: Expected n_neighbors <= n_samples,  but n_samples = 38, n_neighbors = 81
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 83}. error: Expected n_neighbors <= n_samples,  but n_samples = 38, n_neighbors = 83
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 85}. error: Expected n_neighbors <= n_samples,  but n_samples = 38, n_neighbors = 85
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 87}. error: Expected n_neighbors <= n_samples,  but n_samples = 38, n_neighbors = 87
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 89}. error: Expected n_neighbors <= n_samples,  but n_samples = 38, n_neighbors = 89
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 91}. error: Expected n_neighbors <= n_samples,  but n_samples = 38, n_neighbors = 91
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 93}. error: Expected n_neighbors <= n_samples,  but n_samples = 38, n_neighbors = 93
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 95}. error: Expected n_neighbors <= n_samples,  but n_samples = 38, n_neighbors = 95
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 97}. error: Expected n_neighbors <= n_samples,  but n_samples = 38, n_neighbors = 97
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: Expected n_neighbors <= n_samples,  but n_samples = 38, n_neighbors = 99
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 21}. error: Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 21
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 23}. error: Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 23
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 25}. error: Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 25
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 27}. error: Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 27
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 29}. error: Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 29
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 31}. error: Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 31
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 33}. error: Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 33
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 35}. error: Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 35
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 37}. error: Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 37
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 39}. error: Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 39
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 41}. error: Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 41
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 43}. error: Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 43
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 45}. error: Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 45
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 47}. error: Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 47
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 49}. error: Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 49
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 51}. error: Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 51
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 53}. error: Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 53
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 55}. error: Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 55
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 57}. error: Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 57
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 59}. error: Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 59
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 61}. error: Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 61
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 63}. error: Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 63
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 65}. error: Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 65
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 67}. error: Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 67
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 69}. error: Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 69
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 71}. error: Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 71
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 73}. error: Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 73
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 75}. error: Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 75
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 77}. error: Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 77
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 79}. error: Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 79
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 81}. error: Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 81
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 83}. error: Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 83
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 85}. error: Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 85
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 87}. error: Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 87
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 89}. error: Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 89
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 91}. error: Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 91
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 93}. error: Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 93
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 95}. error: Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 95
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 97}. error: Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 97
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 99
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.522e+01, tolerance: 3.080e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.529e+01, tolerance: 3.080e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.524e+01, tolerance: 3.080e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.533e+01, tolerance: 3.080e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.525e+01, tolerance: 3.080e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.535e+01, tolerance: 3.080e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.526e+01, tolerance: 3.080e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.536e+01, tolerance: 3.080e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.527e+01, tolerance: 3.080e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.536e+01, tolerance: 3.080e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.528e+01, tolerance: 3.080e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.537e+01, tolerance: 3.080e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.529e+01, tolerance: 3.080e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.537e+01, tolerance: 3.080e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.529e+01, tolerance: 3.080e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.538e+01, tolerance: 3.080e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.530e+01, tolerance: 3.080e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.538e+01, tolerance: 3.080e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.530e+01, tolerance: 3.080e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.538e+01, tolerance: 3.080e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.531e+01, tolerance: 3.080e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.538e+01, tolerance: 3.080e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.531e+01, tolerance: 3.080e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.538e+01, tolerance: 3.080e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.532e+01, tolerance: 3.080e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.539e+01, tolerance: 3.080e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.532e+01, tolerance: 3.080e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.532e+01, tolerance: 3.080e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.539e+01, tolerance: 3.080e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.533e+01, tolerance: 3.080e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.539e+01, tolerance: 3.080e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.533e+01, tolerance: 3.080e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.539e+01, tolerance: 3.080e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.533e+01, tolerance: 3.080e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.539e+01, tolerance: 3.080e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.533e+01, tolerance: 3.080e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.539e+01, tolerance: 3.080e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.539e+01, tolerance: 3.080e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.303e+01, tolerance: 2.660e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.314e+01, tolerance: 2.660e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.306e+01, tolerance: 2.660e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.319e+01, tolerance: 2.660e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.308e+01, tolerance: 2.660e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.321e+01, tolerance: 2.660e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.309e+01, tolerance: 2.660e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.323e+01, tolerance: 2.660e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.311e+01, tolerance: 2.660e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.324e+01, tolerance: 2.660e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.312e+01, tolerance: 2.660e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.325e+01, tolerance: 2.660e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.313e+01, tolerance: 2.660e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.326e+01, tolerance: 2.660e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.314e+01, tolerance: 2.660e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.326e+01, tolerance: 2.660e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.315e+01, tolerance: 2.660e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.326e+01, tolerance: 2.660e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.316e+01, tolerance: 2.660e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.327e+01, tolerance: 2.660e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.316e+01, tolerance: 2.660e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.327e+01, tolerance: 2.660e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.317e+01, tolerance: 2.660e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.327e+01, tolerance: 2.660e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.317e+01, tolerance: 2.660e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.327e+01, tolerance: 2.660e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.318e+01, tolerance: 2.660e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.328e+01, tolerance: 2.660e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.318e+01, tolerance: 2.660e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.328e+01, tolerance: 2.660e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.319e+01, tolerance: 2.660e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.328e+01, tolerance: 2.660e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.319e+01, tolerance: 2.660e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.328e+01, tolerance: 2.660e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.320e+01, tolerance: 2.660e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.328e+01, tolerance: 2.660e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.320e+01, tolerance: 2.660e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.328e+01, tolerance: 2.660e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.320e+01, tolerance: 2.660e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.328e+01, tolerance: 2.660e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.029e+01, tolerance: 2.071e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.032e+01, tolerance: 2.071e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.030e+01, tolerance: 2.071e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.033e+01, tolerance: 2.071e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.030e+01, tolerance: 2.071e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.034e+01, tolerance: 2.071e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.031e+01, tolerance: 2.071e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.034e+01, tolerance: 2.071e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.031e+01, tolerance: 2.071e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.034e+01, tolerance: 2.071e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.031e+01, tolerance: 2.071e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.035e+01, tolerance: 2.071e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.031e+01, tolerance: 2.071e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.035e+01, tolerance: 2.071e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.032e+01, tolerance: 2.071e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.035e+01, tolerance: 2.071e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.032e+01, tolerance: 2.071e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.035e+01, tolerance: 2.071e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.032e+01, tolerance: 2.071e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.035e+01, tolerance: 2.071e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.032e+01, tolerance: 2.071e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.035e+01, tolerance: 2.071e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.032e+01, tolerance: 2.071e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.035e+01, tolerance: 2.071e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.032e+01, tolerance: 2.071e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.035e+01, tolerance: 2.071e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.033e+01, tolerance: 2.071e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.035e+01, tolerance: 2.071e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.033e+01, tolerance: 2.071e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.035e+01, tolerance: 2.071e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.033e+01, tolerance: 2.071e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.035e+01, tolerance: 2.071e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.033e+01, tolerance: 2.071e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.035e+01, tolerance: 2.071e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.033e+01, tolerance: 2.071e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.035e+01, tolerance: 2.071e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.033e+01, tolerance: 2.071e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.035e+01, tolerance: 2.071e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.033e+01, tolerance: 2.071e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.035e+01, tolerance: 2.071e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 41}. error: Expected n_neighbors <= n_samples,  but n_samples = 40, n_neighbors = 41
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 43}. error: Expected n_neighbors <= n_samples,  but n_samples = 40, n_neighbors = 43
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 45}. error: Expected n_neighbors <= n_samples,  but n_samples = 40, n_neighbors = 45
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 47}. error: Expected n_neighbors <= n_samples,  but n_samples = 40, n_neighbors = 47
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 49}. error: Expected n_neighbors <= n_samples,  but n_samples = 40, n_neighbors = 49
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 51}. error: Expected n_neighbors <= n_samples,  but n_samples = 40, n_neighbors = 51
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 53}. error: Expected n_neighbors <= n_samples,  but n_samples = 40, n_neighbors = 53
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 55}. error: Expected n_neighbors <= n_samples,  but n_samples = 40, n_neighbors = 55
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 57}. error: Expected n_neighbors <= n_samples,  but n_samples = 40, n_neighbors = 57
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 59}. error: Expected n_neighbors <= n_samples,  but n_samples = 40, n_neighbors = 59
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 61}. error: Expected n_neighbors <= n_samples,  but n_samples = 40, n_neighbors = 61
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 63}. error: Expected n_neighbors <= n_samples,  but n_samples = 40, n_neighbors = 63
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 65}. error: Expected n_neighbors <= n_samples,  but n_samples = 40, n_neighbors = 65
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 67}. error: Expected n_neighbors <= n_samples,  but n_samples = 40, n_neighbors = 67
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 69}. error: Expected n_neighbors <= n_samples,  but n_samples = 40, n_neighbors = 69
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 71}. error: Expected n_neighbors <= n_samples,  but n_samples = 40, n_neighbors = 71
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 73}. error: Expected n_neighbors <= n_samples,  but n_samples = 40, n_neighbors = 73
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 75}. error: Expected n_neighbors <= n_samples,  but n_samples = 40, n_neighbors = 75
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 77}. error: Expected n_neighbors <= n_samples,  but n_samples = 40, n_neighbors = 77
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 79}. error: Expected n_neighbors <= n_samples,  but n_samples = 40, n_neighbors = 79
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 81}. error: Expected n_neighbors <= n_samples,  but n_samples = 40, n_neighbors = 81
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 83}. error: Expected n_neighbors <= n_samples,  but n_samples = 40, n_neighbors = 83
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 85}. error: Expected n_neighbors <= n_samples,  but n_samples = 40, n_neighbors = 85
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 87}. error: Expected n_neighbors <= n_samples,  but n_samples = 40, n_neighbors = 87
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 89}. error: Expected n_neighbors <= n_samples,  but n_samples = 40, n_neighbors = 89
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 91}. error: Expected n_neighbors <= n_samples,  but n_samples = 40, n_neighbors = 91
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 93}. error: Expected n_neighbors <= n_samples,  but n_samples = 40, n_neighbors = 93
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 95}. error: Expected n_neighbors <= n_samples,  but n_samples = 40, n_neighbors = 95
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 97}. error: Expected n_neighbors <= n_samples,  but n_samples = 40, n_neighbors = 97
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: Expected n_neighbors <= n_samples,  but n_samples = 40, n_neighbors = 99
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 28}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 28
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 30}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 30
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 32}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 32
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 34}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 34
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 36}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 36
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 38}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 38
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 40}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 40
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 42}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 42
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 44}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 44
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 46}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 46
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 48}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 48
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 50}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 50
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 52}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 52
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 54}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 54
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 56}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 56
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 58}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 58
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 60}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 60
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 62}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 62
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 64}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 64
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 66}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 66
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 68}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 68
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 70}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 70
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 72}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 72
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 74}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 74
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 76}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 76
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 78}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 78
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 80}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 80
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 82}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 82
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 84}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 84
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 86}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 86
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 88}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 88
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 90}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 90
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 92}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 92
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 94}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 94
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 96}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 96
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 98}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 98
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 100
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 15}. error: Expected n_neighbors <= n_samples,  but n_samples = 14, n_neighbors = 15
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 17}. error: Expected n_neighbors <= n_samples,  but n_samples = 14, n_neighbors = 17
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 19}. error: Expected n_neighbors <= n_samples,  but n_samples = 14, n_neighbors = 19
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 21}. error: Expected n_neighbors <= n_samples,  but n_samples = 14, n_neighbors = 21
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 23}. error: Expected n_neighbors <= n_samples,  but n_samples = 14, n_neighbors = 23
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 25}. error: Expected n_neighbors <= n_samples,  but n_samples = 14, n_neighbors = 25
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 27}. error: Expected n_neighbors <= n_samples,  but n_samples = 14, n_neighbors = 27
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 29}. error: Expected n_neighbors <= n_samples,  but n_samples = 14, n_neighbors = 29
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 31}. error: Expected n_neighbors <= n_samples,  but n_samples = 14, n_neighbors = 31
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 33}. error: Expected n_neighbors <= n_samples,  but n_samples = 14, n_neighbors = 33
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 35}. error: Expected n_neighbors <= n_samples,  but n_samples = 14, n_neighbors = 35
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 37}. error: Expected n_neighbors <= n_samples,  but n_samples = 14, n_neighbors = 37
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 39}. error: Expected n_neighbors <= n_samples,  but n_samples = 14, n_neighbors = 39
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 41}. error: Expected n_neighbors <= n_samples,  but n_samples = 14, n_neighbors = 41
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 43}. error: Expected n_neighbors <= n_samples,  but n_samples = 14, n_neighbors = 43
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 45}. error: Expected n_neighbors <= n_samples,  but n_samples = 14, n_neighbors = 45
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 47}. error: Expected n_neighbors <= n_samples,  but n_samples = 14, n_neighbors = 47
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 49}. error: Expected n_neighbors <= n_samples,  but n_samples = 14, n_neighbors = 49
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 51}. error: Expected n_neighbors <= n_samples,  but n_samples = 14, n_neighbors = 51
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 53}. error: Expected n_neighbors <= n_samples,  but n_samples = 14, n_neighbors = 53
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 55}. error: Expected n_neighbors <= n_samples,  but n_samples = 14, n_neighbors = 55
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 57}. error: Expected n_neighbors <= n_samples,  but n_samples = 14, n_neighbors = 57
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 59}. error: Expected n_neighbors <= n_samples,  but n_samples = 14, n_neighbors = 59
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 61}. error: Expected n_neighbors <= n_samples,  but n_samples = 14, n_neighbors = 61
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 63}. error: Expected n_neighbors <= n_samples,  but n_samples = 14, n_neighbors = 63
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 65}. error: Expected n_neighbors <= n_samples,  but n_samples = 14, n_neighbors = 65
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 67}. error: Expected n_neighbors <= n_samples,  but n_samples = 14, n_neighbors = 67
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 69}. error: Expected n_neighbors <= n_samples,  but n_samples = 14, n_neighbors = 69
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 71}. error: Expected n_neighbors <= n_samples,  but n_samples = 14, n_neighbors = 71
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 73}. error: Expected n_neighbors <= n_samples,  but n_samples = 14, n_neighbors = 73
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 75}. error: Expected n_neighbors <= n_samples,  but n_samples = 14, n_neighbors = 75
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 77}. error: Expected n_neighbors <= n_samples,  but n_samples = 14, n_neighbors = 77
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 79}. error: Expected n_neighbors <= n_samples,  but n_samples = 14, n_neighbors = 79
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 81}. error: Expected n_neighbors <= n_samples,  but n_samples = 14, n_neighbors = 81
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 83}. error: Expected n_neighbors <= n_samples,  but n_samples = 14, n_neighbors = 83
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 85}. error: Expected n_neighbors <= n_samples,  but n_samples = 14, n_neighbors = 85
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 87}. error: Expected n_neighbors <= n_samples,  but n_samples = 14, n_neighbors = 87
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 89}. error: Expected n_neighbors <= n_samples,  but n_samples = 14, n_neighbors = 89
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 91}. error: Expected n_neighbors <= n_samples,  but n_samples = 14, n_neighbors = 91
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 93}. error: Expected n_neighbors <= n_samples,  but n_samples = 14, n_neighbors = 93
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 95}. error: Expected n_neighbors <= n_samples,  but n_samples = 14, n_neighbors = 95
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 97}. error: Expected n_neighbors <= n_samples,  but n_samples = 14, n_neighbors = 97
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: Expected n_neighbors <= n_samples,  but n_samples = 14, n_neighbors = 99
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.221e+01, tolerance: 2.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.241e+01, tolerance: 2.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.225e+01, tolerance: 2.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.252e+01, tolerance: 2.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.229e+01, tolerance: 2.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.258e+01, tolerance: 2.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.232e+01, tolerance: 2.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.262e+01, tolerance: 2.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.235e+01, tolerance: 2.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.265e+01, tolerance: 2.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.238e+01, tolerance: 2.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.267e+01, tolerance: 2.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.240e+01, tolerance: 2.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.242e+01, tolerance: 2.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.269e+01, tolerance: 2.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.244e+01, tolerance: 2.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.270e+01, tolerance: 2.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.245e+01, tolerance: 2.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.271e+01, tolerance: 2.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.247e+01, tolerance: 2.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.272e+01, tolerance: 2.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.248e+01, tolerance: 2.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.272e+01, tolerance: 2.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.250e+01, tolerance: 2.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.251e+01, tolerance: 2.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.273e+01, tolerance: 2.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.252e+01, tolerance: 2.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.274e+01, tolerance: 2.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.253e+01, tolerance: 2.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.274e+01, tolerance: 2.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.254e+01, tolerance: 2.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.255e+01, tolerance: 2.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.275e+01, tolerance: 2.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.275e+01, tolerance: 2.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.256e+01, tolerance: 2.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.275e+01, tolerance: 2.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.050e+01, tolerance: 2.129e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.056e+01, tolerance: 2.129e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.051e+01, tolerance: 2.129e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.059e+01, tolerance: 2.129e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.053e+01, tolerance: 2.129e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.060e+01, tolerance: 2.129e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.053e+01, tolerance: 2.129e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.061e+01, tolerance: 2.129e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.054e+01, tolerance: 2.129e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.061e+01, tolerance: 2.129e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.055e+01, tolerance: 2.129e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.062e+01, tolerance: 2.129e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.056e+01, tolerance: 2.129e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.062e+01, tolerance: 2.129e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.056e+01, tolerance: 2.129e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.062e+01, tolerance: 2.129e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.057e+01, tolerance: 2.129e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.063e+01, tolerance: 2.129e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.057e+01, tolerance: 2.129e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.063e+01, tolerance: 2.129e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.057e+01, tolerance: 2.129e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.063e+01, tolerance: 2.129e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.058e+01, tolerance: 2.129e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.063e+01, tolerance: 2.129e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.058e+01, tolerance: 2.129e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.063e+01, tolerance: 2.129e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.058e+01, tolerance: 2.129e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.063e+01, tolerance: 2.129e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.058e+01, tolerance: 2.129e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.063e+01, tolerance: 2.129e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.059e+01, tolerance: 2.129e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.063e+01, tolerance: 2.129e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.059e+01, tolerance: 2.129e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.063e+01, tolerance: 2.129e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.059e+01, tolerance: 2.129e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.063e+01, tolerance: 2.129e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.059e+01, tolerance: 2.129e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.064e+01, tolerance: 2.129e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.059e+01, tolerance: 2.129e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.064e+01, tolerance: 2.129e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.025e+01, tolerance: 2.064e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.027e+01, tolerance: 2.064e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.025e+01, tolerance: 2.064e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.029e+01, tolerance: 2.064e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.026e+01, tolerance: 2.064e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.029e+01, tolerance: 2.064e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.026e+01, tolerance: 2.064e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.030e+01, tolerance: 2.064e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.026e+01, tolerance: 2.064e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.030e+01, tolerance: 2.064e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.027e+01, tolerance: 2.064e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.030e+01, tolerance: 2.064e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.027e+01, tolerance: 2.064e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.030e+01, tolerance: 2.064e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.027e+01, tolerance: 2.064e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.031e+01, tolerance: 2.064e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.027e+01, tolerance: 2.064e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.031e+01, tolerance: 2.064e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.028e+01, tolerance: 2.064e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.031e+01, tolerance: 2.064e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.028e+01, tolerance: 2.064e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.031e+01, tolerance: 2.064e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.028e+01, tolerance: 2.064e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.031e+01, tolerance: 2.064e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.028e+01, tolerance: 2.064e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.031e+01, tolerance: 2.064e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.028e+01, tolerance: 2.064e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.031e+01, tolerance: 2.064e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.028e+01, tolerance: 2.064e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.031e+01, tolerance: 2.064e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.028e+01, tolerance: 2.064e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.031e+01, tolerance: 2.064e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.028e+01, tolerance: 2.064e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.031e+01, tolerance: 2.064e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.029e+01, tolerance: 2.064e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.031e+01, tolerance: 2.064e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.029e+01, tolerance: 2.064e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.031e+01, tolerance: 2.064e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.029e+01, tolerance: 2.064e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.031e+01, tolerance: 2.064e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 22}. error: Expected n_neighbors <= n_samples,  but n_samples = 21, n_neighbors = 22
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 24}. error: Expected n_neighbors <= n_samples,  but n_samples = 21, n_neighbors = 24
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 26}. error: Expected n_neighbors <= n_samples,  but n_samples = 21, n_neighbors = 26
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 28}. error: Expected n_neighbors <= n_samples,  but n_samples = 21, n_neighbors = 28
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 30}. error: Expected n_neighbors <= n_samples,  but n_samples = 21, n_neighbors = 30
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 32}. error: Expected n_neighbors <= n_samples,  but n_samples = 21, n_neighbors = 32
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 34}. error: Expected n_neighbors <= n_samples,  but n_samples = 21, n_neighbors = 34
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 36}. error: Expected n_neighbors <= n_samples,  but n_samples = 21, n_neighbors = 36
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 38}. error: Expected n_neighbors <= n_samples,  but n_samples = 21, n_neighbors = 38
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 40}. error: Expected n_neighbors <= n_samples,  but n_samples = 21, n_neighbors = 40
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 42}. error: Expected n_neighbors <= n_samples,  but n_samples = 21, n_neighbors = 42
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 44}. error: Expected n_neighbors <= n_samples,  but n_samples = 21, n_neighbors = 44
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 46}. error: Expected n_neighbors <= n_samples,  but n_samples = 21, n_neighbors = 46
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 48}. error: Expected n_neighbors <= n_samples,  but n_samples = 21, n_neighbors = 48
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 50}. error: Expected n_neighbors <= n_samples,  but n_samples = 21, n_neighbors = 50
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 52}. error: Expected n_neighbors <= n_samples,  but n_samples = 21, n_neighbors = 52
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 54}. error: Expected n_neighbors <= n_samples,  but n_samples = 21, n_neighbors = 54
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 56}. error: Expected n_neighbors <= n_samples,  but n_samples = 21, n_neighbors = 56
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 58}. error: Expected n_neighbors <= n_samples,  but n_samples = 21, n_neighbors = 58
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 60}. error: Expected n_neighbors <= n_samples,  but n_samples = 21, n_neighbors = 60
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 62}. error: Expected n_neighbors <= n_samples,  but n_samples = 21, n_neighbors = 62
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 64}. error: Expected n_neighbors <= n_samples,  but n_samples = 21, n_neighbors = 64
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 66}. error: Expected n_neighbors <= n_samples,  but n_samples = 21, n_neighbors = 66
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 68}. error: Expected n_neighbors <= n_samples,  but n_samples = 21, n_neighbors = 68
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 70}. error: Expected n_neighbors <= n_samples,  but n_samples = 21, n_neighbors = 70
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 72}. error: Expected n_neighbors <= n_samples,  but n_samples = 21, n_neighbors = 72
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 74}. error: Expected n_neighbors <= n_samples,  but n_samples = 21, n_neighbors = 74
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 76}. error: Expected n_neighbors <= n_samples,  but n_samples = 21, n_neighbors = 76
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 78}. error: Expected n_neighbors <= n_samples,  but n_samples = 21, n_neighbors = 78
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 80}. error: Expected n_neighbors <= n_samples,  but n_samples = 21, n_neighbors = 80
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 82}. error: Expected n_neighbors <= n_samples,  but n_samples = 21, n_neighbors = 82
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 84}. error: Expected n_neighbors <= n_samples,  but n_samples = 21, n_neighbors = 84
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 86}. error: Expected n_neighbors <= n_samples,  but n_samples = 21, n_neighbors = 86
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 88}. error: Expected n_neighbors <= n_samples,  but n_samples = 21, n_neighbors = 88
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 90}. error: Expected n_neighbors <= n_samples,  but n_samples = 21, n_neighbors = 90
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 92}. error: Expected n_neighbors <= n_samples,  but n_samples = 21, n_neighbors = 92
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 94}. error: Expected n_neighbors <= n_samples,  but n_samples = 21, n_neighbors = 94
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 96}. error: Expected n_neighbors <= n_samples,  but n_samples = 21, n_neighbors = 96
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 98}. error: Expected n_neighbors <= n_samples,  but n_samples = 21, n_neighbors = 98
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: Expected n_neighbors <= n_samples,  but n_samples = 21, n_neighbors = 100
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 16}. error: Expected n_neighbors <= n_samples,  but n_samples = 15, n_neighbors = 16
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 18}. error: Expected n_neighbors <= n_samples,  but n_samples = 15, n_neighbors = 18
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 20}. error: Expected n_neighbors <= n_samples,  but n_samples = 15, n_neighbors = 20
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 22}. error: Expected n_neighbors <= n_samples,  but n_samples = 15, n_neighbors = 22
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 24}. error: Expected n_neighbors <= n_samples,  but n_samples = 15, n_neighbors = 24
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 26}. error: Expected n_neighbors <= n_samples,  but n_samples = 15, n_neighbors = 26
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 28}. error: Expected n_neighbors <= n_samples,  but n_samples = 15, n_neighbors = 28
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 30}. error: Expected n_neighbors <= n_samples,  but n_samples = 15, n_neighbors = 30
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 32}. error: Expected n_neighbors <= n_samples,  but n_samples = 15, n_neighbors = 32
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 34}. error: Expected n_neighbors <= n_samples,  but n_samples = 15, n_neighbors = 34
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 36}. error: Expected n_neighbors <= n_samples,  but n_samples = 15, n_neighbors = 36
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 38}. error: Expected n_neighbors <= n_samples,  but n_samples = 15, n_neighbors = 38
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 40}. error: Expected n_neighbors <= n_samples,  but n_samples = 15, n_neighbors = 40
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 42}. error: Expected n_neighbors <= n_samples,  but n_samples = 15, n_neighbors = 42
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 44}. error: Expected n_neighbors <= n_samples,  but n_samples = 15, n_neighbors = 44
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 46}. error: Expected n_neighbors <= n_samples,  but n_samples = 15, n_neighbors = 46
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 48}. error: Expected n_neighbors <= n_samples,  but n_samples = 15, n_neighbors = 48
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 50}. error: Expected n_neighbors <= n_samples,  but n_samples = 15, n_neighbors = 50
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 52}. error: Expected n_neighbors <= n_samples,  but n_samples = 15, n_neighbors = 52
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 54}. error: Expected n_neighbors <= n_samples,  but n_samples = 15, n_neighbors = 54
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 56}. error: Expected n_neighbors <= n_samples,  but n_samples = 15, n_neighbors = 56
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 58}. error: Expected n_neighbors <= n_samples,  but n_samples = 15, n_neighbors = 58
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 60}. error: Expected n_neighbors <= n_samples,  but n_samples = 15, n_neighbors = 60
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 62}. error: Expected n_neighbors <= n_samples,  but n_samples = 15, n_neighbors = 62
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 64}. error: Expected n_neighbors <= n_samples,  but n_samples = 15, n_neighbors = 64
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 66}. error: Expected n_neighbors <= n_samples,  but n_samples = 15, n_neighbors = 66
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 68}. error: Expected n_neighbors <= n_samples,  but n_samples = 15, n_neighbors = 68
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 70}. error: Expected n_neighbors <= n_samples,  but n_samples = 15, n_neighbors = 70
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 72}. error: Expected n_neighbors <= n_samples,  but n_samples = 15, n_neighbors = 72
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 74}. error: Expected n_neighbors <= n_samples,  but n_samples = 15, n_neighbors = 74
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 76}. error: Expected n_neighbors <= n_samples,  but n_samples = 15, n_neighbors = 76
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 78}. error: Expected n_neighbors <= n_samples,  but n_samples = 15, n_neighbors = 78
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 80}. error: Expected n_neighbors <= n_samples,  but n_samples = 15, n_neighbors = 80
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 82}. error: Expected n_neighbors <= n_samples,  but n_samples = 15, n_neighbors = 82
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 84}. error: Expected n_neighbors <= n_samples,  but n_samples = 15, n_neighbors = 84
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 86}. error: Expected n_neighbors <= n_samples,  but n_samples = 15, n_neighbors = 86
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 88}. error: Expected n_neighbors <= n_samples,  but n_samples = 15, n_neighbors = 88
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 90}. error: Expected n_neighbors <= n_samples,  but n_samples = 15, n_neighbors = 90
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 92}. error: Expected n_neighbors <= n_samples,  but n_samples = 15, n_neighbors = 92
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 94}. error: Expected n_neighbors <= n_samples,  but n_samples = 15, n_neighbors = 94
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 96}. error: Expected n_neighbors <= n_samples,  but n_samples = 15, n_neighbors = 96
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 98}. error: Expected n_neighbors <= n_samples,  but n_samples = 15, n_neighbors = 98
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: Expected n_neighbors <= n_samples,  but n_samples = 15, n_neighbors = 100
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 10}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 10
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 12}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 12
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 14}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 14
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 16}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 16
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 18}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 18
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 20}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 20
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 22}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 22
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 24}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 24
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 26}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 26
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 28}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 28
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 30}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 30
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 32}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 32
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 34}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 34
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 36}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 36
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 38}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 38
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 40}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 40
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 42}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 42
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 44}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 44
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 46}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 46
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 48}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 48
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 50}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 50
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 52}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 52
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 54}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 54
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 56}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 56
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 58}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 58
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 60}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 60
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 62}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 62
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 64}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 64
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 66}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 66
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 68}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 68
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 70}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 70
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 72}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 72
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 74}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 74
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 76}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 76
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 78}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 78
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 80}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 80
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 82}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 82
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 84}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 84
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 86}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 86
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 88}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 88
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 90}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 90
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 92}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 92
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 94}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 94
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 96}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 96
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 98}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 98
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 100
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of -0.5 cannot be evaluated. error: 0.0 cannot be raised to a negative power
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:Lambda value of 0 cannot be evaluated. error: Input X contains NaN.
ElasticNet does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of 0.5 cannot be evaluated. error: Input contains NaN.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.438e+00, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.690e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.572e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.916e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.367e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.433e+00, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.812e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.491e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.114e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.632e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.137e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.046e+00, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.351e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.405e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.808e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.867e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.060e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.952e+00, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.012e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.135e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.341e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.231e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.685e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.417e+00, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.599e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.496e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.851e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.592e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.766e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.761e+00, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.874e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.060e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.185e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.377e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.320e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.323e+00, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.255e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.522e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.618e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.621e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.900e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.919e+00, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.016e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.044e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.259e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.160e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.147e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.283e+00, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.256e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.527e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.456e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.766e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.533e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.622e+00, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.460e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.823e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.829e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.928e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.067e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.229e+00, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.278e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.397e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.524e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.550e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.410e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.695e+00, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.559e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.891e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.675e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.088e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.718e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.877e+00, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.639e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.073e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.002e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.182e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.206e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.442e+00, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.459e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.645e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.712e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.836e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.604e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.031e+00, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.808e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.188e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.861e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.363e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.882e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.099e+00, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.800e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.288e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.151e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.400e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.326e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.598e+00, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.593e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.830e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.854e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.057e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.754e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.312e+00, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.016e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.438e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.022e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.604e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.029e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.297e+00, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.946e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.478e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.282e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.591e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.432e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.717e+00, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.697e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.974e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.964e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.234e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.874e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.551e+00, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.194e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.653e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.165e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.817e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.162e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.476e+00, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.079e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.647e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.399e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.761e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.529e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.811e+00, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.779e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.090e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.053e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.378e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.973e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.758e+00, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.348e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.841e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.292e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.008e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.283e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.638e+00, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.202e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.800e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.506e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.915e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.617e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.888e+00, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.845e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.184e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.126e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.499e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.056e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.937e+00, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.483e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.007e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.406e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.181e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.394e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.787e+00, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.315e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.940e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.603e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.055e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.698e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.952e+00, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.901e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.264e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.188e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.601e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.126e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.096e+00, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.601e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.155e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.510e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.338e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.495e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.923e+00, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.420e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.069e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.694e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.184e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.774e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.001e+01, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.948e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.331e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.240e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.689e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.186e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.236e+00, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.706e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.289e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.606e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.481e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.589e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.050e+00, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.519e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.188e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.778e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.304e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.846e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.005e+01, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.988e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.389e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.285e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.766e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.239e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.362e+00, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.801e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.409e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.693e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.613e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.676e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.167e+00, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.610e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.299e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.856e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.416e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.913e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.009e+01, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.023e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.439e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.325e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.833e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.285e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.475e+00, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.885e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.520e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.773e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.734e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.756e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.277e+00, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.696e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.403e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.930e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.520e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.976e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.013e+01, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.053e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.484e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.359e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.892e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.326e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.578e+00, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.962e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.621e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.848e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.846e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.831e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.379e+00, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.777e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.500e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.999e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.618e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.036e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.016e+01, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.080e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.523e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.390e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.946e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.363e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.670e+00, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.032e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.714e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.917e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.951e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.901e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.475e+00, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.853e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.592e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.064e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.711e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.093e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.018e+01, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.104e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.558e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.417e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.993e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.396e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.755e+00, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.096e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.800e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.982e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.048e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.967e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.566e+00, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.925e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.678e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.126e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.799e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.148e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.021e+01, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.125e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.589e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.442e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.036e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.426e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.833e+00, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.154e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.880e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.042e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.139e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.028e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.651e+00, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.993e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.759e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.185e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.882e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.200e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.023e+01, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.144e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.618e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.464e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.075e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.453e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.905e+00, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.208e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.954e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.098e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.223e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.086e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.731e+00, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.058e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.837e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.241e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.961e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.250e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.025e+01, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.161e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.644e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.484e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.111e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.477e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.971e+00, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.258e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.023e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.152e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.303e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.140e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.807e+00, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.119e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.910e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.294e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.036e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.298e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.027e+01, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.177e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.667e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.503e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.143e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.500e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.032e+00, tolerance: 2.130e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.304e-02, tolerance: 1.502e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.088e+00, tolerance: 2.036e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.202e-02, tolerance: 1.382e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.378e+00, tolerance: 1.978e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.192e-02, tolerance: 1.205e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.693e+00, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.259e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.137e+00, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.313e-03, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.121e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.973e-03, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.165e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.665e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.145e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.552e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.823e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.085e-02, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.050e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.467e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.349e+00, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.180e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.651e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.698e-03, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.008e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.331e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.951e+00, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.013e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.330e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.160e-03, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.213e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.946e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.199e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.832e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.001e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.340e-02, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.090e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.668e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.011e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.473e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.797e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.616e-03, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.036e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.396e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.481e+00, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.141e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.447e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.007e-03, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.238e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.141e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.225e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.021e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.114e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.519e-02, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.117e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.821e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.058e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.672e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.888e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.106e-02, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.058e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.455e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.863e+00, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.239e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.527e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.689e-03, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.253e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.283e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.242e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.161e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.198e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.657e-02, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.138e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.943e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.091e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.821e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.957e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.223e-02, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.076e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.509e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.016e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.320e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.587e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.271e-03, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.264e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.393e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.253e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.270e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.264e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.768e-02, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.155e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.043e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.115e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.937e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.012e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.322e-02, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.092e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.560e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.039e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.388e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.636e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.784e-03, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.273e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.479e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.262e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.358e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.317e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.858e-02, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.169e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.127e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.135e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.032e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.059e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.407e-02, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.105e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.607e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.058e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.448e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.678e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.246e-03, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.279e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.550e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.270e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.430e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.362e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.934e-02, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.181e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.199e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.151e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.111e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.099e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.481e-02, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.117e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.651e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.075e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.501e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.713e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.668e-03, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.285e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.608e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.275e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.491e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.399e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.999e-02, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.191e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.261e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.164e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.179e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.135e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.547e-02, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.127e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.692e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.089e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.548e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.745e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.006e-02, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.289e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.657e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.280e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.542e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.431e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.054e-02, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.200e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.315e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.175e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.237e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.168e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.606e-02, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.136e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.731e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.101e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.592e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.774e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.042e-02, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.293e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.699e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.284e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.587e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.459e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.103e-02, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.207e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.363e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.185e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.288e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.197e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.659e-02, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.145e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.768e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.112e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.632e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.800e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.076e-02, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.296e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.735e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.288e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.625e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.484e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.145e-02, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.214e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.406e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.193e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.334e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.223e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.708e-02, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.152e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.803e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.121e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.669e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.824e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.108e-02, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.299e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.767e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.291e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.659e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.505e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.183e-02, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.220e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.445e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.201e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.374e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.247e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.752e-02, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.159e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.836e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.130e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.704e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.846e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.139e-02, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.302e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.794e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.293e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.689e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.525e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.217e-02, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.226e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.480e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.207e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.411e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.270e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.792e-02, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.166e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.867e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.137e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.736e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.867e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.168e-02, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.304e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.819e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.296e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.716e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.542e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.247e-02, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.231e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.511e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.213e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.444e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.290e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.829e-02, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.172e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.897e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.144e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.767e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.886e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.195e-02, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.306e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.841e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.298e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.740e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.557e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.274e-02, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.236e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.540e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.219e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.474e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.309e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.864e-02, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.177e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.926e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.151e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.796e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.904e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.222e-02, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.307e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.861e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.300e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.761e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.572e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.299e-02, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.240e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.567e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.224e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.502e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.327e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.896e-02, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.182e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.953e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.157e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.823e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.922e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.247e-02, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.309e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.879e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.301e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.781e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.584e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.321e-02, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.244e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.592e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.228e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.527e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.344e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.926e-02, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.187e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.979e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.162e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.849e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.938e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.271e-02, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.310e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.895e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.303e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.799e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.596e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.342e-02, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.247e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.614e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.232e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.551e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.359e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.954e-02, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.191e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.004e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.167e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.874e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.954e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.294e-02, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.312e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.910e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.304e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.815e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.607e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.360e-02, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.251e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.635e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.236e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.572e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.374e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.980e-02, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.195e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.028e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.172e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.898e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.969e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.317e-02, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.313e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.923e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.306e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.830e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.617e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.378e-02, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.254e+01, tolerance: 2.679e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.655e-02, tolerance: 6.460e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.240e+01, tolerance: 2.670e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.593e-02, tolerance: 6.368e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.388e+00, tolerance: 7.720e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.004e-02, tolerance: 5.613e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.929e+01, tolerance: 7.563e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.004e-01, tolerance: 1.088e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.214e+01, tolerance: 8.810e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.265e-01, tolerance: 1.149e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 27, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 27
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 28, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 28
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 29, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 29
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 30, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 30
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 31, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 31
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 32, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 32
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 32, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 32
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 33, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 33
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 34, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 34
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 34, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 34
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 35, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 35
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 36, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 36
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 36, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 36
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 37, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 37
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 38, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 38
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 38, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 38
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 39, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 39
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 40, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 40
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 40, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 40
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 41, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 41
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 42, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 42
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 42, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 42
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 43, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 43
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 44, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 44
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 44, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 44
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 45, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 45
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 46, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 46
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 46, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 46
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 47, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 47
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 48, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 48
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 48, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 48
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 49, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 49
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 50, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 50
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 50, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 50
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 51, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 51
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 52, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 52
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 52, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 52
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 53, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 53
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 54, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 54
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 54, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 54
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 55, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 55
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 56, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 56
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 56, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 56
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 57, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 57
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 58, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 58
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 58, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 58
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 59, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 59
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 60, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 60
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 60, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 60
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 61, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 61
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 62, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 62
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 62, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 62
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 63, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 63
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 64, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 64
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 64, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 64
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 65, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 65
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 66, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 66
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 66, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 66
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 67, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 67
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 68, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 68
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 68, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 68
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 69, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 69
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 70, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 70
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 70, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 70
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 71, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 71
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 72, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 72
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 72, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 72
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 73, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 73
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 74, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 74
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 74, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 74
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 75, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 75
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 76, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 76
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 76, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 76
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 77, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 77
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 78, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 78
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 78, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 78
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 79, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 79
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 80, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 80
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 80, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 80
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 81, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 81
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 82, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 82
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 82, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 82
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 83, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 83
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 84, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 84
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 84, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 84
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 85, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 85
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 86, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 86
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 86, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 86
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 87, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 87
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 88, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 88
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 88, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 88
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 89, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 89
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 90, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 90
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 90, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 90
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 91, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 91
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 92, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 92
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 92, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 92
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 93, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 93
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 94, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 94
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 94, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 94
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 95, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 95
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 96, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 96
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 96, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 96
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 97, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 97
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 98, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 98
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 98, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 98
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 99
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 100
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 100
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 27, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 27
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 28, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 28
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 29, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 29
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 30, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 30
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 31, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 31
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 32, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 32
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 32, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 32
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 33, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 33
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 34, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 34
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 34, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 34
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 35, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 35
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 36, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 36
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 36, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 36
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 37, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 37
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 38, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 38
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 38, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 38
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 39, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 39
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 40, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 40
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 40, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 40
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 41, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 41
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 42, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 42
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 42, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 42
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 43, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 43
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 44, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 44
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 44, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 44
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 45, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 45
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 46, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 46
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 46, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 46
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 47, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 47
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 48, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 48
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 48, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 48
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 49, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 49
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 50, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 50
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 50, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 50
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 51, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 51
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 52, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 52
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 52, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 52
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 53, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 53
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 54, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 54
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 54, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 54
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 55, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 55
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 56, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 56
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 56, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 56
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 57, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 57
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 58, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 58
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 58, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 58
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 59, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 59
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 60, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 60
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 60, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 60
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 61, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 61
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 62, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 62
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 62, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 62
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 63, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 63
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 64, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 64
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 64, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 64
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 65, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 65
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 66, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 66
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 66, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 66
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 67, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 67
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 68, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 68
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 68, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 68
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 69, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 69
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 70, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 70
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 70, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 70
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 71, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 71
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 72, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 72
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 72, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 72
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 73, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 73
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 74, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 74
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 74, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 74
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 75, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 75
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 76, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 76
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 76, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 76
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 77, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 77
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 78, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 78
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 78, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 78
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 79, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 79
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 80, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 80
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 80, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 80
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 81, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 81
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 82, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 82
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 82, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 82
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 83, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 83
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 84, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 84
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 84, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 84
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 85, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 85
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 86, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 86
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 86, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 86
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 87, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 87
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 88, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 88
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 88, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 88
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 89, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 89
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 90, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 90
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 90, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 90
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 91, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 91
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 92, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 92
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 92, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 92
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 93, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 93
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 94, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 94
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 94, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 94
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 95, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 95
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 96, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 96
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 96, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 96
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 97, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 97
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 98, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 98
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 98, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 98
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 29, n_neighbors = 99
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 31, n_neighbors = 100
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 26, n_neighbors = 100
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.746e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.700e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.256e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.307e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.486e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.103e-03, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.980e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.055e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.625e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.789e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.113e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.393e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.366e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.173e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.956e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.928e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.658e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.584e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.110e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.919e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.686e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.606e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.051e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.201e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.898e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.611e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.533e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.323e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.043e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.939e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.021e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.577e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.626e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.293e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.262e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.853e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.376e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.082e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.999e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.810e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.436e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.400e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.445e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.949e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.086e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.652e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.617e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.272e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.515e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.876e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.111e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.553e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.697e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.063e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.599e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.220e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.254e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.970e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.735e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.555e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.817e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.184e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.471e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.885e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.022e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.504e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.912e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.115e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.490e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.760e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.042e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.240e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.797e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.341e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.473e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.103e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.983e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.684e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.088e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.359e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.759e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.062e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.328e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.677e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.240e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.312e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.800e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.932e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.331e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.393e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.975e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.451e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.666e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.195e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.795e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.294e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.496e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.982e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.203e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.568e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.812e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.516e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.480e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.061e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.079e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.578e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.527e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.138e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.551e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.838e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.319e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.382e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.893e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.458e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.606e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.161e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.318e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.761e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.920e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.753e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.624e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.285e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.208e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.793e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.647e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.289e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.643e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.995e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.411e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.549e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.981e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.590e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.697e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.308e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.413e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.921e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.009e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.958e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.750e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.481e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.323e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.984e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.754e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.430e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.730e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.139e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.494e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.700e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.062e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.699e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.773e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.431e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.494e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.056e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.084e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.137e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.860e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.654e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.425e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.154e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.852e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.561e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.810e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.271e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.571e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.838e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.136e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.791e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.838e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.536e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.564e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.170e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.148e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.295e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.958e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.808e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.517e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.308e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.941e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.684e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.886e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.394e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.642e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.966e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.205e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.870e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.894e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.625e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.624e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.269e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.203e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.436e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.046e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.947e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.601e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.448e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.022e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.799e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.958e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.509e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.708e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.084e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.270e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.938e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.942e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.704e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.677e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.356e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.251e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.563e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.125e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.072e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.677e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.575e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.096e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.909e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.025e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.616e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.770e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.194e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.330e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.997e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.985e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.772e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.724e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.432e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.293e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.676e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.196e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.186e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.747e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.692e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.165e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.012e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.089e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.717e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.828e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.297e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.387e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.049e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.023e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.833e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.766e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.499e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.331e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.779e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.261e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.291e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.812e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.800e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.229e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.110e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.150e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.812e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.883e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.395e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.441e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.095e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.057e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.887e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.803e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.560e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.364e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.873e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.320e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.387e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.872e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.900e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.288e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.202e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.207e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.902e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.935e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.486e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.492e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.136e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.087e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.935e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.837e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.614e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.394e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.958e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.374e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.476e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.928e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.993e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.344e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.290e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.262e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.987e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.984e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.573e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.540e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.173e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.115e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.979e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.868e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.663e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.421e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.037e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.425e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.559e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.980e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.080e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.395e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.374e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.315e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.068e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.031e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.656e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.587e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.207e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.140e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.018e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.896e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.707e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.446e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.109e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.471e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.635e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.028e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.160e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.443e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.454e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.365e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.145e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.075e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.734e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.631e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.237e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.163e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.054e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.921e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.748e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.469e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.176e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.514e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.707e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.074e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.236e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.489e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.530e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.413e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.219e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.118e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.809e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.673e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.265e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.183e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.087e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.945e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.785e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.489e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.238e+00, tolerance: 1.973e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.553e-02, tolerance: 1.132e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.774e+00, tolerance: 1.966e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.116e-02, tolerance: 1.100e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.307e+00, tolerance: 1.927e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.531e-02, tolerance: 9.931e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.068e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.082e-03, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.033e+00, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.176e-03, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.433e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.249e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.366e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.081e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.338e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.006e-02, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.415e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.526e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.294e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.030e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.131e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.409e-03, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.193e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.106e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.130e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.523e-03, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.932e+00, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.049e-03, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.715e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.901e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.426e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.154e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.411e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.105e-02, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.542e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.472e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.330e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.104e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.202e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.619e-03, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.289e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.010e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.169e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.822e-03, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.054e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.675e-03, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.873e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.346e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.451e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.197e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.441e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.159e-02, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.597e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.004e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.352e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.150e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.246e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.036e-02, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.341e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.569e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.199e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.006e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.100e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.160e-03, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.979e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.690e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.466e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.225e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.457e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.193e-02, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.629e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.354e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.367e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.182e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.277e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.086e-02, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.377e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.965e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.222e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.025e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.137e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.552e-03, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.055e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.972e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.475e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.246e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.468e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.217e-02, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.651e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.603e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.380e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.206e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.300e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.122e-02, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.404e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.266e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.242e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.042e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.166e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.879e-03, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.114e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.213e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.481e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.261e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.475e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.236e-02, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.666e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.790e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.390e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.224e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.319e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.150e-02, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.426e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.504e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.259e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.057e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.191e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.158e-03, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.161e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.424e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.486e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.273e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.481e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.250e-02, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.677e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.936e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.399e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.239e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.335e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.172e-02, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.445e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.700e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.273e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.071e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.213e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.399e-03, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.200e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.612e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.489e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.283e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.485e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.261e-02, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.686e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.053e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.406e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.251e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.348e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.189e-02, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.461e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.865e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.286e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.083e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.231e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.611e-03, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.781e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.492e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.291e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.488e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.270e-02, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.694e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.149e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.412e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.261e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.359e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.204e-02, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.475e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.005e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.298e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.094e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.247e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.799e-03, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.262e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.935e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.495e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.298e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.491e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.278e-02, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.699e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.229e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.418e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.270e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.368e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.216e-02, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.488e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.128e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.308e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.104e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.261e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.968e-03, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.287e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.077e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.496e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.304e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.493e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.285e-02, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.704e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.297e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.423e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.277e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.377e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.227e-02, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.499e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.235e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.318e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.114e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.274e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.012e-02, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.309e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.207e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.498e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.308e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.495e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.290e-02, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.709e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.356e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.428e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.283e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.384e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.236e-02, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.509e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.330e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.326e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.123e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.285e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.026e-02, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.329e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.329e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.499e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.313e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.496e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.295e-02, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.712e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.406e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.432e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.289e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.391e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.244e-02, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.519e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.415e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.334e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.131e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.296e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.039e-02, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.347e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.442e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.501e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.317e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.497e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.300e-02, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.716e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.451e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.435e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.294e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.397e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.251e-02, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.527e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.492e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.341e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.138e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.305e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.050e-02, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.363e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.548e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.502e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.320e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.499e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.304e-02, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.718e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.490e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.439e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.298e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.402e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.257e-02, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.535e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.561e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.347e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.145e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.314e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.061e-02, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.377e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.647e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.503e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.323e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.500e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.307e-02, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.721e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.525e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.442e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.302e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.407e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.263e-02, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.543e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.625e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.354e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.152e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.322e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.071e-02, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.391e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.740e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.503e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.326e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.501e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.310e-02, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.723e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.557e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.445e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.305e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.412e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.268e-02, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.550e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.683e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.359e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.158e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.329e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.080e-02, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.404e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.828e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.504e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.328e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.501e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.313e-02, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.725e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.585e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.447e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.309e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.416e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.273e-02, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.556e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.736e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.364e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.164e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.336e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.089e-02, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.415e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.912e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.505e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.330e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.502e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.315e-02, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.727e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.611e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.450e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.312e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.420e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.277e-02, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.562e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.786e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.369e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.170e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.342e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.097e-02, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.426e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.991e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.505e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.332e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.503e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.318e-02, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.728e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.634e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.452e+01, tolerance: 3.033e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.314e-02, tolerance: 2.751e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.423e+01, tolerance: 3.031e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.280e-02, tolerance: 2.733e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+00, tolerance: 7.524e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.832e-03, tolerance: 1.826e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.084e+01, tolerance: 4.243e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.803e-01, tolerance: 8.762e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.939e+01, tolerance: 8.110e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.809e-01, tolerance: 1.103e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 23, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 23
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 24, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 24
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 25, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 25
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 26, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 26
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 27, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 27
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 28, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 28
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 28, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 28
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 29, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 29
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 30, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 30
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 30, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 30
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 31, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 31
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 32, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 32
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 32, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 32
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 33, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 33
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 34, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 34
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 34, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 34
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 35, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 35
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 36, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 36
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 36, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 36
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 37, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 37
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 38, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 38
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 38, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 38
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 39, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 39
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 40, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 40
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 40, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 40
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 41, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 41
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 42, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 42
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 42, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 42
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 43, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 43
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 44, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 44
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 44, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 44
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 45, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 45
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 46, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 46
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 46, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 46
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 47, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 47
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 48, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 48
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 48, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 48
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 49, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 49
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 50, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 50
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 50, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 50
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 51, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 51
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 52, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 52
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 52, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 52
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 53, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 53
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 54, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 54
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 54, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 54
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 55, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 55
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 56, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 56
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 56, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 56
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 57, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 57
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 58, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 58
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 58, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 58
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 59, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 59
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 60, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 60
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 60, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 60
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 61, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 61
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 62, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 62
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 62, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 62
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 63, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 63
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 64, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 64
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 64, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 64
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 65, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 65
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 66, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 66
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 66, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 66
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 67, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 67
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 68, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 68
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 68, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 68
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 69, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 69
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 70, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 70
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 70, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 70
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 71, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 71
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 72, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 72
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 72, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 72
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 73, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 73
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 74, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 74
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 74, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 74
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 75, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 75
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 76, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 76
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 76, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 76
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 77, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 77
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 78, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 78
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 78, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 78
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 79, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 79
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 80, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 80
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 80, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 80
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 81, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 81
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 82, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 82
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 82, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 82
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 83, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 83
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 84, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 84
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 84, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 84
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 85, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 85
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 86, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 86
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 86, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 86
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 87, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 87
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 88, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 88
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 88, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 88
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 89, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 89
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 90, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 90
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 90, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 90
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 91, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 91
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 92, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 92
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 92, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 92
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 93, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 93
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 94, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 94
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 94, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 94
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 95, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 95
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 96, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 96
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 96, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 96
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 97, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 97
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 98, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 98
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 98, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 98
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 99
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 100
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 100
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 23, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 23
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 24, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 24
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 25, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 25
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 26, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 26
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 27, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 27
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 28, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 28
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 28, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 28
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 29, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 29
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 30, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 30
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 30, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 30
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 31, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 31
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 32, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 32
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 32, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 32
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 33, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 33
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 34, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 34
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 34, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 34
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 35, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 35
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 36, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 36
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 36, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 36
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 37, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 37
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 38, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 38
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 38, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 38
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 39, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 39
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 40, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 40
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 40, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 40
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 41, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 41
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 42, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 42
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 42, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 42
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 43, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 43
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 44, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 44
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 44, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 44
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 45, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 45
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 46, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 46
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 46, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 46
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 47, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 47
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 48, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 48
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 48, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 48
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 49, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 49
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 50, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 50
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 50, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 50
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 51, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 51
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 52, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 52
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 52, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 52
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 53, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 53
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 54, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 54
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 54, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 54
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 55, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 55
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 56, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 56
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 56, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 56
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 57, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 57
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 58, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 58
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 58, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 58
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 59, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 59
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 60, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 60
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 60, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 60
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 61, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 61
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 62, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 62
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 62, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 62
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 63, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 63
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 64, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 64
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 64, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 64
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 65, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 65
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 66, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 66
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 66, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 66
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 67, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 67
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 68, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 68
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 68, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 68
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 69, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 69
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 70, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 70
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 70, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 70
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 71, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 71
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 72, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 72
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 72, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 72
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 73, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 73
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 74, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 74
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 74, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 74
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 75, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 75
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 76, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 76
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 76, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 76
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 77, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 77
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 78, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 78
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 78, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 78
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 79, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 79
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 80, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 80
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 80, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 80
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 81, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 81
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 82, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 82
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 82, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 82
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 83, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 83
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 84, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 84
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 84, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 84
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 85, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 85
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 86, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 86
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 86, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 86
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 87, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 87
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 88, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 88
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 88, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 88
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 89, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 89
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 90, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 90
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 90, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 90
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 91, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 91
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 92, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 92
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 92, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 92
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 93, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 93
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 94, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 94
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 94, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 94
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 95, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 95
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 96, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 96
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 96, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 96
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 97, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 97
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 98, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 98
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 98, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 98
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 25, n_neighbors = 99
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 27, n_neighbors = 100
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 22, n_neighbors = 100
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.017e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.140e-03, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.830e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.319e-03, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.347e-02, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.914e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.105e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.019e-03, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.519e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.293e-03, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.206e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.762e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.113e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.167e-03, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.406e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.701e-03, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.614e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.194e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.043e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.565e-03, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.354e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.768e-03, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.604e-02, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.639e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.129e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.033e-03, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.778e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.055e-03, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.844e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.650e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.136e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.026e-03, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.621e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.335e-03, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.188e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.927e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.059e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.866e-03, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.642e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.098e-03, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.116e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.115e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.143e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.751e-03, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.890e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.513e-03, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.180e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.099e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.148e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.650e-03, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.742e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.741e-03, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.487e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.306e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.070e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.117e-03, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.835e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.362e-03, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.329e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.475e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.152e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.031e-02, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.955e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.839e-03, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.392e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.373e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.156e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.014e-02, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.821e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.038e-03, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.672e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.539e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.078e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.337e-03, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.978e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.583e-03, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.509e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.764e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.158e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.076e-02, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.999e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.089e-03, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.540e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.560e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.161e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.055e-02, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.878e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.269e-03, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.798e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.699e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.085e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.536e-03, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.089e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.772e-03, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.666e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.006e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.163e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.113e-02, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.030e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.291e-03, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.651e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.695e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.166e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.090e-02, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.921e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.457e-03, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.890e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.814e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.091e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.719e-03, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.180e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.938e-03, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.804e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.213e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.167e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.145e-02, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.054e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.458e-03, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.737e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.798e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.169e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.119e-02, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.955e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.612e-03, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.960e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.902e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.097e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.890e-03, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.255e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.085e-03, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.927e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.394e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.170e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.172e-02, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.074e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.600e-03, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.805e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.878e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.172e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.145e-02, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.982e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.744e-03, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.014e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.972e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.101e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.050e-03, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.318e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.217e-03, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.037e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.553e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.173e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.196e-02, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.089e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.721e-03, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.862e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.943e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.175e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.168e-02, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.005e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.857e-03, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.059e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.028e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.106e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.200e-03, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.373e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.337e-03, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.137e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.695e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.176e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.216e-02, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.102e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.827e-03, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.909e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.997e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.177e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.188e-02, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.024e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.955e-03, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.095e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.074e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.109e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.343e-03, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.421e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.446e-03, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.227e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.823e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.178e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.235e-02, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.114e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.920e-03, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.950e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.042e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.179e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.206e-02, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.041e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.004e-02, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.126e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.112e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.113e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.479e-03, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.463e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.547e-03, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.310e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.938e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.179e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.251e-02, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.123e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.000e-02, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.984e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.081e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.180e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.223e-02, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.055e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.012e-02, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.152e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.145e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.116e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.608e-03, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.500e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.641e-03, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.386e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.044e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.181e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.266e-02, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.131e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.008e-02, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.015e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.114e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.182e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.238e-02, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.067e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.019e-02, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.174e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.174e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.119e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.731e-03, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.534e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.728e-03, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.456e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.140e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.182e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.279e-02, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.139e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.014e-02, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.041e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.142e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.183e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.251e-02, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.078e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.025e-02, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.193e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.199e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.121e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.849e-03, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.564e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.809e-03, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.521e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.229e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.184e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.291e-02, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.145e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.020e-02, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.065e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.168e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.184e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.263e-02, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.088e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.030e-02, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.210e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.220e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.124e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.962e-03, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.591e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.886e-03, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.582e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.311e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.185e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.302e-02, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.151e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.026e-02, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.086e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.190e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.185e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.275e-02, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.097e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.035e-02, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.226e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.240e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.126e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.071e-03, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.617e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.958e-03, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.638e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.388e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.186e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.312e-02, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.156e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.031e-02, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.105e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.210e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.186e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.285e-02, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.104e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.040e-02, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.239e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.257e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.128e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.175e-03, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.640e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.026e-03, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.691e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.458e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.187e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.321e-02, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.161e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.035e-02, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.123e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.228e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.187e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.294e-02, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.112e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.044e-02, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.251e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.272e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.130e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.276e-03, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.661e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.091e-03, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.740e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.525e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.188e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.330e-02, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.166e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.039e-02, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.138e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.244e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.188e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.303e-02, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.118e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.048e-02, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.262e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.286e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.132e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.373e-03, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.681e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.152e-03, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.787e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.587e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.188e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.338e-02, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.169e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.043e-02, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.153e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.259e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.188e+00, tolerance: 2.413e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.312e-02, tolerance: 3.079e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.124e-01, tolerance: 1.652e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.052e-02, tolerance: 2.284e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.272e-01, tolerance: 8.950e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.299e-03, tolerance: 1.512e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.144e+00, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.872e-03, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.203e+00, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.378e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.389e-01, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.302e-04, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.146e+00, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.000e-03, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.665e+00, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.910e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.121e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.623e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.259e+00, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.077e-03, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.417e+00, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.399e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.095e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.379e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.978e+00, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.297e-03, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.336e+00, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.077e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.036e-01, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.166e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.842e+00, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.514e-03, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.566e+00, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.078e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.283e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.346e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.508e+00, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.444e-03, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.004e+00, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.392e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.219e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.899e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.448e+00, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.536e-03, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.044e+00, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.620e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.160e-01, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.411e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.016e+01, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.863e-03, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.970e+00, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.745e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.357e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.777e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.658e+00, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.700e-03, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.393e+00, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.050e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.282e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.280e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.777e+00, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.707e-03, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.557e+00, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.066e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.008e-01, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.613e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.035e+01, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.125e-03, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.020e+01, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.197e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.401e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.074e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.770e+00, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.903e-03, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.682e+00, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.546e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.322e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.580e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.031e+00, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.845e-03, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.955e+00, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.444e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.681e-01, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.786e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.047e+01, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.334e-03, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.035e+01, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.531e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.430e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.296e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.862e+00, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.073e-03, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.909e+00, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.941e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.351e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.825e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.237e+00, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.962e-03, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.278e+00, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.771e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.232e-01, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.940e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.056e+01, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.504e-03, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.046e+01, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.791e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.451e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.469e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.939e+00, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.219e-03, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.094e+00, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.268e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.373e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.033e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.410e+00, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.065e-03, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.547e+00, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.057e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.694e-01, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.079e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.063e+01, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.647e-03, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.054e+01, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.000e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.467e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.609e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.001e+01, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.346e-03, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.247e+00, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.544e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.391e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.211e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.560e+00, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.158e-03, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.776e+00, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.312e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.009e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.205e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.068e+01, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.768e-03, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.060e+01, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.174e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.479e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.725e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.006e+01, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.458e-03, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.377e+00, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.781e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.406e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.367e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.690e+00, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.242e-03, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.974e+00, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.541e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.043e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.322e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.072e+01, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.872e-03, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.065e+01, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.320e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.489e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.823e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.012e+01, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.557e-03, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.489e+00, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.987e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.418e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.505e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.806e+00, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.320e-03, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.148e+00, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.748e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.072e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.429e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.075e+01, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.964e-03, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.445e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.498e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.907e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.016e+01, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.646e-03, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.586e+00, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.169e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.428e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.628e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.910e+00, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.393e-03, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.301e+00, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.936e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.099e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.529e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.078e+01, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.004e-02, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.072e+01, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.554e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.505e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.981e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.021e+01, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.727e-03, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.672e+00, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.330e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.437e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.739e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.004e+00, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.461e-03, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.438e+00, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.109e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.122e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.623e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.080e+01, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.012e-02, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.075e+01, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.649e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.511e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.045e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.024e+01, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.800e-03, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.748e+00, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.474e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.445e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.840e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.089e+00, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.525e-03, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.561e+00, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.268e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.143e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.711e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.082e+01, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.018e-02, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.078e+01, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.734e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.517e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.102e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.028e+01, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.867e-03, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.815e+00, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.604e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.453e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.931e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.167e+00, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.586e-03, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.672e+00, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.415e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.162e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.793e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.084e+01, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.024e-02, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.080e+01, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.809e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.522e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.154e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.031e+01, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.928e-03, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.876e+00, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.722e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.459e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.015e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.239e+00, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.643e-03, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.774e+00, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.552e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.179e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.871e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.086e+01, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.029e-02, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.081e+01, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.877e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.526e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.200e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.034e+01, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.984e-03, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.932e+00, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.829e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.465e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.092e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.305e+00, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.697e-03, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.867e+00, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.680e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.195e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.945e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.087e+01, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.034e-02, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.083e+01, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.938e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.530e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.241e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.037e+01, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.004e-02, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.982e+00, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.927e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.470e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.164e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.366e+00, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.749e-03, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.952e+00, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.799e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.210e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.015e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.088e+01, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.038e-02, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.084e+01, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.994e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.533e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.279e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.039e+01, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.008e-02, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.003e+01, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.017e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.475e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.230e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.423e+00, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.799e-03, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.031e+00, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.911e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.223e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.081e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.089e+01, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.042e-02, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.086e+01, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.004e-02, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.536e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.313e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.042e+01, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.013e-02, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.007e+01, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.100e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.479e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.292e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.476e+00, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.846e-03, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.103e+00, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.017e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.235e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.144e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.090e+01, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.045e-02, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.087e+01, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.009e-02, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.539e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.345e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.044e+01, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.017e-02, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.011e+01, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.177e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.484e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.349e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.526e+00, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.891e-03, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.171e+00, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.117e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.247e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.204e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.091e+01, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.049e-02, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.088e+01, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.013e-02, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.541e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.374e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.046e+01, tolerance: 2.218e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.021e-02, tolerance: 2.268e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.014e+01, tolerance: 2.217e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.248e-03, tolerance: 2.236e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.487e+00, tolerance: 3.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.403e-03, tolerance: 1.220e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 14, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 14
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 15, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 15
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 16, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 16
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 17, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 17
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 18, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 18
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 19, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 19
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 19, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 19
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 20, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 20
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 21, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 21
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 21, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 21
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 22, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 22
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 23, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 23
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 23, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 23
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 24, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 24
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 25, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 25
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 25, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 25
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 26, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 26
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 27, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 27
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 27, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 27
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 28, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 28
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 29, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 29
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 29, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 29
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 30, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 30
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 31, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 31
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 31, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 31
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 32, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 32
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 33, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 33
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 33, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 33
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 34, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 34
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 35, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 35
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 35, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 35
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 36, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 36
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 37, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 37
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 37, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 37
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 38, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 38
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 39, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 39
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 39, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 39
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 40, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 40
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 41, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 41
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 41, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 41
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 42, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 42
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 43, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 43
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 43, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 43
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 44, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 44
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 45, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 45
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 45, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 45
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 46, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 46
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 47, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 47
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 47, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 47
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 48, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 48
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 49, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 49
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 49, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 49
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 50, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 50
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 51, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 51
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 51, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 51
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 52, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 52
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 53, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 53
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 53, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 53
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 54, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 54
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 55, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 55
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 55, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 55
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 56, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 56
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 57, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 57
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 57, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 57
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 58, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 58
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 59, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 59
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 59, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 59
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 60, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 60
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 61, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 61
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 61, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 61
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 62, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 62
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 63, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 63
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 63, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 63
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 64, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 64
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 65, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 65
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 65, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 65
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 66, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 66
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 67, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 67
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 67, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 67
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 68, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 68
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 69, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 69
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 69, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 69
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 70, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 70
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 71, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 71
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 71, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 71
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 72, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 72
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 73, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 73
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 73, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 73
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 74, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 74
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 75, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 75
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 75, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 75
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 76, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 76
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 77, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 77
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 77, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 77
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 78, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 78
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 79, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 79
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 79, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 79
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 80, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 80
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 81, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 81
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 81, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 81
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 82, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 82
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 83, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 83
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 83, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 83
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 84, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 84
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 85, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 85
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 85, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 85
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 86, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 86
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 87, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 87
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 87, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 87
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 88, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 88
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 89, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 89
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 89, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 89
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 90, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 90
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 91, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 91
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 91, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 91
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 92, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 92
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 93, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 93
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 93, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 93
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 94, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 94
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 95, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 95
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 95, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 95
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 96, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 96
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 97, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 97
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 97, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 97
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 98, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 98
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 99
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 99
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 100
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 14, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 14
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 15, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 15
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 16, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 16
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 17, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 17
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 18, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 18
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 19, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 19
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 19, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 19
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 20, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 20
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 21, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 21
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 21, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 21
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 22, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 22
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 23, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 23
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 23, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 23
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 24, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 24
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 25, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 25
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 25, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 25
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 26, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 26
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 27, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 27
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 27, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 27
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 28, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 28
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 29, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 29
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 29, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 29
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 30, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 30
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 31, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 31
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 31, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 31
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 32, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 32
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 33, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 33
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 33, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 33
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 34, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 34
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 35, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 35
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 35, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 35
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 36, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 36
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 37, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 37
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 37, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 37
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 38, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 38
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 39, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 39
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 39, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 39
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 40, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 40
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 41, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 41
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 41, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 41
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 42, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 42
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 43, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 43
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 43, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 43
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 44, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 44
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 45, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 45
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 45, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 45
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 46, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 46
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 47, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 47
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 47, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 47
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 48, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 48
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 49, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 49
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 49, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 49
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 50, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 50
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 51, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 51
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 51, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 51
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 52, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 52
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 53, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 53
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 53, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 53
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 54, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 54
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 55, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 55
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 55, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 55
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 56, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 56
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 57, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 57
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 57, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 57
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 58, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 58
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 59, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 59
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 59, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 59
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 60, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 60
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 61, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 61
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 61, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 61
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 62, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 62
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 63, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 63
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 63, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 63
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 64, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 64
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 65, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 65
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 65, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 65
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 66, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 66
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 67, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 67
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 67, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 67
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 68, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 68
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 69, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 69
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 69, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 69
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 70, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 70
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 71, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 71
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 71, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 71
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 72, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 72
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 73, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 73
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 73, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 73
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 74, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 74
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 75, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 75
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 75, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 75
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 76, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 76
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 77, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 77
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 77, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 77
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 78, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 78
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 79, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 79
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 79, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 79
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 80, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 80
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 81, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 81
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 81, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 81
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 82, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 82
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 83, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 83
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 83, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 83
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 84, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 84
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 85, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 85
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 85, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 85
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 86, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 86
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 87, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 87
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 87, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 87
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 88, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 88
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 89, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 89
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 89, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 89
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 90, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 90
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 91, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 91
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 91, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 91
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 92, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 92
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 93, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 93
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 93, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 93
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 94, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 94
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 95, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 95
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 95, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 95
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 96, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 96
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 97, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 97
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 97, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 97
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 98, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 98
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 18, n_neighbors = 99
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 13, n_neighbors = 99
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 16, n_neighbors = 100
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 3}. error: list index out of range
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.618e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.332e-04, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.992e-01, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.231e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.141e-02, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.777e-06, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.027e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.979e-04, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.284e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.285e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.744e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.009e-05, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.996e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.869e-04, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.407e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.141e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.758e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.824e-05, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.760e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.019e-04, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.442e-01, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.848e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.076e-02, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.710e-05, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.147e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.323e-04, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.492e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.334e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.934e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.730e-05, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.120e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.723e-04, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.484e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.880e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.914e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.866e-05, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.838e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.522e-04, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.908e-01, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.273e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.825e-02, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.501e-05, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.212e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.175e-04, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.593e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.033e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.801e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.165e-04, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.190e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.318e-04, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.539e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.437e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.741e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.290e-04, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.892e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.934e-04, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.093e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.604e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.140e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.253e-05, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.254e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.787e-04, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.656e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.557e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.463e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.403e-04, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.235e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.765e-04, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.581e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.876e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.367e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.530e-04, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.933e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.290e-04, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.170e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.879e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.383e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.971e-05, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.284e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.255e-04, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.698e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.969e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.986e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.601e-04, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.268e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.012e-03, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.615e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.232e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.861e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.727e-04, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.967e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.604e-04, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.232e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.116e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.612e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.656e-05, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.307e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.627e-04, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.729e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.305e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.409e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.770e-04, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.293e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.040e-03, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.642e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.527e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.263e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.892e-04, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.996e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.886e-04, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.283e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.326e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.828e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.312e-05, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.325e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.933e-04, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.752e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.584e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.760e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.917e-04, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.312e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.064e-03, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.665e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.775e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.597e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.033e-04, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.020e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.142e-04, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.326e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.516e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.032e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.940e-05, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.339e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.019e-03, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.771e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.821e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.056e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.045e-04, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.328e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.084e-03, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.685e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.988e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.880e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.156e-04, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.042e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.377e-04, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.362e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.689e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.225e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.542e-05, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.351e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.041e-03, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.786e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.024e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.309e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.158e-04, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.340e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.101e-03, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.702e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.171e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.123e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.264e-04, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.061e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.593e-04, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.394e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.848e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.408e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.121e-05, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.361e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.059e-03, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.798e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.200e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.528e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.260e-04, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.351e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.116e-03, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.717e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.332e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.335e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.360e-04, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.079e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.793e-04, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.423e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.996e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.582e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.677e-05, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.370e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.076e-03, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.808e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.355e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.720e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.351e-04, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.361e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.129e-03, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.730e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.474e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.521e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.446e-04, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.094e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.980e-04, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.448e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.135e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.748e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.212e-05, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.377e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.090e-03, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.817e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.492e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.889e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.433e-04, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.369e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.141e-03, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.741e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.599e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.686e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.523e-04, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.109e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.154e-04, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.470e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.265e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.906e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.728e-05, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.384e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.103e-03, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.825e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.614e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.039e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.508e-04, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.376e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.151e-03, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.751e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.712e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.834e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e-04, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.122e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.318e-04, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.491e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.388e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.056e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.225e-05, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.389e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.115e-03, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.832e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.723e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.173e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.576e-04, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.382e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.160e-03, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.760e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.813e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.967e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.658e-04, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.134e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.472e-04, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.509e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.504e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.200e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.705e-05, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.394e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.125e-03, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.838e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.822e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.294e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.639e-04, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.387e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.168e-03, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.769e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.905e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.088e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e-04, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.145e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.617e-04, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.526e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.614e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.337e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.017e-04, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.399e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.134e-03, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.843e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.911e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.404e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.697e-04, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.392e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.175e-03, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.776e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.988e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.198e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e-04, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.156e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.754e-04, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.542e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.719e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.469e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.062e-04, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.403e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.143e-03, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.847e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.993e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.503e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.750e-04, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.397e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.182e-03, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.783e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.064e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.298e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.821e-04, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.166e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.883e-04, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.556e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.819e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.595e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.105e-04, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.407e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.151e-03, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.852e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.067e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.594e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.800e-04, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.401e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.188e-03, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.789e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.134e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.391e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.868e-04, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.175e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.007e-04, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.569e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.914e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.715e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.147e-04, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.410e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.158e-03, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.855e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.136e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.678e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.846e-04, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.404e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.194e-03, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.795e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.198e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.476e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.911e-04, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.183e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.124e-04, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.582e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.006e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.831e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.188e-04, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.413e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.164e-03, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.859e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.199e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.755e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.889e-04, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.408e+00, tolerance: 4.965e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.199e-03, tolerance: 2.651e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.800e+00, tolerance: 3.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.258e-04, tolerance: 1.951e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.554e-01, tolerance: 1.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.951e-04, tolerance: 8.302e-08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.291e+00, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.837e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.489e-01, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.668e-04, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.393e-03, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.242e-05, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.946e+00, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.134e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.711e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.017e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.627e-02, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.562e-04, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.039e+01, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.386e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.414e-01, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.194e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.370e-03, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.678e-05, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.312e+00, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.373e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.180e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.104e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.554e-03, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.333e-05, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.025e+01, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.430e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.389e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.417e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.542e-02, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.642e-04, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.094e+01, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.666e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.386e-01, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.439e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.684e-03, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.195e-05, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.946e+00, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.636e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.489e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.331e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.250e-02, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.229e-04, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.094e+01, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.597e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.766e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.633e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.023e-02, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.385e-04, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.123e+01, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.821e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.083e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.601e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.944e-03, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.356e-04, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.417e+00, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.801e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.731e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.505e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.626e-02, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.611e-04, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.137e+01, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.713e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.016e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.775e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.215e-02, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.879e-04, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.142e+01, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.922e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.296e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.724e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.153e-03, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.778e-04, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.794e+00, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.919e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.932e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.645e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.984e-02, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.980e-04, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.168e+01, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.800e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.196e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.877e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.202e-02, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.178e-04, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.157e+01, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.994e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.484e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.826e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.131e-02, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.186e-04, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.110e+00, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.010e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.102e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.762e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.325e-02, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.339e-04, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.190e+01, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.869e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.334e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.955e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.037e-02, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.032e-03, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.168e+01, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.048e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.654e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.912e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.342e-02, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.582e-04, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.382e+00, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.083e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.250e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.862e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.651e-02, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.686e-04, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.208e+01, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.924e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.443e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.017e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.755e-02, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.134e-03, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.178e+01, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.091e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.807e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.988e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.549e-02, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.965e-04, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.621e+00, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.145e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.382e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.950e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.964e-02, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.023e-04, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.222e+01, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.970e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.533e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.067e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.038e-01, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.224e-03, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.186e+01, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.125e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.948e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.056e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.750e-02, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.337e-04, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.834e+00, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.199e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.499e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.027e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.263e-02, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.350e-04, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.233e+01, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.009e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.607e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.109e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.093e-01, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.306e-03, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.193e+01, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.153e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.077e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.116e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.948e-02, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.697e-04, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.025e+00, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.245e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.605e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.095e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.550e-02, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.668e-04, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.243e+01, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.042e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.670e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.145e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.142e-01, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.381e-03, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.199e+01, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.176e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.196e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.172e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.141e-02, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.047e-04, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.198e+00, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.287e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.702e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.157e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.826e-02, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.977e-04, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.251e+01, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.071e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.724e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.176e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.186e-01, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.448e-03, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.204e+01, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.196e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.306e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.331e-02, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.386e-04, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.356e+00, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.325e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.791e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.214e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.091e-02, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.278e-04, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.258e+01, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.096e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.771e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.203e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.226e-01, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.510e-03, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.209e+01, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.214e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.409e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.269e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.516e-02, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.716e-04, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.502e+00, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.359e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.873e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.265e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.346e-02, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.571e-04, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.264e+01, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.119e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.812e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.226e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.262e-01, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.567e-03, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.214e+01, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.229e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.504e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.312e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.697e-02, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.037e-04, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.636e+00, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.391e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.949e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.312e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.592e-02, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.857e-04, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.269e+01, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.138e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.849e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.247e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.294e-01, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.619e-03, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.218e+01, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.242e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.352e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.875e-02, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.349e-04, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.761e+00, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.420e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.020e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.355e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.830e-02, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.135e-04, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.273e+01, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.156e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.882e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.266e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.324e-01, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.668e-03, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.222e+01, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.254e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.677e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.389e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.049e-02, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.652e-04, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.877e+00, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.447e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.086e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.395e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.059e-02, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.406e-04, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.278e+01, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.172e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.911e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.283e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.352e-01, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.713e-03, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.226e+01, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.265e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.756e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.424e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.220e-02, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.947e-04, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.986e+00, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.473e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.148e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.432e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.280e-02, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.671e-04, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.281e+01, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.187e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.937e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.298e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.378e-01, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.755e-03, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.229e+01, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.274e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.830e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.457e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.387e-02, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.235e-04, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.009e+01, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.497e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.206e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.467e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.495e-02, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.929e-04, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.285e+01, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.200e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.961e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.312e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.401e-01, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.794e-03, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.232e+01, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.283e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.900e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.487e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.552e-02, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.515e-04, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.018e+01, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.519e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.262e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.500e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.702e-02, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.181e-04, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.288e+01, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.212e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.983e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.325e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.423e-01, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.831e-03, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.235e+01, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.291e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.966e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.516e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.712e-02, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.788e-04, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.027e+01, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.540e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.314e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.530e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.902e-02, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.427e-04, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.290e+01, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.223e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.003e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.336e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.443e-01, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.865e-03, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.238e+01, tolerance: 2.700e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.298e-03, tolerance: 1.496e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.028e+00, tolerance: 1.094e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.544e-03, tolerance: 7.216e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.870e-02, tolerance: 4.072e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.054e-04, tolerance: 5.876e-07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.030e+00, tolerance: 8.871e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.404e-02, tolerance: 5.384e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.054e+01, tolerance: 2.510e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.165e-02, tolerance: 3.260e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 5, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 5
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 6, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 7, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 7
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 8, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 8
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 9, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 9
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 10, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 10
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 10, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 10
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 11, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 11
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 12, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 12
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 12, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 12
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 13, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 13
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 14, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 14
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 14, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 14
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 15, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 15
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 16, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 16
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 16, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 16
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 17, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 17
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 18, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 18
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 18, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 18
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 19, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 19
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 20, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 20
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 20, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 20
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 21, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 21
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 22, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 22
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 22, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 22
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 23, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 23
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 24, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 24
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 24, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 24
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 25, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 25
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 26, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 26
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 26, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 26
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 27, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 27
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 28, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 28
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 28, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 28
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 29, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 29
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 30, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 30
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 30, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 30
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 31, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 31
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 32, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 32
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 32, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 32
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 33, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 33
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 34, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 34
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 34, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 34
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 35, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 35
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 36, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 36
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 36, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 36
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 37, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 37
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 38, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 38
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 38, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 38
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 39, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 39
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 40, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 40
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 40, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 40
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 41, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 41
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 42, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 42
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 42, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 42
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 43, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 43
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 44, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 44
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 44, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 44
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 45, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 45
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 46, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 46
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 46, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 46
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 47, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 47
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 48, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 48
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 48, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 48
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 49, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 49
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 50, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 50
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 50, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 50
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 51, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 51
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 52, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 52
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 52, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 52
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 53, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 53
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 54, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 54
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 54, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 54
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 55, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 55
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 56, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 56
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 56, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 56
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 57, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 57
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 58, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 58
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 58, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 58
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 59, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 59
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 60, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 60
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 60, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 60
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 61, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 61
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 62, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 62
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 62, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 62
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 63, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 63
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 64, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 64
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 64, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 64
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 65, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 65
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 66, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 66
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 66, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 66
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 67, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 67
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 68, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 68
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 68, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 68
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 69, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 69
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 70, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 70
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 70, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 70
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 71, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 71
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 72, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 72
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 72, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 72
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 73, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 73
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 74, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 74
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 74, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 74
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 75, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 75
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 76, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 76
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 76, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 76
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 77, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 77
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 78, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 78
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 78, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 78
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 79, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 79
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 80, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 80
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 80, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 80
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 81, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 81
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 82, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 82
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 82, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 82
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 83, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 83
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 84, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 84
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 84, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 84
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 85, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 85
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 86, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 86
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 86, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 86
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 87, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 87
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 88, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 88
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 88, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 88
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 89, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 89
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 90, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 90
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 90, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 90
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 91, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 91
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 92, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 92
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 92, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 92
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 93, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 93
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 94, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 94
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 94, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 94
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 95, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 95
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 96, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 96
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 96, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 96
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 97, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 97
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 98, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 98
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 98, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 98
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 99
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 100
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 100
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 5, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 5
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 6, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 7, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 7
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 8, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 8
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 9, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 9
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 10, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 10
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 10, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 10
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 11, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 11
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 12, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 12
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 12, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 12
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 13, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 13
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 14, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 14
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 14, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 14
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 15, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 15
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 16, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 16
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 16, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 16
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 17, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 17
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 18, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 18
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 18, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 18
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 19, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 19
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 20, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 20
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 20, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 20
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 21, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 21
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 22, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 22
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 22, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 22
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 23, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 23
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 24, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 24
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 24, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 24
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 25, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 25
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 26, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 26
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 26, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 26
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 27, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 27
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 28, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 28
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 28, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 28
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 29, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 29
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 30, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 30
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 30, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 30
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 31, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 31
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 32, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 32
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 32, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 32
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 33, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 33
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 34, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 34
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 34, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 34
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 35, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 35
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 36, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 36
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 36, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 36
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 37, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 37
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 38, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 38
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 38, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 38
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 39, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 39
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 40, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 40
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 40, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 40
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 41, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 41
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 42, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 42
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 42, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 42
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 43, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 43
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 44, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 44
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 44, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 44
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 45, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 45
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 46, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 46
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 46, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 46
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 47, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 47
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 48, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 48
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 48, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 48
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 49, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 49
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 50, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 50
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 50, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 50
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 51, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 51
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 52, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 52
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 52, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 52
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 53, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 53
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 54, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 54
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 54, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 54
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 55, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 55
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 56, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 56
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 56, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 56
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 57, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 57
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 58, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 58
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 58, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 58
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 59, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 59
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 60, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 60
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 60, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 60
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 61, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 61
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 62, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 62
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 62, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 62
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 63, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 63
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 64, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 64
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 64, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 64
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 65, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 65
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 66, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 66
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 66, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 66
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 67, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 67
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 68, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 68
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 68, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 68
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 69, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 69
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 70, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 70
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 70, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 70
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 71, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 71
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 72, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 72
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 72, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 72
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 73, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 73
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 74, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 74
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 74, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 74
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 75, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 75
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 76, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 76
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 76, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 76
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 77, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 77
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 78, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 78
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 78, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 78
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 79, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 79
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 80, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 80
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 80, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 80
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 81, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 81
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 82, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 82
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 82, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 82
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 83, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 83
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 84, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 84
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 84, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 84
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 85, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 85
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 86, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 86
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 86, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 86
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 87, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 87
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 88, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 88
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 88, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 88
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 89, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 89
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 90, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 90
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 90, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 90
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 91, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 91
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 92, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 92
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 92, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 92
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 93, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 93
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 94, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 94
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 94, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 94
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 95, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 95
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 96, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 96
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 96, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 96
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 97, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 97
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 98, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 98
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 98, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 98
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99, 'lags': 3}. error: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 99
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 1}. error: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 100
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 100
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100, 'lags': 6}. error: list index out of range
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.098e+01, tolerance: 9.017e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.215e+01, tolerance: 9.017e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.123e+01, tolerance: 9.017e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.283e+01, tolerance: 9.017e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.142e+01, tolerance: 9.017e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.325e+01, tolerance: 9.017e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.159e+01, tolerance: 9.017e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.354e+01, tolerance: 9.017e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.173e+01, tolerance: 9.017e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.375e+01, tolerance: 9.017e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.186e+01, tolerance: 9.017e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.199e+01, tolerance: 9.017e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.404e+01, tolerance: 9.017e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.210e+01, tolerance: 9.017e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.414e+01, tolerance: 9.017e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.220e+01, tolerance: 9.017e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.422e+01, tolerance: 9.017e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.230e+01, tolerance: 9.017e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.429e+01, tolerance: 9.017e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.239e+01, tolerance: 9.017e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.435e+01, tolerance: 9.017e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.247e+01, tolerance: 9.017e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.440e+01, tolerance: 9.017e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.255e+01, tolerance: 9.017e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.445e+01, tolerance: 9.017e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.263e+01, tolerance: 9.017e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.449e+01, tolerance: 9.017e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.270e+01, tolerance: 9.017e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.452e+01, tolerance: 9.017e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.277e+01, tolerance: 9.017e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.455e+01, tolerance: 9.017e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.283e+01, tolerance: 9.017e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.458e+01, tolerance: 9.017e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.289e+01, tolerance: 9.017e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.460e+01, tolerance: 9.017e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.294e+01, tolerance: 9.017e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.463e+01, tolerance: 9.017e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.300e+01, tolerance: 9.017e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.465e+01, tolerance: 9.017e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.575e+01, tolerance: 1.066e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.044e+01, tolerance: 1.170e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 80}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 80
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 82}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 82
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 84}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 84
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 86}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 86
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 88}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 88
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 90}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 90
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 92}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 92
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 94}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 94
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 96}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 96
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 98}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 98
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 100
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of -0.5 cannot be evaluated. error: 0.0 cannot be raised to a negative power
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:Lambda value of 0 cannot be evaluated. error: test_size=25 should be either positive and smaller than the number of samples 18 or a float in the (0, 1) range
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of 0.5 cannot be evaluated. error: Input contains NaN.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.809e+01, tolerance: 6.858e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.555e+01, tolerance: 6.858e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.893e+01, tolerance: 6.858e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.808e+01, tolerance: 6.858e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.963e+01, tolerance: 6.858e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.945e+01, tolerance: 6.858e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.024e+01, tolerance: 6.858e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.032e+01, tolerance: 6.858e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.077e+01, tolerance: 6.858e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.092e+01, tolerance: 6.858e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.124e+01, tolerance: 6.858e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.136e+01, tolerance: 6.858e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.167e+01, tolerance: 6.858e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.170e+01, tolerance: 6.858e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.206e+01, tolerance: 6.858e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.197e+01, tolerance: 6.858e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.242e+01, tolerance: 6.858e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.219e+01, tolerance: 6.858e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.275e+01, tolerance: 6.858e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.237e+01, tolerance: 6.858e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.306e+01, tolerance: 6.858e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.252e+01, tolerance: 6.858e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.335e+01, tolerance: 6.858e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.265e+01, tolerance: 6.858e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.362e+01, tolerance: 6.858e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.276e+01, tolerance: 6.858e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.387e+01, tolerance: 6.858e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.286e+01, tolerance: 6.858e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.411e+01, tolerance: 6.858e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.295e+01, tolerance: 6.858e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.434e+01, tolerance: 6.858e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.302e+01, tolerance: 6.858e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.456e+01, tolerance: 6.858e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.309e+01, tolerance: 6.858e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.476e+01, tolerance: 6.858e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.315e+01, tolerance: 6.858e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.496e+01, tolerance: 6.858e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.321e+01, tolerance: 6.858e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.514e+01, tolerance: 6.858e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.326e+01, tolerance: 6.858e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.840e+01, tolerance: 8.689e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.808e+01, tolerance: 1.049e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 66}. error: Expected n_neighbors <= n_samples,  but n_samples = 65, n_neighbors = 66
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 68}. error: Expected n_neighbors <= n_samples,  but n_samples = 65, n_neighbors = 68
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 70}. error: Expected n_neighbors <= n_samples,  but n_samples = 65, n_neighbors = 70
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 72}. error: Expected n_neighbors <= n_samples,  but n_samples = 65, n_neighbors = 72
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 74}. error: Expected n_neighbors <= n_samples,  but n_samples = 65, n_neighbors = 74
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 76}. error: Expected n_neighbors <= n_samples,  but n_samples = 65, n_neighbors = 76
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 78}. error: Expected n_neighbors <= n_samples,  but n_samples = 65, n_neighbors = 78
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 80}. error: Expected n_neighbors <= n_samples,  but n_samples = 65, n_neighbors = 80
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 82}. error: Expected n_neighbors <= n_samples,  but n_samples = 65, n_neighbors = 82
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 84}. error: Expected n_neighbors <= n_samples,  but n_samples = 65, n_neighbors = 84
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 86}. error: Expected n_neighbors <= n_samples,  but n_samples = 65, n_neighbors = 86
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 88}. error: Expected n_neighbors <= n_samples,  but n_samples = 65, n_neighbors = 88
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 90}. error: Expected n_neighbors <= n_samples,  but n_samples = 65, n_neighbors = 90
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 92}. error: Expected n_neighbors <= n_samples,  but n_samples = 65, n_neighbors = 92
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 94}. error: Expected n_neighbors <= n_samples,  but n_samples = 65, n_neighbors = 94
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 96}. error: Expected n_neighbors <= n_samples,  but n_samples = 65, n_neighbors = 96
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 98}. error: Expected n_neighbors <= n_samples,  but n_samples = 65, n_neighbors = 98
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: Expected n_neighbors <= n_samples,  but n_samples = 65, n_neighbors = 100
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of -0.5 cannot be evaluated. error: 0.0 cannot be raised to a negative power
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:Lambda value of 0 cannot be evaluated. error: test_size=25 should be either positive and smaller than the number of samples 13 or a float in the (0, 1) range
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of 0.5 cannot be evaluated. error: Input contains NaN.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.208e+11, tolerance: 1.706e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.604e+11, tolerance: 1.706e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.416e+11, tolerance: 1.706e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.160e+11, tolerance: 1.706e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.581e+11, tolerance: 1.706e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.511e+11, tolerance: 1.706e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.718e+11, tolerance: 1.706e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.762e+11, tolerance: 1.706e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.838e+11, tolerance: 1.706e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.954e+11, tolerance: 1.706e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.945e+11, tolerance: 1.706e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.107e+11, tolerance: 1.706e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.041e+11, tolerance: 1.706e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.232e+11, tolerance: 1.706e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.128e+11, tolerance: 1.706e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.336e+11, tolerance: 1.706e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.209e+11, tolerance: 1.706e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.425e+11, tolerance: 1.706e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.283e+11, tolerance: 1.706e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.501e+11, tolerance: 1.706e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.353e+11, tolerance: 1.706e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.567e+11, tolerance: 1.706e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.418e+11, tolerance: 1.706e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.625e+11, tolerance: 1.706e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.480e+11, tolerance: 1.706e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.677e+11, tolerance: 1.706e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.538e+11, tolerance: 1.706e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.723e+11, tolerance: 1.706e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.593e+11, tolerance: 1.706e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.764e+11, tolerance: 1.706e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.645e+11, tolerance: 1.706e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.801e+11, tolerance: 1.706e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.694e+11, tolerance: 1.706e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.835e+11, tolerance: 1.706e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.742e+11, tolerance: 1.706e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.865e+11, tolerance: 1.706e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.787e+11, tolerance: 1.706e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.894e+11, tolerance: 1.706e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.831e+11, tolerance: 1.706e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.919e+11, tolerance: 1.706e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of -0.5 cannot be evaluated. error: 0.0 cannot be raised to a negative power
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:Lambda value of 0 cannot be evaluated. error: Input X contains NaN.
ElasticNet does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of 0.5 cannot be evaluated. error: Input contains NaN.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.685e+09, tolerance: 2.313e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.015e+10, tolerance: 2.313e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.009e+09, tolerance: 2.313e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.068e+10, tolerance: 2.313e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.269e+09, tolerance: 2.313e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.091e+10, tolerance: 2.313e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.485e+09, tolerance: 2.313e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.105e+10, tolerance: 2.313e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.668e+09, tolerance: 2.313e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.114e+10, tolerance: 2.313e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.826e+09, tolerance: 2.313e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.120e+10, tolerance: 2.313e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.965e+09, tolerance: 2.313e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.125e+10, tolerance: 2.313e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.088e+09, tolerance: 2.313e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.129e+10, tolerance: 2.313e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.198e+09, tolerance: 2.313e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.131e+10, tolerance: 2.313e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.298e+09, tolerance: 2.313e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.134e+10, tolerance: 2.313e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.388e+09, tolerance: 2.313e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.136e+10, tolerance: 2.313e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.470e+09, tolerance: 2.313e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.137e+10, tolerance: 2.313e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.546e+09, tolerance: 2.313e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.139e+10, tolerance: 2.313e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.616e+09, tolerance: 2.313e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.140e+10, tolerance: 2.313e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.681e+09, tolerance: 2.313e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.141e+10, tolerance: 2.313e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.741e+09, tolerance: 2.313e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.142e+10, tolerance: 2.313e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.797e+09, tolerance: 2.313e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.143e+10, tolerance: 2.313e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.850e+09, tolerance: 2.313e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.143e+10, tolerance: 2.313e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.899e+09, tolerance: 2.313e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.144e+10, tolerance: 2.313e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.945e+09, tolerance: 2.313e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.145e+10, tolerance: 2.313e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 62}. error: Expected n_neighbors <= n_samples,  but n_samples = 61, n_neighbors = 62
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 64}. error: Expected n_neighbors <= n_samples,  but n_samples = 61, n_neighbors = 64
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 66}. error: Expected n_neighbors <= n_samples,  but n_samples = 61, n_neighbors = 66
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 68}. error: Expected n_neighbors <= n_samples,  but n_samples = 61, n_neighbors = 68
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 70}. error: Expected n_neighbors <= n_samples,  but n_samples = 61, n_neighbors = 70
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 72}. error: Expected n_neighbors <= n_samples,  but n_samples = 61, n_neighbors = 72
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 74}. error: Expected n_neighbors <= n_samples,  but n_samples = 61, n_neighbors = 74
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 76}. error: Expected n_neighbors <= n_samples,  but n_samples = 61, n_neighbors = 76
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 78}. error: Expected n_neighbors <= n_samples,  but n_samples = 61, n_neighbors = 78
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 80}. error: Expected n_neighbors <= n_samples,  but n_samples = 61, n_neighbors = 80
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 82}. error: Expected n_neighbors <= n_samples,  but n_samples = 61, n_neighbors = 82
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 84}. error: Expected n_neighbors <= n_samples,  but n_samples = 61, n_neighbors = 84
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 86}. error: Expected n_neighbors <= n_samples,  but n_samples = 61, n_neighbors = 86
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 88}. error: Expected n_neighbors <= n_samples,  but n_samples = 61, n_neighbors = 88
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 90}. error: Expected n_neighbors <= n_samples,  but n_samples = 61, n_neighbors = 90
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 92}. error: Expected n_neighbors <= n_samples,  but n_samples = 61, n_neighbors = 92
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 94}. error: Expected n_neighbors <= n_samples,  but n_samples = 61, n_neighbors = 94
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 96}. error: Expected n_neighbors <= n_samples,  but n_samples = 61, n_neighbors = 96
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 98}. error: Expected n_neighbors <= n_samples,  but n_samples = 61, n_neighbors = 98
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: Expected n_neighbors <= n_samples,  but n_samples = 61, n_neighbors = 100
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.536e+00, tolerance: 3.256e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.572e+00, tolerance: 3.256e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.544e+00, tolerance: 3.256e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.589e+00, tolerance: 3.256e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.550e+00, tolerance: 3.256e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.598e+00, tolerance: 3.256e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.556e+00, tolerance: 3.256e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.604e+00, tolerance: 3.256e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.561e+00, tolerance: 3.256e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.608e+00, tolerance: 3.256e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.565e+00, tolerance: 3.256e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.611e+00, tolerance: 3.256e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.569e+00, tolerance: 3.256e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.613e+00, tolerance: 3.256e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.572e+00, tolerance: 3.256e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.614e+00, tolerance: 3.256e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.575e+00, tolerance: 3.256e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.616e+00, tolerance: 3.256e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.578e+00, tolerance: 3.256e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.617e+00, tolerance: 3.256e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.580e+00, tolerance: 3.256e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.582e+00, tolerance: 3.256e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.619e+00, tolerance: 3.256e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.584e+00, tolerance: 3.256e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.619e+00, tolerance: 3.256e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.586e+00, tolerance: 3.256e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.620e+00, tolerance: 3.256e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.588e+00, tolerance: 3.256e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.620e+00, tolerance: 3.256e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.589e+00, tolerance: 3.256e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.621e+00, tolerance: 3.256e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.591e+00, tolerance: 3.256e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.621e+00, tolerance: 3.256e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.592e+00, tolerance: 3.256e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.622e+00, tolerance: 3.256e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.593e+00, tolerance: 3.256e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.622e+00, tolerance: 3.256e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.595e+00, tolerance: 3.256e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.622e+00, tolerance: 3.256e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 80}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 80
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 82}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 82
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 84}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 84
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 86}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 86
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 88}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 88
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 90}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 90
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 92}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 92
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 94}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 94
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 96}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 96
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 98}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 98
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 100
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of -0.5 cannot be evaluated. error: 0.0 cannot be raised to a negative power
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:Lambda value of 0 cannot be evaluated. error: Input X contains NaN.
ElasticNet does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of 0.5 cannot be evaluated. error: Input contains NaN.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.122e+10, tolerance: 6.236e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.815e+10, tolerance: 6.236e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.221e+10, tolerance: 6.236e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.075e+10, tolerance: 6.236e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.296e+10, tolerance: 6.236e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.238e+10, tolerance: 6.236e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.356e+10, tolerance: 6.236e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.354e+10, tolerance: 6.236e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.407e+10, tolerance: 6.236e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.442e+10, tolerance: 6.236e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.452e+10, tolerance: 6.236e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.511e+10, tolerance: 6.236e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.492e+10, tolerance: 6.236e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.567e+10, tolerance: 6.236e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.528e+10, tolerance: 6.236e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.614e+10, tolerance: 6.236e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.561e+10, tolerance: 6.236e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.653e+10, tolerance: 6.236e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.592e+10, tolerance: 6.236e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.687e+10, tolerance: 6.236e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.620e+10, tolerance: 6.236e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.716e+10, tolerance: 6.236e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.646e+10, tolerance: 6.236e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.741e+10, tolerance: 6.236e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.671e+10, tolerance: 6.236e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.763e+10, tolerance: 6.236e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.695e+10, tolerance: 6.236e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.783e+10, tolerance: 6.236e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.717e+10, tolerance: 6.236e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.801e+10, tolerance: 6.236e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.739e+10, tolerance: 6.236e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.817e+10, tolerance: 6.236e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.759e+10, tolerance: 6.236e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.831e+10, tolerance: 6.236e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.779e+10, tolerance: 6.236e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.844e+10, tolerance: 6.236e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.797e+10, tolerance: 6.236e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.856e+10, tolerance: 6.236e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.815e+10, tolerance: 6.236e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.867e+10, tolerance: 6.236e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 64}. error: Expected n_neighbors <= n_samples,  but n_samples = 63, n_neighbors = 64
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 66}. error: Expected n_neighbors <= n_samples,  but n_samples = 63, n_neighbors = 66
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 68}. error: Expected n_neighbors <= n_samples,  but n_samples = 63, n_neighbors = 68
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 70}. error: Expected n_neighbors <= n_samples,  but n_samples = 63, n_neighbors = 70
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 72}. error: Expected n_neighbors <= n_samples,  but n_samples = 63, n_neighbors = 72
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 74}. error: Expected n_neighbors <= n_samples,  but n_samples = 63, n_neighbors = 74
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 76}. error: Expected n_neighbors <= n_samples,  but n_samples = 63, n_neighbors = 76
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 78}. error: Expected n_neighbors <= n_samples,  but n_samples = 63, n_neighbors = 78
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 80}. error: Expected n_neighbors <= n_samples,  but n_samples = 63, n_neighbors = 80
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 82}. error: Expected n_neighbors <= n_samples,  but n_samples = 63, n_neighbors = 82
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 84}. error: Expected n_neighbors <= n_samples,  but n_samples = 63, n_neighbors = 84
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 86}. error: Expected n_neighbors <= n_samples,  but n_samples = 63, n_neighbors = 86
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 88}. error: Expected n_neighbors <= n_samples,  but n_samples = 63, n_neighbors = 88
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 90}. error: Expected n_neighbors <= n_samples,  but n_samples = 63, n_neighbors = 90
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 92}. error: Expected n_neighbors <= n_samples,  but n_samples = 63, n_neighbors = 92
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 94}. error: Expected n_neighbors <= n_samples,  but n_samples = 63, n_neighbors = 94
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 96}. error: Expected n_neighbors <= n_samples,  but n_samples = 63, n_neighbors = 96
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 98}. error: Expected n_neighbors <= n_samples,  but n_samples = 63, n_neighbors = 98
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: Expected n_neighbors <= n_samples,  but n_samples = 63, n_neighbors = 100
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.193e+06, tolerance: 2.270e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.144e+06, tolerance: 2.270e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.546e+06, tolerance: 2.270e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.180e+06, tolerance: 2.270e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.830e+06, tolerance: 2.270e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.783e+06, tolerance: 2.270e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.073e+06, tolerance: 2.270e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.187e+06, tolerance: 2.270e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.287e+06, tolerance: 2.270e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.479e+06, tolerance: 2.270e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.478e+06, tolerance: 2.270e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.700e+06, tolerance: 2.270e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.652e+06, tolerance: 2.270e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.874e+06, tolerance: 2.270e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.812e+06, tolerance: 2.270e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.001e+07, tolerance: 2.270e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.960e+06, tolerance: 2.270e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.013e+07, tolerance: 2.270e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.097e+06, tolerance: 2.270e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.023e+07, tolerance: 2.270e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.226e+06, tolerance: 2.270e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.031e+07, tolerance: 2.270e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.347e+06, tolerance: 2.270e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.038e+07, tolerance: 2.270e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.460e+06, tolerance: 2.270e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.044e+07, tolerance: 2.270e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.568e+06, tolerance: 2.270e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.050e+07, tolerance: 2.270e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.670e+06, tolerance: 2.270e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.055e+07, tolerance: 2.270e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.767e+06, tolerance: 2.270e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.059e+07, tolerance: 2.270e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.859e+06, tolerance: 2.270e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.063e+07, tolerance: 2.270e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.947e+06, tolerance: 2.270e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.066e+07, tolerance: 2.270e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.031e+06, tolerance: 2.270e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.070e+07, tolerance: 2.270e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.112e+06, tolerance: 2.270e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.073e+07, tolerance: 2.270e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of -0.5 cannot be evaluated. error: 0.0 cannot be raised to a negative power
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:Lambda value of 0 cannot be evaluated. error: Input X contains NaN.
ElasticNet does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of 0.5 cannot be evaluated. error: Input contains NaN.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.081e-01, tolerance: 1.503e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.249e-01, tolerance: 1.503e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.117e-01, tolerance: 1.503e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.330e-01, tolerance: 1.503e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.148e-01, tolerance: 1.503e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.374e-01, tolerance: 1.503e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.174e-01, tolerance: 1.503e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.400e-01, tolerance: 1.503e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.197e-01, tolerance: 1.503e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.418e-01, tolerance: 1.503e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.217e-01, tolerance: 1.503e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.432e-01, tolerance: 1.503e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.234e-01, tolerance: 1.503e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.441e-01, tolerance: 1.503e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.250e-01, tolerance: 1.503e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.449e-01, tolerance: 1.503e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.264e-01, tolerance: 1.503e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.456e-01, tolerance: 1.503e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.276e-01, tolerance: 1.503e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.461e-01, tolerance: 1.503e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.287e-01, tolerance: 1.503e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.465e-01, tolerance: 1.503e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.298e-01, tolerance: 1.503e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.469e-01, tolerance: 1.503e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.307e-01, tolerance: 1.503e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.472e-01, tolerance: 1.503e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.316e-01, tolerance: 1.503e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.475e-01, tolerance: 1.503e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.324e-01, tolerance: 1.503e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.477e-01, tolerance: 1.503e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.331e-01, tolerance: 1.503e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.479e-01, tolerance: 1.503e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.338e-01, tolerance: 1.503e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.481e-01, tolerance: 1.503e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.344e-01, tolerance: 1.503e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.350e-01, tolerance: 1.503e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.484e-01, tolerance: 1.503e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.355e-01, tolerance: 1.503e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.486e-01, tolerance: 1.503e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 80}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 80
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 82}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 82
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 84}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 84
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 86}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 86
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 88}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 88
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 90}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 90
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 92}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 92
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 94}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 94
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 96}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 96
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 98}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 98
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 100
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of -0.5 cannot be evaluated. error: 0.0 cannot be raised to a negative power
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:Lambda value of 0 cannot be evaluated. error: Input X contains NaN.
ElasticNet does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of 0.5 cannot be evaluated. error: Input contains NaN.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.645e+01, tolerance: 9.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.338e+01, tolerance: 9.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.755e+01, tolerance: 9.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.665e+01, tolerance: 9.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.846e+01, tolerance: 9.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.853e+01, tolerance: 9.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.925e+01, tolerance: 9.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.977e+01, tolerance: 9.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.995e+01, tolerance: 9.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.065e+01, tolerance: 9.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.058e+01, tolerance: 9.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.132e+01, tolerance: 9.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.116e+01, tolerance: 9.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.184e+01, tolerance: 9.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.168e+01, tolerance: 9.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.226e+01, tolerance: 9.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.217e+01, tolerance: 9.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.260e+01, tolerance: 9.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.262e+01, tolerance: 9.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.289e+01, tolerance: 9.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.304e+01, tolerance: 9.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.314e+01, tolerance: 9.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.344e+01, tolerance: 9.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.335e+01, tolerance: 9.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.380e+01, tolerance: 9.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.353e+01, tolerance: 9.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.415e+01, tolerance: 9.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.369e+01, tolerance: 9.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.447e+01, tolerance: 9.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.383e+01, tolerance: 9.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.478e+01, tolerance: 9.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.396e+01, tolerance: 9.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.507e+01, tolerance: 9.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.408e+01, tolerance: 9.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.535e+01, tolerance: 9.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.418e+01, tolerance: 9.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.561e+01, tolerance: 9.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.427e+01, tolerance: 9.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.585e+01, tolerance: 9.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.436e+01, tolerance: 9.238e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 79}. error: Expected n_neighbors <= n_samples,  but n_samples = 78, n_neighbors = 79
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 81}. error: Expected n_neighbors <= n_samples,  but n_samples = 78, n_neighbors = 81
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 83}. error: Expected n_neighbors <= n_samples,  but n_samples = 78, n_neighbors = 83
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 85}. error: Expected n_neighbors <= n_samples,  but n_samples = 78, n_neighbors = 85
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 87}. error: Expected n_neighbors <= n_samples,  but n_samples = 78, n_neighbors = 87
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 89}. error: Expected n_neighbors <= n_samples,  but n_samples = 78, n_neighbors = 89
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 91}. error: Expected n_neighbors <= n_samples,  but n_samples = 78, n_neighbors = 91
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 93}. error: Expected n_neighbors <= n_samples,  but n_samples = 78, n_neighbors = 93
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 95}. error: Expected n_neighbors <= n_samples,  but n_samples = 78, n_neighbors = 95
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 97}. error: Expected n_neighbors <= n_samples,  but n_samples = 78, n_neighbors = 97
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: Expected n_neighbors <= n_samples,  but n_samples = 78, n_neighbors = 99
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.410e+10, tolerance: 3.892e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.329e+11, tolerance: 3.892e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.881e+10, tolerance: 3.892e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.486e+11, tolerance: 3.892e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.024e+11, tolerance: 3.892e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.577e+11, tolerance: 3.892e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.053e+11, tolerance: 3.892e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.638e+11, tolerance: 3.892e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.078e+11, tolerance: 3.892e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.681e+11, tolerance: 3.892e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.100e+11, tolerance: 3.892e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.713e+11, tolerance: 3.892e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.120e+11, tolerance: 3.892e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.739e+11, tolerance: 3.892e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.139e+11, tolerance: 3.892e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.759e+11, tolerance: 3.892e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.156e+11, tolerance: 3.892e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.776e+11, tolerance: 3.892e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.172e+11, tolerance: 3.892e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.789e+11, tolerance: 3.892e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.187e+11, tolerance: 3.892e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.801e+11, tolerance: 3.892e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.201e+11, tolerance: 3.892e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.811e+11, tolerance: 3.892e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.214e+11, tolerance: 3.892e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.820e+11, tolerance: 3.892e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.227e+11, tolerance: 3.892e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.828e+11, tolerance: 3.892e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.239e+11, tolerance: 3.892e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.835e+11, tolerance: 3.892e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.251e+11, tolerance: 3.892e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.841e+11, tolerance: 3.892e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.262e+11, tolerance: 3.892e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.846e+11, tolerance: 3.892e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.272e+11, tolerance: 3.892e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.851e+11, tolerance: 3.892e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.283e+11, tolerance: 3.892e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.856e+11, tolerance: 3.892e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.292e+11, tolerance: 3.892e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.860e+11, tolerance: 3.892e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.000e+11, tolerance: 4.139e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.425e+11, tolerance: 5.009e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of -0.5 cannot be evaluated. error: 0.0 cannot be raised to a negative power
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:Lambda value of 0 cannot be evaluated. error: Input X contains NaN.
ElasticNet does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of 0.5 cannot be evaluated. error: Input contains NaN.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.369e+01, tolerance: 4.924e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.070e+01, tolerance: 4.924e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.460e+01, tolerance: 4.924e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.221e+01, tolerance: 4.924e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.532e+01, tolerance: 4.924e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.288e+01, tolerance: 4.924e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.592e+01, tolerance: 4.924e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.325e+01, tolerance: 4.924e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.643e+01, tolerance: 4.924e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.350e+01, tolerance: 4.924e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.687e+01, tolerance: 4.924e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.367e+01, tolerance: 4.924e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.727e+01, tolerance: 4.924e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.379e+01, tolerance: 4.924e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.762e+01, tolerance: 4.924e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.389e+01, tolerance: 4.924e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.794e+01, tolerance: 4.924e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.396e+01, tolerance: 4.924e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.822e+01, tolerance: 4.924e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.402e+01, tolerance: 4.924e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.849e+01, tolerance: 4.924e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.408e+01, tolerance: 4.924e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.872e+01, tolerance: 4.924e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.412e+01, tolerance: 4.924e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.895e+01, tolerance: 4.924e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.416e+01, tolerance: 4.924e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.915e+01, tolerance: 4.924e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.419e+01, tolerance: 4.924e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.934e+01, tolerance: 4.924e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.421e+01, tolerance: 4.924e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.951e+01, tolerance: 4.924e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.424e+01, tolerance: 4.924e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.968e+01, tolerance: 4.924e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.426e+01, tolerance: 4.924e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.983e+01, tolerance: 4.924e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.428e+01, tolerance: 4.924e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.997e+01, tolerance: 4.924e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.430e+01, tolerance: 4.924e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.011e+01, tolerance: 4.924e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.431e+01, tolerance: 4.924e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.129e+01, tolerance: 6.668e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.442e+01, tolerance: 9.589e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 58}. error: Expected n_neighbors <= n_samples,  but n_samples = 57, n_neighbors = 58
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 60}. error: Expected n_neighbors <= n_samples,  but n_samples = 57, n_neighbors = 60
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 62}. error: Expected n_neighbors <= n_samples,  but n_samples = 57, n_neighbors = 62
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 64}. error: Expected n_neighbors <= n_samples,  but n_samples = 57, n_neighbors = 64
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 66}. error: Expected n_neighbors <= n_samples,  but n_samples = 57, n_neighbors = 66
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 68}. error: Expected n_neighbors <= n_samples,  but n_samples = 57, n_neighbors = 68
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 70}. error: Expected n_neighbors <= n_samples,  but n_samples = 57, n_neighbors = 70
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 72}. error: Expected n_neighbors <= n_samples,  but n_samples = 57, n_neighbors = 72
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 74}. error: Expected n_neighbors <= n_samples,  but n_samples = 57, n_neighbors = 74
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 76}. error: Expected n_neighbors <= n_samples,  but n_samples = 57, n_neighbors = 76
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 78}. error: Expected n_neighbors <= n_samples,  but n_samples = 57, n_neighbors = 78
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 80}. error: Expected n_neighbors <= n_samples,  but n_samples = 57, n_neighbors = 80
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 82}. error: Expected n_neighbors <= n_samples,  but n_samples = 57, n_neighbors = 82
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 84}. error: Expected n_neighbors <= n_samples,  but n_samples = 57, n_neighbors = 84
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 86}. error: Expected n_neighbors <= n_samples,  but n_samples = 57, n_neighbors = 86
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 88}. error: Expected n_neighbors <= n_samples,  but n_samples = 57, n_neighbors = 88
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 90}. error: Expected n_neighbors <= n_samples,  but n_samples = 57, n_neighbors = 90
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 92}. error: Expected n_neighbors <= n_samples,  but n_samples = 57, n_neighbors = 92
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 94}. error: Expected n_neighbors <= n_samples,  but n_samples = 57, n_neighbors = 94
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 96}. error: Expected n_neighbors <= n_samples,  but n_samples = 57, n_neighbors = 96
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 98}. error: Expected n_neighbors <= n_samples,  but n_samples = 57, n_neighbors = 98
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: Expected n_neighbors <= n_samples,  but n_samples = 57, n_neighbors = 100
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of -0.5 cannot be evaluated. error: 0.0 cannot be raised to a negative power
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:Lambda value of 0 cannot be evaluated. error: Input X contains NaN.
ElasticNet does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of 0.5 cannot be evaluated. error: Input contains NaN.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.810e+01, tolerance: 6.015e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.948e+01, tolerance: 6.015e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.864e+01, tolerance: 6.015e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.970e+01, tolerance: 6.015e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.894e+01, tolerance: 6.015e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.979e+01, tolerance: 6.015e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.912e+01, tolerance: 6.015e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.985e+01, tolerance: 6.015e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.924e+01, tolerance: 6.015e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.988e+01, tolerance: 6.015e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.933e+01, tolerance: 6.015e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.991e+01, tolerance: 6.015e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.941e+01, tolerance: 6.015e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.993e+01, tolerance: 6.015e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.946e+01, tolerance: 6.015e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.994e+01, tolerance: 6.015e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.951e+01, tolerance: 6.015e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.996e+01, tolerance: 6.015e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.955e+01, tolerance: 6.015e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.997e+01, tolerance: 6.015e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.958e+01, tolerance: 6.015e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.997e+01, tolerance: 6.015e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.961e+01, tolerance: 6.015e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.998e+01, tolerance: 6.015e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.963e+01, tolerance: 6.015e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.999e+01, tolerance: 6.015e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.966e+01, tolerance: 6.015e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.999e+01, tolerance: 6.015e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.968e+01, tolerance: 6.015e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.000e+01, tolerance: 6.015e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.969e+01, tolerance: 6.015e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.000e+01, tolerance: 6.015e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.971e+01, tolerance: 6.015e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.001e+01, tolerance: 6.015e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.972e+01, tolerance: 6.015e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.001e+01, tolerance: 6.015e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.974e+01, tolerance: 6.015e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.001e+01, tolerance: 6.015e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.975e+01, tolerance: 6.015e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.002e+01, tolerance: 6.015e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 80}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 80
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 82}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 82
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 84}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 84
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 86}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 86
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 88}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 88
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 90}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 90
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 92}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 92
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 94}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 94
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 96}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 96
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 98}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 98
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 100
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of -0.5 cannot be evaluated. error: 0.0 cannot be raised to a negative power
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:Lambda value of 0 cannot be evaluated. error: Input X contains NaN.
ElasticNet does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of 0.5 cannot be evaluated. error: Input contains NaN.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.983e+11, tolerance: 3.028e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.025e+12, tolerance: 3.028e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.479e+11, tolerance: 3.028e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.134e+12, tolerance: 3.028e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.848e+11, tolerance: 3.028e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.199e+12, tolerance: 3.028e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.149e+11, tolerance: 3.028e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.243e+12, tolerance: 3.028e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.406e+11, tolerance: 3.028e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.276e+12, tolerance: 3.028e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.633e+11, tolerance: 3.028e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.301e+12, tolerance: 3.028e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.835e+11, tolerance: 3.028e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.321e+12, tolerance: 3.028e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.018e+11, tolerance: 3.028e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.338e+12, tolerance: 3.028e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.185e+11, tolerance: 3.028e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.352e+12, tolerance: 3.028e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.340e+11, tolerance: 3.028e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.364e+12, tolerance: 3.028e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.483e+11, tolerance: 3.028e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.374e+12, tolerance: 3.028e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.616e+11, tolerance: 3.028e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.383e+12, tolerance: 3.028e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.742e+11, tolerance: 3.028e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.391e+12, tolerance: 3.028e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.860e+11, tolerance: 3.028e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.398e+12, tolerance: 3.028e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.971e+11, tolerance: 3.028e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.404e+12, tolerance: 3.028e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.008e+12, tolerance: 3.028e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.410e+12, tolerance: 3.028e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.018e+12, tolerance: 3.028e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.415e+12, tolerance: 3.028e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.027e+12, tolerance: 3.028e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.420e+12, tolerance: 3.028e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.036e+12, tolerance: 3.028e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.424e+12, tolerance: 3.028e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.045e+12, tolerance: 3.028e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.427e+12, tolerance: 3.028e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of -0.5 cannot be evaluated. error: 0.0 cannot be raised to a negative power
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:Lambda value of 0 cannot be evaluated. error: test_size=25 should be either positive and smaller than the number of samples 24 or a float in the (0, 1) range
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of 0.5 cannot be evaluated. error: Input contains NaN.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.138e+11, tolerance: 4.120e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.650e+11, tolerance: 4.120e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.209e+11, tolerance: 4.120e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.788e+11, tolerance: 4.120e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.265e+11, tolerance: 4.120e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.855e+11, tolerance: 4.120e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.312e+11, tolerance: 4.120e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.895e+11, tolerance: 4.120e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.352e+11, tolerance: 4.120e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.922e+11, tolerance: 4.120e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.387e+11, tolerance: 4.120e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.942e+11, tolerance: 4.120e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.417e+11, tolerance: 4.120e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.956e+11, tolerance: 4.120e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.444e+11, tolerance: 4.120e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.967e+11, tolerance: 4.120e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.469e+11, tolerance: 4.120e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.977e+11, tolerance: 4.120e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.491e+11, tolerance: 4.120e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.984e+11, tolerance: 4.120e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.511e+11, tolerance: 4.120e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.990e+11, tolerance: 4.120e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.530e+11, tolerance: 4.120e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.996e+11, tolerance: 4.120e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.547e+11, tolerance: 4.120e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.000e+11, tolerance: 4.120e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.563e+11, tolerance: 4.120e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.004e+11, tolerance: 4.120e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.578e+11, tolerance: 4.120e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.007e+11, tolerance: 4.120e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.592e+11, tolerance: 4.120e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.011e+11, tolerance: 4.120e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.605e+11, tolerance: 4.120e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.013e+11, tolerance: 4.120e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.617e+11, tolerance: 4.120e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.016e+11, tolerance: 4.120e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.628e+11, tolerance: 4.120e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.018e+11, tolerance: 4.120e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.639e+11, tolerance: 4.120e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.020e+11, tolerance: 4.120e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 60}. error: Expected n_neighbors <= n_samples,  but n_samples = 59, n_neighbors = 60
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 62}. error: Expected n_neighbors <= n_samples,  but n_samples = 59, n_neighbors = 62
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 64}. error: Expected n_neighbors <= n_samples,  but n_samples = 59, n_neighbors = 64
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 66}. error: Expected n_neighbors <= n_samples,  but n_samples = 59, n_neighbors = 66
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 68}. error: Expected n_neighbors <= n_samples,  but n_samples = 59, n_neighbors = 68
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 70}. error: Expected n_neighbors <= n_samples,  but n_samples = 59, n_neighbors = 70
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 72}. error: Expected n_neighbors <= n_samples,  but n_samples = 59, n_neighbors = 72
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 74}. error: Expected n_neighbors <= n_samples,  but n_samples = 59, n_neighbors = 74
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 76}. error: Expected n_neighbors <= n_samples,  but n_samples = 59, n_neighbors = 76
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 78}. error: Expected n_neighbors <= n_samples,  but n_samples = 59, n_neighbors = 78
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 80}. error: Expected n_neighbors <= n_samples,  but n_samples = 59, n_neighbors = 80
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 82}. error: Expected n_neighbors <= n_samples,  but n_samples = 59, n_neighbors = 82
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 84}. error: Expected n_neighbors <= n_samples,  but n_samples = 59, n_neighbors = 84
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 86}. error: Expected n_neighbors <= n_samples,  but n_samples = 59, n_neighbors = 86
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 88}. error: Expected n_neighbors <= n_samples,  but n_samples = 59, n_neighbors = 88
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 90}. error: Expected n_neighbors <= n_samples,  but n_samples = 59, n_neighbors = 90
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 92}. error: Expected n_neighbors <= n_samples,  but n_samples = 59, n_neighbors = 92
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 94}. error: Expected n_neighbors <= n_samples,  but n_samples = 59, n_neighbors = 94
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 96}. error: Expected n_neighbors <= n_samples,  but n_samples = 59, n_neighbors = 96
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 98}. error: Expected n_neighbors <= n_samples,  but n_samples = 59, n_neighbors = 98
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: Expected n_neighbors <= n_samples,  but n_samples = 59, n_neighbors = 100
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of -0.5 cannot be evaluated. error: 0.0 cannot be raised to a negative power
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:Lambda value of 0 cannot be evaluated. error: test_size=25 should be either positive and smaller than the number of samples 16 or a float in the (0, 1) range
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of 0.5 cannot be evaluated. error: Input contains NaN.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.391e+00, tolerance: 2.978e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.429e+00, tolerance: 2.978e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.400e+00, tolerance: 2.978e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.447e+00, tolerance: 2.978e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.406e+00, tolerance: 2.978e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.457e+00, tolerance: 2.978e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.412e+00, tolerance: 2.978e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.463e+00, tolerance: 2.978e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.417e+00, tolerance: 2.978e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.467e+00, tolerance: 2.978e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.422e+00, tolerance: 2.978e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.470e+00, tolerance: 2.978e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.426e+00, tolerance: 2.978e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.429e+00, tolerance: 2.978e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.432e+00, tolerance: 2.978e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.476e+00, tolerance: 2.978e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.435e+00, tolerance: 2.978e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.438e+00, tolerance: 2.978e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.478e+00, tolerance: 2.978e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.440e+00, tolerance: 2.978e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.479e+00, tolerance: 2.978e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.442e+00, tolerance: 2.978e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.479e+00, tolerance: 2.978e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.480e+00, tolerance: 2.978e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.446e+00, tolerance: 2.978e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.480e+00, tolerance: 2.978e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.447e+00, tolerance: 2.978e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.481e+00, tolerance: 2.978e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.449e+00, tolerance: 2.978e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.481e+00, tolerance: 2.978e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.450e+00, tolerance: 2.978e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.482e+00, tolerance: 2.978e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.452e+00, tolerance: 2.978e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.482e+00, tolerance: 2.978e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.453e+00, tolerance: 2.978e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.482e+00, tolerance: 2.978e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.410e+00, tolerance: 3.041e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.584e+00, tolerance: 3.284e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 80}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 80
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 82}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 82
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 84}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 84
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 86}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 86
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 88}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 88
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 90}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 90
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 92}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 92
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 94}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 94
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 96}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 96
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 98}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 98
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 100
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of -0.5 cannot be evaluated. error: 0.0 cannot be raised to a negative power
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:Lambda value of 0 cannot be evaluated. error: test_size=25 should be either positive and smaller than the number of samples 21 or a float in the (0, 1) range
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of 0.5 cannot be evaluated. error: Input contains NaN.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.892e+12, tolerance: 1.764e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.619e+12, tolerance: 1.764e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.071e+12, tolerance: 1.764e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.047e+12, tolerance: 1.764e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.223e+12, tolerance: 1.764e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.248e+12, tolerance: 1.764e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.354e+12, tolerance: 1.764e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.366e+12, tolerance: 1.764e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.470e+12, tolerance: 1.764e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.444e+12, tolerance: 1.764e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.573e+12, tolerance: 1.764e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.499e+12, tolerance: 1.764e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.665e+12, tolerance: 1.764e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.540e+12, tolerance: 1.764e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.749e+12, tolerance: 1.764e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.571e+12, tolerance: 1.764e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.825e+12, tolerance: 1.764e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.597e+12, tolerance: 1.764e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.895e+12, tolerance: 1.764e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.617e+12, tolerance: 1.764e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.960e+12, tolerance: 1.764e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.635e+12, tolerance: 1.764e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.020e+12, tolerance: 1.764e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.649e+12, tolerance: 1.764e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.075e+12, tolerance: 1.764e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.661e+12, tolerance: 1.764e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.127e+12, tolerance: 1.764e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.672e+12, tolerance: 1.764e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.176e+12, tolerance: 1.764e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.682e+12, tolerance: 1.764e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.221e+12, tolerance: 1.764e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.690e+12, tolerance: 1.764e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.264e+12, tolerance: 1.764e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.697e+12, tolerance: 1.764e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.305e+12, tolerance: 1.764e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.704e+12, tolerance: 1.764e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.343e+12, tolerance: 1.764e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.710e+12, tolerance: 1.764e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.379e+12, tolerance: 1.764e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.715e+12, tolerance: 1.764e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 71}. error: Expected n_neighbors <= n_samples,  but n_samples = 70, n_neighbors = 71
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 73}. error: Expected n_neighbors <= n_samples,  but n_samples = 70, n_neighbors = 73
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 75}. error: Expected n_neighbors <= n_samples,  but n_samples = 70, n_neighbors = 75
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 77}. error: Expected n_neighbors <= n_samples,  but n_samples = 70, n_neighbors = 77
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 79}. error: Expected n_neighbors <= n_samples,  but n_samples = 70, n_neighbors = 79
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 81}. error: Expected n_neighbors <= n_samples,  but n_samples = 70, n_neighbors = 81
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 83}. error: Expected n_neighbors <= n_samples,  but n_samples = 70, n_neighbors = 83
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 85}. error: Expected n_neighbors <= n_samples,  but n_samples = 70, n_neighbors = 85
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 87}. error: Expected n_neighbors <= n_samples,  but n_samples = 70, n_neighbors = 87
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 89}. error: Expected n_neighbors <= n_samples,  but n_samples = 70, n_neighbors = 89
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 91}. error: Expected n_neighbors <= n_samples,  but n_samples = 70, n_neighbors = 91
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 93}. error: Expected n_neighbors <= n_samples,  but n_samples = 70, n_neighbors = 93
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 95}. error: Expected n_neighbors <= n_samples,  but n_samples = 70, n_neighbors = 95
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 97}. error: Expected n_neighbors <= n_samples,  but n_samples = 70, n_neighbors = 97
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: Expected n_neighbors <= n_samples,  but n_samples = 70, n_neighbors = 99
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of -0.5 cannot be evaluated. error: 0.0 cannot be raised to a negative power
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:Lambda value of 0 cannot be evaluated. error: Input X contains NaN.
ElasticNet does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of 0.5 cannot be evaluated. error: Input contains NaN.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.432e+10, tolerance: 1.686e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.074e+10, tolerance: 1.686e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.679e+10, tolerance: 1.686e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.697e+10, tolerance: 1.686e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.870e+10, tolerance: 1.686e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.094e+10, tolerance: 1.686e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.027e+10, tolerance: 1.686e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.381e+10, tolerance: 1.686e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.162e+10, tolerance: 1.686e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.602e+10, tolerance: 1.686e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.280e+10, tolerance: 1.686e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.778e+10, tolerance: 1.686e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.387e+10, tolerance: 1.686e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.922e+10, tolerance: 1.686e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.483e+10, tolerance: 1.686e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.042e+10, tolerance: 1.686e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.571e+10, tolerance: 1.686e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.144e+10, tolerance: 1.686e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.652e+10, tolerance: 1.686e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.232e+10, tolerance: 1.686e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.728e+10, tolerance: 1.686e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.309e+10, tolerance: 1.686e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.799e+10, tolerance: 1.686e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.376e+10, tolerance: 1.686e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.866e+10, tolerance: 1.686e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.436e+10, tolerance: 1.686e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.929e+10, tolerance: 1.686e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.489e+10, tolerance: 1.686e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.988e+10, tolerance: 1.686e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.537e+10, tolerance: 1.686e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.045e+10, tolerance: 1.686e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.580e+10, tolerance: 1.686e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.098e+10, tolerance: 1.686e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.619e+10, tolerance: 1.686e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.150e+10, tolerance: 1.686e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.655e+10, tolerance: 1.686e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.199e+10, tolerance: 1.686e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.687e+10, tolerance: 1.686e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.246e+10, tolerance: 1.686e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.717e+10, tolerance: 1.686e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of -0.5 cannot be evaluated. error: 0.0 cannot be raised to a negative power
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:Lambda value of 0 cannot be evaluated. error: test_size=25 should be either positive and smaller than the number of samples 14 or a float in the (0, 1) range
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of 0.5 cannot be evaluated. error: Input contains NaN.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.125e+11, tolerance: 3.986e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.456e+11, tolerance: 3.986e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.170e+11, tolerance: 3.986e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.568e+11, tolerance: 3.986e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.207e+11, tolerance: 3.986e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.636e+11, tolerance: 3.986e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.238e+11, tolerance: 3.986e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.684e+11, tolerance: 3.986e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.265e+11, tolerance: 3.986e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.720e+11, tolerance: 3.986e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.289e+11, tolerance: 3.986e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.748e+11, tolerance: 3.986e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.310e+11, tolerance: 3.986e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.771e+11, tolerance: 3.986e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.329e+11, tolerance: 3.986e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.790e+11, tolerance: 3.986e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.347e+11, tolerance: 3.986e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.805e+11, tolerance: 3.986e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.363e+11, tolerance: 3.986e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.819e+11, tolerance: 3.986e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.378e+11, tolerance: 3.986e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.831e+11, tolerance: 3.986e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.392e+11, tolerance: 3.986e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.841e+11, tolerance: 3.986e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.405e+11, tolerance: 3.986e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.850e+11, tolerance: 3.986e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.418e+11, tolerance: 3.986e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.858e+11, tolerance: 3.986e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.429e+11, tolerance: 3.986e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.865e+11, tolerance: 3.986e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.440e+11, tolerance: 3.986e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.871e+11, tolerance: 3.986e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.451e+11, tolerance: 3.986e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.877e+11, tolerance: 3.986e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.461e+11, tolerance: 3.986e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.882e+11, tolerance: 3.986e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.470e+11, tolerance: 3.986e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.887e+11, tolerance: 3.986e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.479e+11, tolerance: 3.986e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.892e+11, tolerance: 3.986e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of -0.5 cannot be evaluated. error: 0.0 cannot be raised to a negative power
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:Lambda value of 0 cannot be evaluated. error: Input X contains NaN.
ElasticNet does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of 0.5 cannot be evaluated. error: Input contains NaN.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.524e+01, tolerance: 5.781e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.722e+01, tolerance: 5.781e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.596e+01, tolerance: 5.781e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.768e+01, tolerance: 5.781e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.636e+01, tolerance: 5.781e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.792e+01, tolerance: 5.781e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.662e+01, tolerance: 5.781e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.808e+01, tolerance: 5.781e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.681e+01, tolerance: 5.781e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.819e+01, tolerance: 5.781e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.696e+01, tolerance: 5.781e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.827e+01, tolerance: 5.781e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.708e+01, tolerance: 5.781e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.834e+01, tolerance: 5.781e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+01, tolerance: 5.781e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.839e+01, tolerance: 5.781e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.726e+01, tolerance: 5.781e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.843e+01, tolerance: 5.781e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.733e+01, tolerance: 5.781e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.847e+01, tolerance: 5.781e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.740e+01, tolerance: 5.781e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.850e+01, tolerance: 5.781e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.745e+01, tolerance: 5.781e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.853e+01, tolerance: 5.781e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.751e+01, tolerance: 5.781e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.855e+01, tolerance: 5.781e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.755e+01, tolerance: 5.781e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.857e+01, tolerance: 5.781e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.760e+01, tolerance: 5.781e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.859e+01, tolerance: 5.781e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.764e+01, tolerance: 5.781e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.861e+01, tolerance: 5.781e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.767e+01, tolerance: 5.781e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.862e+01, tolerance: 5.781e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+01, tolerance: 5.781e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.864e+01, tolerance: 5.781e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.774e+01, tolerance: 5.781e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.865e+01, tolerance: 5.781e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.777e+01, tolerance: 5.781e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.866e+01, tolerance: 5.781e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.595e+01, tolerance: 7.976e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.393e+01, tolerance: 1.170e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 80}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 80
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 82}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 82
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 84}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 84
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 86}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 86
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 88}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 88
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 90}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 90
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 92}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 92
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 94}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 94
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 96}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 96
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 98}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 98
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 100
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of -0.5 cannot be evaluated. error: 0.0 cannot be raised to a negative power
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:Lambda value of 0 cannot be evaluated. error: Input X contains NaN.
ElasticNet does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of 0.5 cannot be evaluated. error: Input contains NaN.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.651e+01, tolerance: 7.867e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.717e+01, tolerance: 7.867e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.664e+01, tolerance: 7.867e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.759e+01, tolerance: 7.867e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.675e+01, tolerance: 7.867e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.787e+01, tolerance: 7.867e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.684e+01, tolerance: 7.867e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.807e+01, tolerance: 7.867e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.692e+01, tolerance: 7.867e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.823e+01, tolerance: 7.867e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.699e+01, tolerance: 7.867e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.835e+01, tolerance: 7.867e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.706e+01, tolerance: 7.867e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.844e+01, tolerance: 7.867e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.713e+01, tolerance: 7.867e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.852e+01, tolerance: 7.867e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.719e+01, tolerance: 7.867e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.859e+01, tolerance: 7.867e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.725e+01, tolerance: 7.867e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.865e+01, tolerance: 7.867e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.730e+01, tolerance: 7.867e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.870e+01, tolerance: 7.867e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.736e+01, tolerance: 7.867e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.874e+01, tolerance: 7.867e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.740e+01, tolerance: 7.867e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.877e+01, tolerance: 7.867e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.745e+01, tolerance: 7.867e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.881e+01, tolerance: 7.867e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.750e+01, tolerance: 7.867e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.884e+01, tolerance: 7.867e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.754e+01, tolerance: 7.867e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.886e+01, tolerance: 7.867e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.758e+01, tolerance: 7.867e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.889e+01, tolerance: 7.867e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.762e+01, tolerance: 7.867e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.891e+01, tolerance: 7.867e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.765e+01, tolerance: 7.867e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.893e+01, tolerance: 7.867e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.769e+01, tolerance: 7.867e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.894e+01, tolerance: 7.867e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.947e+01, tolerance: 9.125e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.147e+01, tolerance: 1.170e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 80}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 80
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 82}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 82
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 84}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 84
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 86}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 86
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 88}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 88
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 90}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 90
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 92}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 92
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 94}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 94
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 96}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 96
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 98}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 98
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 100
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of -0.5 cannot be evaluated. error: 0.0 cannot be raised to a negative power
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:Lambda value of 0 cannot be evaluated. error: test_size=25 should be either positive and smaller than the number of samples 16 or a float in the (0, 1) range
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of 0.5 cannot be evaluated. error: Input contains NaN.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.073e+11, tolerance: 3.348e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.340e+11, tolerance: 3.348e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.113e+11, tolerance: 3.348e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.415e+11, tolerance: 3.348e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.145e+11, tolerance: 3.348e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.458e+11, tolerance: 3.348e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.171e+11, tolerance: 3.348e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.488e+11, tolerance: 3.348e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.193e+11, tolerance: 3.348e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.510e+11, tolerance: 3.348e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.212e+11, tolerance: 3.348e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.527e+11, tolerance: 3.348e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.230e+11, tolerance: 3.348e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.541e+11, tolerance: 3.348e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.245e+11, tolerance: 3.348e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.552e+11, tolerance: 3.348e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.259e+11, tolerance: 3.348e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.562e+11, tolerance: 3.348e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.272e+11, tolerance: 3.348e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.570e+11, tolerance: 3.348e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.283e+11, tolerance: 3.348e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.577e+11, tolerance: 3.348e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.294e+11, tolerance: 3.348e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.583e+11, tolerance: 3.348e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.304e+11, tolerance: 3.348e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.589e+11, tolerance: 3.348e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.313e+11, tolerance: 3.348e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.593e+11, tolerance: 3.348e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.322e+11, tolerance: 3.348e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.598e+11, tolerance: 3.348e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.330e+11, tolerance: 3.348e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.602e+11, tolerance: 3.348e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.338e+11, tolerance: 3.348e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.605e+11, tolerance: 3.348e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.345e+11, tolerance: 3.348e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.608e+11, tolerance: 3.348e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.352e+11, tolerance: 3.348e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.611e+11, tolerance: 3.348e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.359e+11, tolerance: 3.348e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.614e+11, tolerance: 3.348e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.157e+05, tolerance: 5.496e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.565e+05, tolerance: 5.496e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.204e+05, tolerance: 5.496e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.638e+05, tolerance: 5.496e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.243e+05, tolerance: 5.496e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.670e+05, tolerance: 5.496e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.275e+05, tolerance: 5.496e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.687e+05, tolerance: 5.496e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.303e+05, tolerance: 5.496e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.698e+05, tolerance: 5.496e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.327e+05, tolerance: 5.496e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.706e+05, tolerance: 5.496e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.349e+05, tolerance: 5.496e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.711e+05, tolerance: 5.496e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.368e+05, tolerance: 5.496e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.716e+05, tolerance: 5.496e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.385e+05, tolerance: 5.496e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.719e+05, tolerance: 5.496e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.401e+05, tolerance: 5.496e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.722e+05, tolerance: 5.496e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.415e+05, tolerance: 5.496e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.724e+05, tolerance: 5.496e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.428e+05, tolerance: 5.496e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.726e+05, tolerance: 5.496e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.440e+05, tolerance: 5.496e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.728e+05, tolerance: 5.496e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.451e+05, tolerance: 5.496e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.729e+05, tolerance: 5.496e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.461e+05, tolerance: 5.496e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.730e+05, tolerance: 5.496e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.471e+05, tolerance: 5.496e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.731e+05, tolerance: 5.496e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.479e+05, tolerance: 5.496e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.732e+05, tolerance: 5.496e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.488e+05, tolerance: 5.496e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.733e+05, tolerance: 5.496e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.495e+05, tolerance: 5.496e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.734e+05, tolerance: 5.496e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.503e+05, tolerance: 5.496e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.735e+05, tolerance: 5.496e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 66}. error: Expected n_neighbors <= n_samples,  but n_samples = 65, n_neighbors = 66
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 68}. error: Expected n_neighbors <= n_samples,  but n_samples = 65, n_neighbors = 68
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 70}. error: Expected n_neighbors <= n_samples,  but n_samples = 65, n_neighbors = 70
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 72}. error: Expected n_neighbors <= n_samples,  but n_samples = 65, n_neighbors = 72
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 74}. error: Expected n_neighbors <= n_samples,  but n_samples = 65, n_neighbors = 74
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 76}. error: Expected n_neighbors <= n_samples,  but n_samples = 65, n_neighbors = 76
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 78}. error: Expected n_neighbors <= n_samples,  but n_samples = 65, n_neighbors = 78
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 80}. error: Expected n_neighbors <= n_samples,  but n_samples = 65, n_neighbors = 80
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 82}. error: Expected n_neighbors <= n_samples,  but n_samples = 65, n_neighbors = 82
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 84}. error: Expected n_neighbors <= n_samples,  but n_samples = 65, n_neighbors = 84
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 86}. error: Expected n_neighbors <= n_samples,  but n_samples = 65, n_neighbors = 86
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 88}. error: Expected n_neighbors <= n_samples,  but n_samples = 65, n_neighbors = 88
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 90}. error: Expected n_neighbors <= n_samples,  but n_samples = 65, n_neighbors = 90
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 92}. error: Expected n_neighbors <= n_samples,  but n_samples = 65, n_neighbors = 92
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 94}. error: Expected n_neighbors <= n_samples,  but n_samples = 65, n_neighbors = 94
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 96}. error: Expected n_neighbors <= n_samples,  but n_samples = 65, n_neighbors = 96
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 98}. error: Expected n_neighbors <= n_samples,  but n_samples = 65, n_neighbors = 98
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: Expected n_neighbors <= n_samples,  but n_samples = 65, n_neighbors = 100
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of -0.5 cannot be evaluated. error: 0.0 cannot be raised to a negative power
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:Lambda value of 0 cannot be evaluated. error: Input X contains NaN.
ElasticNet does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of 0.5 cannot be evaluated. error: Input contains NaN.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.334e+12, tolerance: 3.909e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.266e+13, tolerance: 3.909e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.143e+12, tolerance: 3.909e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.435e+13, tolerance: 3.909e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.734e+12, tolerance: 3.909e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.533e+13, tolerance: 3.909e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.214e+12, tolerance: 3.909e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.598e+13, tolerance: 3.909e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.622e+12, tolerance: 3.909e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.646e+13, tolerance: 3.909e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.980e+12, tolerance: 3.909e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.682e+13, tolerance: 3.909e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.030e+13, tolerance: 3.909e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.711e+13, tolerance: 3.909e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.059e+13, tolerance: 3.909e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.734e+13, tolerance: 3.909e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.085e+13, tolerance: 3.909e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.753e+13, tolerance: 3.909e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.110e+13, tolerance: 3.909e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.769e+13, tolerance: 3.909e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.132e+13, tolerance: 3.909e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.782e+13, tolerance: 3.909e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.153e+13, tolerance: 3.909e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.794e+13, tolerance: 3.909e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.173e+13, tolerance: 3.909e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.804e+13, tolerance: 3.909e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.192e+13, tolerance: 3.909e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.813e+13, tolerance: 3.909e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.209e+13, tolerance: 3.909e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.821e+13, tolerance: 3.909e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.226e+13, tolerance: 3.909e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.828e+13, tolerance: 3.909e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.241e+13, tolerance: 3.909e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.835e+13, tolerance: 3.909e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.256e+13, tolerance: 3.909e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.840e+13, tolerance: 3.909e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.270e+13, tolerance: 3.909e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.846e+13, tolerance: 3.909e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.284e+13, tolerance: 3.909e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.850e+13, tolerance: 3.909e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of -0.5 cannot be evaluated. error: 0.0 cannot be raised to a negative power
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:Lambda value of 0 cannot be evaluated. error: Input X contains NaN.
ElasticNet does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of 0.5 cannot be evaluated. error: Input contains NaN.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.877e+09, tolerance: 1.463e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.482e+09, tolerance: 1.463e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.694e+08, tolerance: 1.463e+06
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.528e+07, tolerance: 1.463e+06
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.171e+09, tolerance: 1.463e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.754e+09, tolerance: 1.463e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.661e+08, tolerance: 1.463e+06
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.707e+07, tolerance: 1.463e+06
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.378e+09, tolerance: 1.463e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.883e+09, tolerance: 1.463e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.357e+07, tolerance: 1.463e+06
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.241e+07, tolerance: 1.463e+06
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.536e+09, tolerance: 1.463e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.961e+09, tolerance: 1.463e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.991e+07, tolerance: 1.463e+06
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.046e+06, tolerance: 1.463e+06
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.662e+09, tolerance: 1.463e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.014e+09, tolerance: 1.463e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.300e+07, tolerance: 1.463e+06
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.519e+06, tolerance: 1.463e+06
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.766e+09, tolerance: 1.463e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.053e+09, tolerance: 1.463e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.336e+07, tolerance: 1.463e+06
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.142e+06, tolerance: 1.463e+06
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.855e+09, tolerance: 1.463e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.082e+09, tolerance: 1.463e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.735e+07, tolerance: 1.463e+06
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.313e+06, tolerance: 1.463e+06
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.931e+09, tolerance: 1.463e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.106e+09, tolerance: 1.463e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.336e+07, tolerance: 1.463e+06
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.778e+06, tolerance: 1.463e+06
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.997e+09, tolerance: 1.463e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.125e+09, tolerance: 1.463e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.059e+07, tolerance: 1.463e+06
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.056e+09, tolerance: 1.463e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.141e+09, tolerance: 1.463e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.580e+06, tolerance: 1.463e+06
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.109e+09, tolerance: 1.463e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.154e+09, tolerance: 1.463e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.083e+06, tolerance: 1.463e+06
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.157e+09, tolerance: 1.463e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.165e+09, tolerance: 1.463e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.939e+06, tolerance: 1.463e+06
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.200e+09, tolerance: 1.463e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.175e+09, tolerance: 1.463e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.046e+06, tolerance: 1.463e+06
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.240e+09, tolerance: 1.463e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.184e+09, tolerance: 1.463e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.336e+06, tolerance: 1.463e+06
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.276e+09, tolerance: 1.463e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.191e+09, tolerance: 1.463e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.763e+06, tolerance: 1.463e+06
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.309e+09, tolerance: 1.463e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.198e+09, tolerance: 1.463e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.294e+06, tolerance: 1.463e+06
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.341e+09, tolerance: 1.463e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.204e+09, tolerance: 1.463e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.905e+06, tolerance: 1.463e+06
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.369e+09, tolerance: 1.463e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.210e+09, tolerance: 1.463e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.580e+06, tolerance: 1.463e+06
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.396e+09, tolerance: 1.463e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.215e+09, tolerance: 1.463e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.307e+06, tolerance: 1.463e+06
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.422e+09, tolerance: 1.463e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.219e+09, tolerance: 1.463e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.073e+06, tolerance: 1.463e+06
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.567e+09, tolerance: 1.728e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.428e+10, tolerance: 2.873e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 56}. error: Expected n_neighbors <= n_samples,  but n_samples = 55, n_neighbors = 56
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 58}. error: Expected n_neighbors <= n_samples,  but n_samples = 55, n_neighbors = 58
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 60}. error: Expected n_neighbors <= n_samples,  but n_samples = 55, n_neighbors = 60
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 62}. error: Expected n_neighbors <= n_samples,  but n_samples = 55, n_neighbors = 62
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 64}. error: Expected n_neighbors <= n_samples,  but n_samples = 55, n_neighbors = 64
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 66}. error: Expected n_neighbors <= n_samples,  but n_samples = 55, n_neighbors = 66
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 68}. error: Expected n_neighbors <= n_samples,  but n_samples = 55, n_neighbors = 68
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 70}. error: Expected n_neighbors <= n_samples,  but n_samples = 55, n_neighbors = 70
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 72}. error: Expected n_neighbors <= n_samples,  but n_samples = 55, n_neighbors = 72
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 74}. error: Expected n_neighbors <= n_samples,  but n_samples = 55, n_neighbors = 74
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 76}. error: Expected n_neighbors <= n_samples,  but n_samples = 55, n_neighbors = 76
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 78}. error: Expected n_neighbors <= n_samples,  but n_samples = 55, n_neighbors = 78
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 80}. error: Expected n_neighbors <= n_samples,  but n_samples = 55, n_neighbors = 80
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 82}. error: Expected n_neighbors <= n_samples,  but n_samples = 55, n_neighbors = 82
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 84}. error: Expected n_neighbors <= n_samples,  but n_samples = 55, n_neighbors = 84
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 86}. error: Expected n_neighbors <= n_samples,  but n_samples = 55, n_neighbors = 86
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 88}. error: Expected n_neighbors <= n_samples,  but n_samples = 55, n_neighbors = 88
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 90}. error: Expected n_neighbors <= n_samples,  but n_samples = 55, n_neighbors = 90
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 92}. error: Expected n_neighbors <= n_samples,  but n_samples = 55, n_neighbors = 92
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 94}. error: Expected n_neighbors <= n_samples,  but n_samples = 55, n_neighbors = 94
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 96}. error: Expected n_neighbors <= n_samples,  but n_samples = 55, n_neighbors = 96
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 98}. error: Expected n_neighbors <= n_samples,  but n_samples = 55, n_neighbors = 98
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: Expected n_neighbors <= n_samples,  but n_samples = 55, n_neighbors = 100
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of -0.5 cannot be evaluated. error: 0.0 cannot be raised to a negative power
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:Lambda value of 0 cannot be evaluated. error: test_size=25 should be either positive and smaller than the number of samples 18 or a float in the (0, 1) range
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of 0.5 cannot be evaluated. error: Input contains NaN.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.105e+12, tolerance: 3.230e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.343e+12, tolerance: 3.230e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.144e+12, tolerance: 3.230e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.409e+12, tolerance: 3.230e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.173e+12, tolerance: 3.230e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.445e+12, tolerance: 3.230e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.198e+12, tolerance: 3.230e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.469e+12, tolerance: 3.230e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.218e+12, tolerance: 3.230e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.487e+12, tolerance: 3.230e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.236e+12, tolerance: 3.230e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.501e+12, tolerance: 3.230e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.252e+12, tolerance: 3.230e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.512e+12, tolerance: 3.230e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.265e+12, tolerance: 3.230e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.521e+12, tolerance: 3.230e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.278e+12, tolerance: 3.230e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.529e+12, tolerance: 3.230e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.289e+12, tolerance: 3.230e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.535e+12, tolerance: 3.230e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.300e+12, tolerance: 3.230e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.541e+12, tolerance: 3.230e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.309e+12, tolerance: 3.230e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.545e+12, tolerance: 3.230e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.318e+12, tolerance: 3.230e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.550e+12, tolerance: 3.230e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.326e+12, tolerance: 3.230e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.553e+12, tolerance: 3.230e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.334e+12, tolerance: 3.230e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.557e+12, tolerance: 3.230e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.341e+12, tolerance: 3.230e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.560e+12, tolerance: 3.230e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.348e+12, tolerance: 3.230e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.562e+12, tolerance: 3.230e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.354e+12, tolerance: 3.230e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.565e+12, tolerance: 3.230e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.360e+12, tolerance: 3.230e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.567e+12, tolerance: 3.230e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.366e+12, tolerance: 3.230e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.569e+12, tolerance: 3.230e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of -0.5 cannot be evaluated. error: 0.0 cannot be raised to a negative power
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:Lambda value of 0 cannot be evaluated. error: Input X contains NaN.
ElasticNet does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of 0.5 cannot be evaluated. error: Input contains NaN.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.141e+01, tolerance: 6.711e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.195e+01, tolerance: 6.711e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.155e+01, tolerance: 6.711e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.226e+01, tolerance: 6.711e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.164e+01, tolerance: 6.711e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.247e+01, tolerance: 6.711e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.171e+01, tolerance: 6.711e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.261e+01, tolerance: 6.711e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.177e+01, tolerance: 6.711e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.273e+01, tolerance: 6.711e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.183e+01, tolerance: 6.711e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.282e+01, tolerance: 6.711e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.188e+01, tolerance: 6.711e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.289e+01, tolerance: 6.711e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.193e+01, tolerance: 6.711e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.295e+01, tolerance: 6.711e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.197e+01, tolerance: 6.711e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.300e+01, tolerance: 6.711e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.202e+01, tolerance: 6.711e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.304e+01, tolerance: 6.711e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.206e+01, tolerance: 6.711e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.307e+01, tolerance: 6.711e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.210e+01, tolerance: 6.711e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.311e+01, tolerance: 6.711e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.213e+01, tolerance: 6.711e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.313e+01, tolerance: 6.711e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.217e+01, tolerance: 6.711e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.316e+01, tolerance: 6.711e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.220e+01, tolerance: 6.711e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.318e+01, tolerance: 6.711e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.223e+01, tolerance: 6.711e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.320e+01, tolerance: 6.711e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.226e+01, tolerance: 6.711e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.322e+01, tolerance: 6.711e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.229e+01, tolerance: 6.711e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.323e+01, tolerance: 6.711e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.231e+01, tolerance: 6.711e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.325e+01, tolerance: 6.711e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.234e+01, tolerance: 6.711e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.326e+01, tolerance: 6.711e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.685e+01, tolerance: 8.955e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.889e+01, tolerance: 1.170e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 80}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 80
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 82}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 82
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 84}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 84
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 86}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 86
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 88}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 88
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 90}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 90
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 92}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 92
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 94}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 94
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 96}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 96
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 98}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 98
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 100
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of -0.5 cannot be evaluated. error: 0.0 cannot be raised to a negative power
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:Lambda value of 0 cannot be evaluated. error: Input X contains NaN.
ElasticNet does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of 0.5 cannot be evaluated. error: Input contains NaN.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.907e+10, tolerance: 1.088e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.239e+10, tolerance: 1.088e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.938e+10, tolerance: 1.088e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.312e+10, tolerance: 1.088e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.966e+10, tolerance: 1.088e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.346e+10, tolerance: 1.088e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.990e+10, tolerance: 1.088e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.366e+10, tolerance: 1.088e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.012e+10, tolerance: 1.088e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.378e+10, tolerance: 1.088e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.032e+10, tolerance: 1.088e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.388e+10, tolerance: 1.088e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.050e+10, tolerance: 1.088e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.394e+10, tolerance: 1.088e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.066e+10, tolerance: 1.088e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.400e+10, tolerance: 1.088e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.081e+10, tolerance: 1.088e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.404e+10, tolerance: 1.088e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.095e+10, tolerance: 1.088e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.407e+10, tolerance: 1.088e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.108e+10, tolerance: 1.088e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.410e+10, tolerance: 1.088e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.119e+10, tolerance: 1.088e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.412e+10, tolerance: 1.088e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.130e+10, tolerance: 1.088e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.414e+10, tolerance: 1.088e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.141e+10, tolerance: 1.088e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.416e+10, tolerance: 1.088e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.150e+10, tolerance: 1.088e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.418e+10, tolerance: 1.088e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.159e+10, tolerance: 1.088e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.419e+10, tolerance: 1.088e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.167e+10, tolerance: 1.088e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.420e+10, tolerance: 1.088e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.175e+10, tolerance: 1.088e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.421e+10, tolerance: 1.088e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.183e+10, tolerance: 1.088e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.422e+10, tolerance: 1.088e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.190e+10, tolerance: 1.088e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.423e+10, tolerance: 1.088e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.569e+10, tolerance: 1.616e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.964e+10, tolerance: 2.147e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 74}. error: Expected n_neighbors <= n_samples,  but n_samples = 73, n_neighbors = 74
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 76}. error: Expected n_neighbors <= n_samples,  but n_samples = 73, n_neighbors = 76
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 78}. error: Expected n_neighbors <= n_samples,  but n_samples = 73, n_neighbors = 78
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 80}. error: Expected n_neighbors <= n_samples,  but n_samples = 73, n_neighbors = 80
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 82}. error: Expected n_neighbors <= n_samples,  but n_samples = 73, n_neighbors = 82
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 84}. error: Expected n_neighbors <= n_samples,  but n_samples = 73, n_neighbors = 84
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 86}. error: Expected n_neighbors <= n_samples,  but n_samples = 73, n_neighbors = 86
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 88}. error: Expected n_neighbors <= n_samples,  but n_samples = 73, n_neighbors = 88
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 90}. error: Expected n_neighbors <= n_samples,  but n_samples = 73, n_neighbors = 90
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 92}. error: Expected n_neighbors <= n_samples,  but n_samples = 73, n_neighbors = 92
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 94}. error: Expected n_neighbors <= n_samples,  but n_samples = 73, n_neighbors = 94
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 96}. error: Expected n_neighbors <= n_samples,  but n_samples = 73, n_neighbors = 96
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 98}. error: Expected n_neighbors <= n_samples,  but n_samples = 73, n_neighbors = 98
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: Expected n_neighbors <= n_samples,  but n_samples = 73, n_neighbors = 100
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of -0.5 cannot be evaluated. error: 0.0 cannot be raised to a negative power
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:Lambda value of 0 cannot be evaluated. error: test_size=25 should be either positive and smaller than the number of samples 20 or a float in the (0, 1) range
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of 0.5 cannot be evaluated. error: Input contains NaN.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.605e+11, tolerance: 5.843e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.201e+11, tolerance: 5.843e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.704e+11, tolerance: 5.843e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.354e+11, tolerance: 5.843e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.778e+11, tolerance: 5.843e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.446e+11, tolerance: 5.843e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.837e+11, tolerance: 5.843e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.511e+11, tolerance: 5.843e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.887e+11, tolerance: 5.843e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.559e+11, tolerance: 5.843e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.930e+11, tolerance: 5.843e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.597e+11, tolerance: 5.843e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.967e+11, tolerance: 5.843e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.628e+11, tolerance: 5.843e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.001e+11, tolerance: 5.843e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.653e+11, tolerance: 5.843e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.031e+11, tolerance: 5.843e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.674e+11, tolerance: 5.843e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.058e+11, tolerance: 5.843e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.692e+11, tolerance: 5.843e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.083e+11, tolerance: 5.843e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.708e+11, tolerance: 5.843e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.106e+11, tolerance: 5.843e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.721e+11, tolerance: 5.843e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.127e+11, tolerance: 5.843e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.733e+11, tolerance: 5.843e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.146e+11, tolerance: 5.843e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.744e+11, tolerance: 5.843e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.165e+11, tolerance: 5.843e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.753e+11, tolerance: 5.843e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.182e+11, tolerance: 5.843e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.762e+11, tolerance: 5.843e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.198e+11, tolerance: 5.843e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.769e+11, tolerance: 5.843e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.214e+11, tolerance: 5.843e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.776e+11, tolerance: 5.843e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.228e+11, tolerance: 5.843e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.783e+11, tolerance: 5.843e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.242e+11, tolerance: 5.843e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.789e+11, tolerance: 5.843e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of -0.5 cannot be evaluated. error: 0.0 cannot be raised to a negative power
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:Lambda value of 0 cannot be evaluated. error: test_size=25 should be either positive and smaller than the number of samples 13 or a float in the (0, 1) range
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of 0.5 cannot be evaluated. error: Input contains NaN.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.366e+12, tolerance: 1.166e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.534e+12, tolerance: 1.166e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.541e+12, tolerance: 1.166e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.861e+12, tolerance: 1.166e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.674e+12, tolerance: 1.166e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.041e+12, tolerance: 1.166e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.783e+12, tolerance: 1.166e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.161e+12, tolerance: 1.166e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.876e+12, tolerance: 1.166e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.247e+12, tolerance: 1.166e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.956e+12, tolerance: 1.166e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.313e+12, tolerance: 1.166e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.028e+12, tolerance: 1.166e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.365e+12, tolerance: 1.166e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.091e+12, tolerance: 1.166e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.407e+12, tolerance: 1.166e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.149e+12, tolerance: 1.166e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.442e+12, tolerance: 1.166e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.202e+12, tolerance: 1.166e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.472e+12, tolerance: 1.166e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.250e+12, tolerance: 1.166e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.497e+12, tolerance: 1.166e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.295e+12, tolerance: 1.166e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.519e+12, tolerance: 1.166e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.337e+12, tolerance: 1.166e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.538e+12, tolerance: 1.166e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.375e+12, tolerance: 1.166e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.555e+12, tolerance: 1.166e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.412e+12, tolerance: 1.166e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.570e+12, tolerance: 1.166e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.446e+12, tolerance: 1.166e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.584e+12, tolerance: 1.166e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.478e+12, tolerance: 1.166e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.596e+12, tolerance: 1.166e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.508e+12, tolerance: 1.166e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.607e+12, tolerance: 1.166e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.537e+12, tolerance: 1.166e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.617e+12, tolerance: 1.166e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.564e+12, tolerance: 1.166e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.626e+12, tolerance: 1.166e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of -0.5 cannot be evaluated. error: 0.0 cannot be raised to a negative power
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:Lambda value of 0 cannot be evaluated. error: test_size=25 should be either positive and smaller than the number of samples 21 or a float in the (0, 1) range
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of 0.5 cannot be evaluated. error: Input contains NaN.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.454e+13, tolerance: 6.351e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+13, tolerance: 6.351e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.545e+13, tolerance: 6.351e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.312e+13, tolerance: 6.351e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.616e+13, tolerance: 6.351e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.444e+13, tolerance: 6.351e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.676e+13, tolerance: 6.351e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.538e+13, tolerance: 6.351e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.726e+13, tolerance: 6.351e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.610e+13, tolerance: 6.351e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.771e+13, tolerance: 6.351e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.666e+13, tolerance: 6.351e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.810e+13, tolerance: 6.351e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.712e+13, tolerance: 6.351e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.846e+13, tolerance: 6.351e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.751e+13, tolerance: 6.351e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+13, tolerance: 6.351e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.783e+13, tolerance: 6.351e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.909e+13, tolerance: 6.351e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.811e+13, tolerance: 6.351e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.937e+13, tolerance: 6.351e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.835e+13, tolerance: 6.351e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.963e+13, tolerance: 6.351e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.856e+13, tolerance: 6.351e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.987e+13, tolerance: 6.351e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.874e+13, tolerance: 6.351e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.010e+13, tolerance: 6.351e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.891e+13, tolerance: 6.351e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.032e+13, tolerance: 6.351e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.906e+13, tolerance: 6.351e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.052e+13, tolerance: 6.351e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.919e+13, tolerance: 6.351e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.072e+13, tolerance: 6.351e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.931e+13, tolerance: 6.351e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.090e+13, tolerance: 6.351e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.942e+13, tolerance: 6.351e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.108e+13, tolerance: 6.351e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.952e+13, tolerance: 6.351e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.125e+13, tolerance: 6.351e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.961e+13, tolerance: 6.351e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.523e+13, tolerance: 6.843e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.151e+13, tolerance: 9.752e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of -0.5 cannot be evaluated. error: 0.0 cannot be raised to a negative power
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:Lambda value of 0 cannot be evaluated. error: Input X contains NaN.
ElasticNet does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of 0.5 cannot be evaluated. error: Input contains NaN.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.069e+01, tolerance: 7.172e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.205e+01, tolerance: 7.172e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.105e+01, tolerance: 7.172e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.279e+01, tolerance: 7.172e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.128e+01, tolerance: 7.172e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.328e+01, tolerance: 7.172e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.146e+01, tolerance: 7.172e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.363e+01, tolerance: 7.172e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.162e+01, tolerance: 7.172e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.390e+01, tolerance: 7.172e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.176e+01, tolerance: 7.172e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.411e+01, tolerance: 7.172e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.189e+01, tolerance: 7.172e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.428e+01, tolerance: 7.172e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.201e+01, tolerance: 7.172e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.442e+01, tolerance: 7.172e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.212e+01, tolerance: 7.172e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.453e+01, tolerance: 7.172e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.222e+01, tolerance: 7.172e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.463e+01, tolerance: 7.172e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.232e+01, tolerance: 7.172e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.472e+01, tolerance: 7.172e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.241e+01, tolerance: 7.172e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.479e+01, tolerance: 7.172e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.249e+01, tolerance: 7.172e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.486e+01, tolerance: 7.172e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.258e+01, tolerance: 7.172e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.491e+01, tolerance: 7.172e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.265e+01, tolerance: 7.172e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.497e+01, tolerance: 7.172e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.273e+01, tolerance: 7.172e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.501e+01, tolerance: 7.172e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.280e+01, tolerance: 7.172e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.505e+01, tolerance: 7.172e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.286e+01, tolerance: 7.172e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.509e+01, tolerance: 7.172e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.293e+01, tolerance: 7.172e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.513e+01, tolerance: 7.172e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.299e+01, tolerance: 7.172e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.516e+01, tolerance: 7.172e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.660e+01, tolerance: 8.433e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.087e+01, tolerance: 1.170e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 80}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 80
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 82}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 82
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 84}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 84
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 86}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 86
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 88}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 88
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 90}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 90
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 92}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 92
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 94}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 94
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 96}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 96
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 98}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 98
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 100
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of -0.5 cannot be evaluated. error: 0.0 cannot be raised to a negative power
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:Lambda value of 0 cannot be evaluated. error: test_size=25 should be either positive and smaller than the number of samples 17 or a float in the (0, 1) range
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of 0.5 cannot be evaluated. error: Input contains NaN.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.453e+11, tolerance: 1.092e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.313e+11, tolerance: 1.092e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.586e+11, tolerance: 1.092e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.573e+11, tolerance: 1.092e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.691e+11, tolerance: 1.092e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.723e+11, tolerance: 1.092e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.778e+11, tolerance: 1.092e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.825e+11, tolerance: 1.092e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.852e+11, tolerance: 1.092e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.901e+11, tolerance: 1.092e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.917e+11, tolerance: 1.092e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.960e+11, tolerance: 1.092e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.974e+11, tolerance: 1.092e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.007e+11, tolerance: 1.092e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.025e+11, tolerance: 1.092e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.047e+11, tolerance: 1.092e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.072e+11, tolerance: 1.092e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.079e+11, tolerance: 1.092e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.114e+11, tolerance: 1.092e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.107e+11, tolerance: 1.092e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.153e+11, tolerance: 1.092e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.131e+11, tolerance: 1.092e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.189e+11, tolerance: 1.092e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.152e+11, tolerance: 1.092e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.223e+11, tolerance: 1.092e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.171e+11, tolerance: 1.092e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.254e+11, tolerance: 1.092e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.187e+11, tolerance: 1.092e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.283e+11, tolerance: 1.092e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.202e+11, tolerance: 1.092e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.311e+11, tolerance: 1.092e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.215e+11, tolerance: 1.092e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.337e+11, tolerance: 1.092e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.227e+11, tolerance: 1.092e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.361e+11, tolerance: 1.092e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.237e+11, tolerance: 1.092e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.384e+11, tolerance: 1.092e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.247e+11, tolerance: 1.092e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.406e+11, tolerance: 1.092e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.256e+11, tolerance: 1.092e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of -0.5 cannot be evaluated. error: 0.0 cannot be raised to a negative power
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:Lambda value of 0 cannot be evaluated. error: test_size=25 should be either positive and smaller than the number of samples 15 or a float in the (0, 1) range
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of 0.5 cannot be evaluated. error: Input contains NaN.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.290e+00, tolerance: 2.589e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.291e+00, tolerance: 2.589e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.290e+00, tolerance: 2.589e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.292e+00, tolerance: 2.589e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.290e+00, tolerance: 2.589e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.293e+00, tolerance: 2.589e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.291e+00, tolerance: 2.589e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.293e+00, tolerance: 2.589e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.291e+00, tolerance: 2.589e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.293e+00, tolerance: 2.589e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.291e+00, tolerance: 2.589e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.293e+00, tolerance: 2.589e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.291e+00, tolerance: 2.589e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.294e+00, tolerance: 2.589e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.291e+00, tolerance: 2.589e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.294e+00, tolerance: 2.589e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.292e+00, tolerance: 2.589e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.294e+00, tolerance: 2.589e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.292e+00, tolerance: 2.589e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.294e+00, tolerance: 2.589e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.292e+00, tolerance: 2.589e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.294e+00, tolerance: 2.589e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.292e+00, tolerance: 2.589e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.294e+00, tolerance: 2.589e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.292e+00, tolerance: 2.589e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.294e+00, tolerance: 2.589e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.292e+00, tolerance: 2.589e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.294e+00, tolerance: 2.589e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.292e+00, tolerance: 2.589e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.294e+00, tolerance: 2.589e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.292e+00, tolerance: 2.589e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.294e+00, tolerance: 2.589e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.292e+00, tolerance: 2.589e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.294e+00, tolerance: 2.589e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.292e+00, tolerance: 2.589e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.294e+00, tolerance: 2.589e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.292e+00, tolerance: 2.589e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.294e+00, tolerance: 2.589e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.293e+00, tolerance: 2.589e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.294e+00, tolerance: 2.589e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 79}. error: Expected n_neighbors <= n_samples,  but n_samples = 78, n_neighbors = 79
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 81}. error: Expected n_neighbors <= n_samples,  but n_samples = 78, n_neighbors = 81
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 83}. error: Expected n_neighbors <= n_samples,  but n_samples = 78, n_neighbors = 83
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 85}. error: Expected n_neighbors <= n_samples,  but n_samples = 78, n_neighbors = 85
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 87}. error: Expected n_neighbors <= n_samples,  but n_samples = 78, n_neighbors = 87
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 89}. error: Expected n_neighbors <= n_samples,  but n_samples = 78, n_neighbors = 89
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 91}. error: Expected n_neighbors <= n_samples,  but n_samples = 78, n_neighbors = 91
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 93}. error: Expected n_neighbors <= n_samples,  but n_samples = 78, n_neighbors = 93
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 95}. error: Expected n_neighbors <= n_samples,  but n_samples = 78, n_neighbors = 95
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 97}. error: Expected n_neighbors <= n_samples,  but n_samples = 78, n_neighbors = 97
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: Expected n_neighbors <= n_samples,  but n_samples = 78, n_neighbors = 99
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of -0.5 cannot be evaluated. error: 0.0 cannot be raised to a negative power
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:Lambda value of 0 cannot be evaluated. error: Input X contains NaN.
ElasticNet does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of 0.5 cannot be evaluated. error: Input contains NaN.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.130e+12, tolerance: 3.259e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.405e+12, tolerance: 3.259e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.181e+12, tolerance: 3.259e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.482e+12, tolerance: 3.259e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.218e+12, tolerance: 3.259e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.519e+12, tolerance: 3.259e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.248e+12, tolerance: 3.259e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.541e+12, tolerance: 3.259e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.273e+12, tolerance: 3.259e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.556e+12, tolerance: 3.259e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.294e+12, tolerance: 3.259e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.566e+12, tolerance: 3.259e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.312e+12, tolerance: 3.259e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.574e+12, tolerance: 3.259e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.328e+12, tolerance: 3.259e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.580e+12, tolerance: 3.259e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.342e+12, tolerance: 3.259e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.585e+12, tolerance: 3.259e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.355e+12, tolerance: 3.259e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.589e+12, tolerance: 3.259e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.367e+12, tolerance: 3.259e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.593e+12, tolerance: 3.259e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.378e+12, tolerance: 3.259e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.595e+12, tolerance: 3.259e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.387e+12, tolerance: 3.259e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.598e+12, tolerance: 3.259e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.396e+12, tolerance: 3.259e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+12, tolerance: 3.259e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.405e+12, tolerance: 3.259e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.602e+12, tolerance: 3.259e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.412e+12, tolerance: 3.259e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.603e+12, tolerance: 3.259e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.419e+12, tolerance: 3.259e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.605e+12, tolerance: 3.259e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.426e+12, tolerance: 3.259e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.606e+12, tolerance: 3.259e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.432e+12, tolerance: 3.259e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.607e+12, tolerance: 3.259e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.438e+12, tolerance: 3.259e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.608e+12, tolerance: 3.259e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 57}. error: Expected n_neighbors <= n_samples,  but n_samples = 56, n_neighbors = 57
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 59}. error: Expected n_neighbors <= n_samples,  but n_samples = 56, n_neighbors = 59
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 61}. error: Expected n_neighbors <= n_samples,  but n_samples = 56, n_neighbors = 61
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 63}. error: Expected n_neighbors <= n_samples,  but n_samples = 56, n_neighbors = 63
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 65}. error: Expected n_neighbors <= n_samples,  but n_samples = 56, n_neighbors = 65
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 67}. error: Expected n_neighbors <= n_samples,  but n_samples = 56, n_neighbors = 67
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 69}. error: Expected n_neighbors <= n_samples,  but n_samples = 56, n_neighbors = 69
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 71}. error: Expected n_neighbors <= n_samples,  but n_samples = 56, n_neighbors = 71
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 73}. error: Expected n_neighbors <= n_samples,  but n_samples = 56, n_neighbors = 73
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 75}. error: Expected n_neighbors <= n_samples,  but n_samples = 56, n_neighbors = 75
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 77}. error: Expected n_neighbors <= n_samples,  but n_samples = 56, n_neighbors = 77
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 79}. error: Expected n_neighbors <= n_samples,  but n_samples = 56, n_neighbors = 79
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 81}. error: Expected n_neighbors <= n_samples,  but n_samples = 56, n_neighbors = 81
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 83}. error: Expected n_neighbors <= n_samples,  but n_samples = 56, n_neighbors = 83
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 85}. error: Expected n_neighbors <= n_samples,  but n_samples = 56, n_neighbors = 85
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 87}. error: Expected n_neighbors <= n_samples,  but n_samples = 56, n_neighbors = 87
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 89}. error: Expected n_neighbors <= n_samples,  but n_samples = 56, n_neighbors = 89
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 91}. error: Expected n_neighbors <= n_samples,  but n_samples = 56, n_neighbors = 91
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 93}. error: Expected n_neighbors <= n_samples,  but n_samples = 56, n_neighbors = 93
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 95}. error: Expected n_neighbors <= n_samples,  but n_samples = 56, n_neighbors = 95
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 97}. error: Expected n_neighbors <= n_samples,  but n_samples = 56, n_neighbors = 97
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: Expected n_neighbors <= n_samples,  but n_samples = 56, n_neighbors = 99
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of -0.5 cannot be evaluated. error: 0.0 cannot be raised to a negative power
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:Lambda value of 0 cannot be evaluated. error: test_size=25 should be either positive and smaller than the number of samples 17 or a float in the (0, 1) range
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of 0.5 cannot be evaluated. error: Input contains NaN.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.419e-01, tolerance: 1.885e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.420e-01, tolerance: 1.885e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.419e-01, tolerance: 1.885e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.421e-01, tolerance: 1.885e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.419e-01, tolerance: 1.885e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.422e-01, tolerance: 1.885e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.420e-01, tolerance: 1.885e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.422e-01, tolerance: 1.885e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.420e-01, tolerance: 1.885e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.422e-01, tolerance: 1.885e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.420e-01, tolerance: 1.885e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.422e-01, tolerance: 1.885e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.420e-01, tolerance: 1.885e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.423e-01, tolerance: 1.885e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.420e-01, tolerance: 1.885e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.423e-01, tolerance: 1.885e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.421e-01, tolerance: 1.885e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.423e-01, tolerance: 1.885e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.421e-01, tolerance: 1.885e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.423e-01, tolerance: 1.885e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.421e-01, tolerance: 1.885e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.423e-01, tolerance: 1.885e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.421e-01, tolerance: 1.885e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.423e-01, tolerance: 1.885e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.421e-01, tolerance: 1.885e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.423e-01, tolerance: 1.885e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.421e-01, tolerance: 1.885e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.423e-01, tolerance: 1.885e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.421e-01, tolerance: 1.885e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.423e-01, tolerance: 1.885e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.421e-01, tolerance: 1.885e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.423e-01, tolerance: 1.885e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.421e-01, tolerance: 1.885e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.423e-01, tolerance: 1.885e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.422e-01, tolerance: 1.885e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.423e-01, tolerance: 1.885e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.422e-01, tolerance: 1.885e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.423e-01, tolerance: 1.885e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.422e-01, tolerance: 1.885e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.423e-01, tolerance: 1.885e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 79}. error: Expected n_neighbors <= n_samples,  but n_samples = 78, n_neighbors = 79
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 81}. error: Expected n_neighbors <= n_samples,  but n_samples = 78, n_neighbors = 81
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 83}. error: Expected n_neighbors <= n_samples,  but n_samples = 78, n_neighbors = 83
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 85}. error: Expected n_neighbors <= n_samples,  but n_samples = 78, n_neighbors = 85
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 87}. error: Expected n_neighbors <= n_samples,  but n_samples = 78, n_neighbors = 87
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 89}. error: Expected n_neighbors <= n_samples,  but n_samples = 78, n_neighbors = 89
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 91}. error: Expected n_neighbors <= n_samples,  but n_samples = 78, n_neighbors = 91
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 93}. error: Expected n_neighbors <= n_samples,  but n_samples = 78, n_neighbors = 93
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 95}. error: Expected n_neighbors <= n_samples,  but n_samples = 78, n_neighbors = 95
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 97}. error: Expected n_neighbors <= n_samples,  but n_samples = 78, n_neighbors = 97
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: Expected n_neighbors <= n_samples,  but n_samples = 78, n_neighbors = 99
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of -0.5 cannot be evaluated. error: 0.0 cannot be raised to a negative power
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:Lambda value of 0 cannot be evaluated. error: Input X contains NaN.
ElasticNet does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of 0.5 cannot be evaluated. error: Input contains NaN.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.821e+01, tolerance: 6.174e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.496e+01, tolerance: 6.174e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.898e+01, tolerance: 6.174e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.687e+01, tolerance: 6.174e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.964e+01, tolerance: 6.174e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.783e+01, tolerance: 6.174e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.019e+01, tolerance: 6.174e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.841e+01, tolerance: 6.174e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.068e+01, tolerance: 6.174e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.881e+01, tolerance: 6.174e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.112e+01, tolerance: 6.174e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.910e+01, tolerance: 6.174e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.150e+01, tolerance: 6.174e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.931e+01, tolerance: 6.174e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.185e+01, tolerance: 6.174e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.948e+01, tolerance: 6.174e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.217e+01, tolerance: 6.174e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.962e+01, tolerance: 6.174e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.247e+01, tolerance: 6.174e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.973e+01, tolerance: 6.174e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.274e+01, tolerance: 6.174e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.982e+01, tolerance: 6.174e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.299e+01, tolerance: 6.174e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.990e+01, tolerance: 6.174e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.322e+01, tolerance: 6.174e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.997e+01, tolerance: 6.174e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.344e+01, tolerance: 6.174e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.003e+01, tolerance: 6.174e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.364e+01, tolerance: 6.174e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.008e+01, tolerance: 6.174e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.384e+01, tolerance: 6.174e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.013e+01, tolerance: 6.174e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.402e+01, tolerance: 6.174e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.017e+01, tolerance: 6.174e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.419e+01, tolerance: 6.174e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.020e+01, tolerance: 6.174e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.435e+01, tolerance: 6.174e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.024e+01, tolerance: 6.174e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.450e+01, tolerance: 6.174e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.027e+01, tolerance: 6.174e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.295e+01, tolerance: 7.254e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.469e+01, tolerance: 9.428e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 70}. error: Expected n_neighbors <= n_samples,  but n_samples = 69, n_neighbors = 70
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 72}. error: Expected n_neighbors <= n_samples,  but n_samples = 69, n_neighbors = 72
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 74}. error: Expected n_neighbors <= n_samples,  but n_samples = 69, n_neighbors = 74
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 76}. error: Expected n_neighbors <= n_samples,  but n_samples = 69, n_neighbors = 76
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 78}. error: Expected n_neighbors <= n_samples,  but n_samples = 69, n_neighbors = 78
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 80}. error: Expected n_neighbors <= n_samples,  but n_samples = 69, n_neighbors = 80
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 82}. error: Expected n_neighbors <= n_samples,  but n_samples = 69, n_neighbors = 82
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 84}. error: Expected n_neighbors <= n_samples,  but n_samples = 69, n_neighbors = 84
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 86}. error: Expected n_neighbors <= n_samples,  but n_samples = 69, n_neighbors = 86
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 88}. error: Expected n_neighbors <= n_samples,  but n_samples = 69, n_neighbors = 88
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 90}. error: Expected n_neighbors <= n_samples,  but n_samples = 69, n_neighbors = 90
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 92}. error: Expected n_neighbors <= n_samples,  but n_samples = 69, n_neighbors = 92
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 94}. error: Expected n_neighbors <= n_samples,  but n_samples = 69, n_neighbors = 94
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 96}. error: Expected n_neighbors <= n_samples,  but n_samples = 69, n_neighbors = 96
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 98}. error: Expected n_neighbors <= n_samples,  but n_samples = 69, n_neighbors = 98
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: Expected n_neighbors <= n_samples,  but n_samples = 69, n_neighbors = 100
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.633e+05, tolerance: 4.467e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.510e+06, tolerance: 4.467e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.027e+06, tolerance: 4.467e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.696e+06, tolerance: 4.467e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.078e+06, tolerance: 4.467e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.800e+06, tolerance: 4.467e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.121e+06, tolerance: 4.467e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.868e+06, tolerance: 4.467e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.159e+06, tolerance: 4.467e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.918e+06, tolerance: 4.467e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.193e+06, tolerance: 4.467e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.955e+06, tolerance: 4.467e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.223e+06, tolerance: 4.467e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.984e+06, tolerance: 4.467e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.251e+06, tolerance: 4.467e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.007e+06, tolerance: 4.467e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.276e+06, tolerance: 4.467e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.027e+06, tolerance: 4.467e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.300e+06, tolerance: 4.467e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.043e+06, tolerance: 4.467e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.322e+06, tolerance: 4.467e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.057e+06, tolerance: 4.467e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.342e+06, tolerance: 4.467e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.069e+06, tolerance: 4.467e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.362e+06, tolerance: 4.467e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.079e+06, tolerance: 4.467e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.380e+06, tolerance: 4.467e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.089e+06, tolerance: 4.467e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.397e+06, tolerance: 4.467e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.097e+06, tolerance: 4.467e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.413e+06, tolerance: 4.467e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.104e+06, tolerance: 4.467e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.428e+06, tolerance: 4.467e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.111e+06, tolerance: 4.467e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.443e+06, tolerance: 4.467e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.116e+06, tolerance: 4.467e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.457e+06, tolerance: 4.467e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.122e+06, tolerance: 4.467e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.470e+06, tolerance: 4.467e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.127e+06, tolerance: 4.467e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.335e+06, tolerance: 5.665e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.832e+06, tolerance: 6.861e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of -0.5 cannot be evaluated. error: 0.0 cannot be raised to a negative power
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:Lambda value of 0 cannot be evaluated. error: Input X contains NaN.
ElasticNet does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of 0.5 cannot be evaluated. error: Input contains NaN.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.665e+01, tolerance: 5.925e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.780e+01, tolerance: 5.925e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.690e+01, tolerance: 5.925e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.836e+01, tolerance: 5.925e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.711e+01, tolerance: 5.925e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.866e+01, tolerance: 5.925e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.729e+01, tolerance: 5.925e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.744e+01, tolerance: 5.925e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.897e+01, tolerance: 5.925e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.758e+01, tolerance: 5.925e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.906e+01, tolerance: 5.925e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.770e+01, tolerance: 5.925e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.781e+01, tolerance: 5.925e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.918e+01, tolerance: 5.925e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.790e+01, tolerance: 5.925e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.922e+01, tolerance: 5.925e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.799e+01, tolerance: 5.925e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.807e+01, tolerance: 5.925e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.814e+01, tolerance: 5.925e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.931e+01, tolerance: 5.925e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.820e+01, tolerance: 5.925e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.934e+01, tolerance: 5.925e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.826e+01, tolerance: 5.925e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.936e+01, tolerance: 5.925e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.832e+01, tolerance: 5.925e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.937e+01, tolerance: 5.925e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.837e+01, tolerance: 5.925e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.939e+01, tolerance: 5.925e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.841e+01, tolerance: 5.925e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.940e+01, tolerance: 5.925e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.846e+01, tolerance: 5.925e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.941e+01, tolerance: 5.925e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.850e+01, tolerance: 5.925e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.942e+01, tolerance: 5.925e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.853e+01, tolerance: 5.925e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 80}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 80
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 82}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 82
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 84}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 84
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 86}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 86
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 88}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 88
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 90}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 90
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 92}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 92
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 94}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 94
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 96}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 96
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 98}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 98
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 100
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of -0.5 cannot be evaluated. error: 0.0 cannot be raised to a negative power
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:Lambda value of 0 cannot be evaluated. error: Input X contains NaN.
ElasticNet does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of 0.5 cannot be evaluated. error: Input contains NaN.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.475e+01, tolerance: 7.201e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.515e+01, tolerance: 7.201e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.487e+01, tolerance: 7.201e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.533e+01, tolerance: 7.201e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.495e+01, tolerance: 7.201e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.543e+01, tolerance: 7.201e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.500e+01, tolerance: 7.201e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.551e+01, tolerance: 7.201e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.505e+01, tolerance: 7.201e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.557e+01, tolerance: 7.201e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.508e+01, tolerance: 7.201e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.562e+01, tolerance: 7.201e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.512e+01, tolerance: 7.201e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.565e+01, tolerance: 7.201e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.515e+01, tolerance: 7.201e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.569e+01, tolerance: 7.201e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.517e+01, tolerance: 7.201e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.571e+01, tolerance: 7.201e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.520e+01, tolerance: 7.201e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.573e+01, tolerance: 7.201e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.522e+01, tolerance: 7.201e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.575e+01, tolerance: 7.201e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.524e+01, tolerance: 7.201e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.577e+01, tolerance: 7.201e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.526e+01, tolerance: 7.201e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.578e+01, tolerance: 7.201e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.528e+01, tolerance: 7.201e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.579e+01, tolerance: 7.201e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.530e+01, tolerance: 7.201e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.581e+01, tolerance: 7.201e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.532e+01, tolerance: 7.201e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.582e+01, tolerance: 7.201e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.533e+01, tolerance: 7.201e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.583e+01, tolerance: 7.201e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.535e+01, tolerance: 7.201e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.583e+01, tolerance: 7.201e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.536e+01, tolerance: 7.201e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.584e+01, tolerance: 7.201e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.538e+01, tolerance: 7.201e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.585e+01, tolerance: 7.201e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.087e+01, tolerance: 9.292e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.987e+01, tolerance: 1.170e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 80}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 80
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 82}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 82
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 84}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 84
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 86}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 86
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 88}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 88
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 90}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 90
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 92}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 92
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 94}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 94
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 96}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 96
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 98}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 98
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 100
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of -0.5 cannot be evaluated. error: 0.0 cannot be raised to a negative power
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:Lambda value of 0 cannot be evaluated. error: Input X contains NaN.
ElasticNet does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of 0.5 cannot be evaluated. error: Input contains NaN.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.147e+10, tolerance: 6.976e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.884e+10, tolerance: 6.976e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.267e+10, tolerance: 6.976e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.178e+10, tolerance: 6.976e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.358e+10, tolerance: 6.976e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.366e+10, tolerance: 6.976e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.432e+10, tolerance: 6.976e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.503e+10, tolerance: 6.976e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.495e+10, tolerance: 6.976e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.608e+10, tolerance: 6.976e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.550e+10, tolerance: 6.976e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.692e+10, tolerance: 6.976e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+10, tolerance: 6.976e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.761e+10, tolerance: 6.976e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.645e+10, tolerance: 6.976e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.818e+10, tolerance: 6.976e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.687e+10, tolerance: 6.976e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.867e+10, tolerance: 6.976e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.726e+10, tolerance: 6.976e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.909e+10, tolerance: 6.976e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.762e+10, tolerance: 6.976e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.946e+10, tolerance: 6.976e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.796e+10, tolerance: 6.976e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.978e+10, tolerance: 6.976e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.827e+10, tolerance: 6.976e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.007e+10, tolerance: 6.976e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.857e+10, tolerance: 6.976e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.033e+10, tolerance: 6.976e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.886e+10, tolerance: 6.976e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.056e+10, tolerance: 6.976e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.913e+10, tolerance: 6.976e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.076e+10, tolerance: 6.976e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.939e+10, tolerance: 6.976e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.095e+10, tolerance: 6.976e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.964e+10, tolerance: 6.976e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.112e+10, tolerance: 6.976e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.987e+10, tolerance: 6.976e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.128e+10, tolerance: 6.976e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.010e+10, tolerance: 6.976e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.143e+10, tolerance: 6.976e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of -0.5 cannot be evaluated. error: 0.0 cannot be raised to a negative power
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:Lambda value of 0 cannot be evaluated. error: test_size=25 should be either positive and smaller than the number of samples 25 or a float in the (0, 1) range
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of 0.5 cannot be evaluated. error: Input contains NaN.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.971e+01, tolerance: 8.901e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.156e+01, tolerance: 8.901e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.011e+01, tolerance: 8.901e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.247e+01, tolerance: 8.901e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.044e+01, tolerance: 8.901e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.295e+01, tolerance: 8.901e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.073e+01, tolerance: 8.901e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.324e+01, tolerance: 8.901e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.098e+01, tolerance: 8.901e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.120e+01, tolerance: 8.901e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.140e+01, tolerance: 8.901e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.370e+01, tolerance: 8.901e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.157e+01, tolerance: 8.901e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.172e+01, tolerance: 8.901e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.386e+01, tolerance: 8.901e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.186e+01, tolerance: 8.901e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.392e+01, tolerance: 8.901e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.396e+01, tolerance: 8.901e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.210e+01, tolerance: 8.901e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.221e+01, tolerance: 8.901e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.404e+01, tolerance: 8.901e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.230e+01, tolerance: 8.901e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.239e+01, tolerance: 8.901e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.247e+01, tolerance: 8.901e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.412e+01, tolerance: 8.901e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.255e+01, tolerance: 8.901e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.414e+01, tolerance: 8.901e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.262e+01, tolerance: 8.901e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.418e+01, tolerance: 8.901e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.274e+01, tolerance: 8.901e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.419e+01, tolerance: 8.901e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 80}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 80
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 82}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 82
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 84}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 84
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 86}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 86
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 88}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 88
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 90}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 90
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 92}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 92
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 94}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 94
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 96}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 96
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 98}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 98
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 100
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of -0.5 cannot be evaluated. error: 0.0 cannot be raised to a negative power
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:Lambda value of 0 cannot be evaluated. error: Input X contains NaN.
ElasticNet does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of 0.5 cannot be evaluated. error: Input contains NaN.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.314e+11, tolerance: 1.257e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.484e+11, tolerance: 1.257e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.470e+11, tolerance: 1.257e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.909e+11, tolerance: 1.257e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.593e+11, tolerance: 1.257e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.159e+11, tolerance: 1.257e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.696e+11, tolerance: 1.257e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.329e+11, tolerance: 1.257e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.786e+11, tolerance: 1.257e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.453e+11, tolerance: 1.257e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.867e+11, tolerance: 1.257e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.548e+11, tolerance: 1.257e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.940e+11, tolerance: 1.257e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.623e+11, tolerance: 1.257e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.007e+11, tolerance: 1.257e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.684e+11, tolerance: 1.257e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.069e+11, tolerance: 1.257e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.734e+11, tolerance: 1.257e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.126e+11, tolerance: 1.257e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.777e+11, tolerance: 1.257e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.180e+11, tolerance: 1.257e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.814e+11, tolerance: 1.257e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.231e+11, tolerance: 1.257e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.845e+11, tolerance: 1.257e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.278e+11, tolerance: 1.257e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.873e+11, tolerance: 1.257e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.323e+11, tolerance: 1.257e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.897e+11, tolerance: 1.257e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.366e+11, tolerance: 1.257e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.919e+11, tolerance: 1.257e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.406e+11, tolerance: 1.257e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.938e+11, tolerance: 1.257e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.444e+11, tolerance: 1.257e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.956e+11, tolerance: 1.257e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.481e+11, tolerance: 1.257e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.971e+11, tolerance: 1.257e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.516e+11, tolerance: 1.257e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.986e+11, tolerance: 1.257e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.550e+11, tolerance: 1.257e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.999e+11, tolerance: 1.257e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of -0.5 cannot be evaluated. error: 0.0 cannot be raised to a negative power
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:Lambda value of 0 cannot be evaluated. error: test_size=25 should be either positive and smaller than the number of samples 21 or a float in the (0, 1) range
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of 0.5 cannot be evaluated. error: Input contains NaN.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.266e+12, tolerance: 3.796e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.567e+12, tolerance: 3.796e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.306e+12, tolerance: 3.796e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.654e+12, tolerance: 3.796e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.336e+12, tolerance: 3.796e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.702e+12, tolerance: 3.796e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.361e+12, tolerance: 3.796e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.733e+12, tolerance: 3.796e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.382e+12, tolerance: 3.796e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.755e+12, tolerance: 3.796e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.401e+12, tolerance: 3.796e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.772e+12, tolerance: 3.796e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.418e+12, tolerance: 3.796e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.785e+12, tolerance: 3.796e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.433e+12, tolerance: 3.796e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.796e+12, tolerance: 3.796e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.447e+12, tolerance: 3.796e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.805e+12, tolerance: 3.796e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.460e+12, tolerance: 3.796e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.812e+12, tolerance: 3.796e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.472e+12, tolerance: 3.796e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.818e+12, tolerance: 3.796e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.484e+12, tolerance: 3.796e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.824e+12, tolerance: 3.796e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.494e+12, tolerance: 3.796e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.829e+12, tolerance: 3.796e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.504e+12, tolerance: 3.796e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.833e+12, tolerance: 3.796e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.513e+12, tolerance: 3.796e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.836e+12, tolerance: 3.796e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.522e+12, tolerance: 3.796e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.840e+12, tolerance: 3.796e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.531e+12, tolerance: 3.796e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.843e+12, tolerance: 3.796e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.539e+12, tolerance: 3.796e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.845e+12, tolerance: 3.796e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.546e+12, tolerance: 3.796e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.848e+12, tolerance: 3.796e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.553e+12, tolerance: 3.796e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.850e+12, tolerance: 3.796e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of -0.5 cannot be evaluated. error: 0.0 cannot be raised to a negative power
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:Lambda value of 0 cannot be evaluated. error: Input X contains NaN.
ElasticNet does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of 0.5 cannot be evaluated. error: Input contains NaN.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.965e+11, tolerance: 6.006e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.645e+11, tolerance: 6.006e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.068e+11, tolerance: 6.006e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.782e+11, tolerance: 6.006e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.148e+11, tolerance: 6.006e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.843e+11, tolerance: 6.006e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.213e+11, tolerance: 6.006e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.877e+11, tolerance: 6.006e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.267e+11, tolerance: 6.006e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.900e+11, tolerance: 6.006e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.313e+11, tolerance: 6.006e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.915e+11, tolerance: 6.006e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.353e+11, tolerance: 6.006e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.927e+11, tolerance: 6.006e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.388e+11, tolerance: 6.006e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.935e+11, tolerance: 6.006e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.419e+11, tolerance: 6.006e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.942e+11, tolerance: 6.006e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.446e+11, tolerance: 6.006e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.948e+11, tolerance: 6.006e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.471e+11, tolerance: 6.006e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.953e+11, tolerance: 6.006e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.494e+11, tolerance: 6.006e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.957e+11, tolerance: 6.006e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.515e+11, tolerance: 6.006e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.960e+11, tolerance: 6.006e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.534e+11, tolerance: 6.006e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.963e+11, tolerance: 6.006e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.551e+11, tolerance: 6.006e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.965e+11, tolerance: 6.006e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.567e+11, tolerance: 6.006e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.968e+11, tolerance: 6.006e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.582e+11, tolerance: 6.006e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.970e+11, tolerance: 6.006e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.596e+11, tolerance: 6.006e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.971e+11, tolerance: 6.006e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.609e+11, tolerance: 6.006e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.973e+11, tolerance: 6.006e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.621e+11, tolerance: 6.006e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.975e+11, tolerance: 6.006e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 55}. error: Expected n_neighbors <= n_samples,  but n_samples = 54, n_neighbors = 55
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 57}. error: Expected n_neighbors <= n_samples,  but n_samples = 54, n_neighbors = 57
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 59}. error: Expected n_neighbors <= n_samples,  but n_samples = 54, n_neighbors = 59
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 61}. error: Expected n_neighbors <= n_samples,  but n_samples = 54, n_neighbors = 61
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 63}. error: Expected n_neighbors <= n_samples,  but n_samples = 54, n_neighbors = 63
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 65}. error: Expected n_neighbors <= n_samples,  but n_samples = 54, n_neighbors = 65
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 67}. error: Expected n_neighbors <= n_samples,  but n_samples = 54, n_neighbors = 67
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 69}. error: Expected n_neighbors <= n_samples,  but n_samples = 54, n_neighbors = 69
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 71}. error: Expected n_neighbors <= n_samples,  but n_samples = 54, n_neighbors = 71
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 73}. error: Expected n_neighbors <= n_samples,  but n_samples = 54, n_neighbors = 73
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 75}. error: Expected n_neighbors <= n_samples,  but n_samples = 54, n_neighbors = 75
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 77}. error: Expected n_neighbors <= n_samples,  but n_samples = 54, n_neighbors = 77
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 79}. error: Expected n_neighbors <= n_samples,  but n_samples = 54, n_neighbors = 79
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 81}. error: Expected n_neighbors <= n_samples,  but n_samples = 54, n_neighbors = 81
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 83}. error: Expected n_neighbors <= n_samples,  but n_samples = 54, n_neighbors = 83
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 85}. error: Expected n_neighbors <= n_samples,  but n_samples = 54, n_neighbors = 85
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 87}. error: Expected n_neighbors <= n_samples,  but n_samples = 54, n_neighbors = 87
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 89}. error: Expected n_neighbors <= n_samples,  but n_samples = 54, n_neighbors = 89
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 91}. error: Expected n_neighbors <= n_samples,  but n_samples = 54, n_neighbors = 91
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 93}. error: Expected n_neighbors <= n_samples,  but n_samples = 54, n_neighbors = 93
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 95}. error: Expected n_neighbors <= n_samples,  but n_samples = 54, n_neighbors = 95
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 97}. error: Expected n_neighbors <= n_samples,  but n_samples = 54, n_neighbors = 97
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: Expected n_neighbors <= n_samples,  but n_samples = 54, n_neighbors = 99
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of -0.5 cannot be evaluated. error: 0.0 cannot be raised to a negative power
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:Lambda value of 0 cannot be evaluated. error: Input X contains NaN.
ElasticNet does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of 0.5 cannot be evaluated. error: Input contains NaN.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.201e+01, tolerance: 8.705e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.260e+01, tolerance: 8.705e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.214e+01, tolerance: 8.705e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.288e+01, tolerance: 8.705e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.225e+01, tolerance: 8.705e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.303e+01, tolerance: 8.705e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.234e+01, tolerance: 8.705e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.313e+01, tolerance: 8.705e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.242e+01, tolerance: 8.705e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.319e+01, tolerance: 8.705e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.248e+01, tolerance: 8.705e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.324e+01, tolerance: 8.705e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.255e+01, tolerance: 8.705e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.327e+01, tolerance: 8.705e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.260e+01, tolerance: 8.705e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.330e+01, tolerance: 8.705e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.265e+01, tolerance: 8.705e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.332e+01, tolerance: 8.705e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.269e+01, tolerance: 8.705e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.334e+01, tolerance: 8.705e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.273e+01, tolerance: 8.705e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.335e+01, tolerance: 8.705e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.277e+01, tolerance: 8.705e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.337e+01, tolerance: 8.705e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.280e+01, tolerance: 8.705e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.338e+01, tolerance: 8.705e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.283e+01, tolerance: 8.705e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.339e+01, tolerance: 8.705e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.286e+01, tolerance: 8.705e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.340e+01, tolerance: 8.705e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.288e+01, tolerance: 8.705e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.340e+01, tolerance: 8.705e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.291e+01, tolerance: 8.705e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.341e+01, tolerance: 8.705e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.293e+01, tolerance: 8.705e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.342e+01, tolerance: 8.705e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.295e+01, tolerance: 8.705e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.342e+01, tolerance: 8.705e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.297e+01, tolerance: 8.705e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.343e+01, tolerance: 8.705e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 80}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 80
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 82}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 82
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 84}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 84
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 86}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 86
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 88}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 88
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 90}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 90
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 92}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 92
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 94}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 94
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 96}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 96
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 98}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 98
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 100
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of -0.5 cannot be evaluated. error: 0.0 cannot be raised to a negative power
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:Lambda value of 0 cannot be evaluated. error: Input X contains NaN.
ElasticNet does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of 0.5 cannot be evaluated. error: Input contains NaN.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.454e+01, tolerance: 5.444e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.611e+01, tolerance: 5.444e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.513e+01, tolerance: 5.444e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.644e+01, tolerance: 5.444e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.545e+01, tolerance: 5.444e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.660e+01, tolerance: 5.444e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.566e+01, tolerance: 5.444e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.670e+01, tolerance: 5.444e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.581e+01, tolerance: 5.444e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.677e+01, tolerance: 5.444e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.592e+01, tolerance: 5.444e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.682e+01, tolerance: 5.444e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.601e+01, tolerance: 5.444e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.687e+01, tolerance: 5.444e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.609e+01, tolerance: 5.444e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.690e+01, tolerance: 5.444e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.615e+01, tolerance: 5.444e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.693e+01, tolerance: 5.444e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.620e+01, tolerance: 5.444e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.695e+01, tolerance: 5.444e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.625e+01, tolerance: 5.444e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.697e+01, tolerance: 5.444e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.629e+01, tolerance: 5.444e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.699e+01, tolerance: 5.444e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.633e+01, tolerance: 5.444e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.700e+01, tolerance: 5.444e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.636e+01, tolerance: 5.444e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.702e+01, tolerance: 5.444e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.639e+01, tolerance: 5.444e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.703e+01, tolerance: 5.444e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.642e+01, tolerance: 5.444e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.704e+01, tolerance: 5.444e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.644e+01, tolerance: 5.444e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.705e+01, tolerance: 5.444e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.647e+01, tolerance: 5.444e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.705e+01, tolerance: 5.444e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.649e+01, tolerance: 5.444e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.706e+01, tolerance: 5.444e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.651e+01, tolerance: 5.444e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.707e+01, tolerance: 5.444e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.977e+01, tolerance: 8.839e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.294e+01, tolerance: 1.170e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 80}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 80
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 82}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 82
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 84}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 84
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 86}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 86
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 88}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 88
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 90}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 90
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 92}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 92
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 94}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 94
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 96}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 96
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 98}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 98
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 100
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of -0.5 cannot be evaluated. error: 0.0 cannot be raised to a negative power
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:Lambda value of 0 cannot be evaluated. error: test_size=25 should be either positive and smaller than the number of samples 16 or a float in the (0, 1) range
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of 0.5 cannot be evaluated. error: Input contains NaN.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.790e+13, tolerance: 9.132e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.504e+13, tolerance: 9.132e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.895e+13, tolerance: 9.132e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.729e+13, tolerance: 9.132e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.979e+13, tolerance: 9.132e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.863e+13, tolerance: 9.132e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.049e+13, tolerance: 9.132e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.957e+13, tolerance: 9.132e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.109e+13, tolerance: 9.132e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.028e+13, tolerance: 9.132e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.162e+13, tolerance: 9.132e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.083e+13, tolerance: 9.132e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.209e+13, tolerance: 9.132e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.128e+13, tolerance: 9.132e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.252e+13, tolerance: 9.132e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.165e+13, tolerance: 9.132e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.290e+13, tolerance: 9.132e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.196e+13, tolerance: 9.132e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.326e+13, tolerance: 9.132e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.223e+13, tolerance: 9.132e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.358e+13, tolerance: 9.132e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.246e+13, tolerance: 9.132e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.389e+13, tolerance: 9.132e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.266e+13, tolerance: 9.132e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.417e+13, tolerance: 9.132e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.284e+13, tolerance: 9.132e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.444e+13, tolerance: 9.132e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.299e+13, tolerance: 9.132e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.469e+13, tolerance: 9.132e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.313e+13, tolerance: 9.132e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.492e+13, tolerance: 9.132e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.326e+13, tolerance: 9.132e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.515e+13, tolerance: 9.132e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.337e+13, tolerance: 9.132e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.536e+13, tolerance: 9.132e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.348e+13, tolerance: 9.132e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.556e+13, tolerance: 9.132e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.357e+13, tolerance: 9.132e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.575e+13, tolerance: 9.132e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.366e+13, tolerance: 9.132e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.340e+05, tolerance: 5.847e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.059e+05, tolerance: 5.847e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.429e+05, tolerance: 5.847e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.295e+05, tolerance: 5.847e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.498e+05, tolerance: 5.847e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.426e+05, tolerance: 5.847e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.556e+05, tolerance: 5.847e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.511e+05, tolerance: 5.847e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.606e+05, tolerance: 5.847e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.570e+05, tolerance: 5.847e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.650e+05, tolerance: 5.847e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.615e+05, tolerance: 5.847e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.689e+05, tolerance: 5.847e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.649e+05, tolerance: 5.847e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.724e+05, tolerance: 5.847e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.677e+05, tolerance: 5.847e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.757e+05, tolerance: 5.847e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.699e+05, tolerance: 5.847e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.787e+05, tolerance: 5.847e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.718e+05, tolerance: 5.847e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.815e+05, tolerance: 5.847e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.734e+05, tolerance: 5.847e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.841e+05, tolerance: 5.847e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.747e+05, tolerance: 5.847e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.865e+05, tolerance: 5.847e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.759e+05, tolerance: 5.847e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.888e+05, tolerance: 5.847e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.769e+05, tolerance: 5.847e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.910e+05, tolerance: 5.847e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.778e+05, tolerance: 5.847e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.931e+05, tolerance: 5.847e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.786e+05, tolerance: 5.847e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.950e+05, tolerance: 5.847e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.793e+05, tolerance: 5.847e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.969e+05, tolerance: 5.847e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.800e+05, tolerance: 5.847e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.987e+05, tolerance: 5.847e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.806e+05, tolerance: 5.847e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.004e+05, tolerance: 5.847e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.811e+05, tolerance: 5.847e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of -0.5 cannot be evaluated. error: 0.0 cannot be raised to a negative power
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:Lambda value of 0 cannot be evaluated. error: test_size=25 should be either positive and smaller than the number of samples 22 or a float in the (0, 1) range
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of 0.5 cannot be evaluated. error: Input contains NaN.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.833e+10, tolerance: 2.600e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.692e+10, tolerance: 2.600e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.228e+10, tolerance: 2.600e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.994e+10, tolerance: 2.600e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.542e+10, tolerance: 2.600e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.817e+10, tolerance: 2.600e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.809e+10, tolerance: 2.600e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.397e+10, tolerance: 2.600e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.043e+10, tolerance: 2.600e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.832e+10, tolerance: 2.600e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.253e+10, tolerance: 2.600e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.017e+11, tolerance: 2.600e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.443e+10, tolerance: 2.600e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.044e+11, tolerance: 2.600e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.618e+10, tolerance: 2.600e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.067e+11, tolerance: 2.600e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.780e+10, tolerance: 2.600e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.086e+11, tolerance: 2.600e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.930e+10, tolerance: 2.600e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.102e+11, tolerance: 2.600e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.071e+10, tolerance: 2.600e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.115e+11, tolerance: 2.600e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.203e+10, tolerance: 2.600e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.127e+11, tolerance: 2.600e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.328e+10, tolerance: 2.600e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.138e+11, tolerance: 2.600e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.447e+10, tolerance: 2.600e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.147e+11, tolerance: 2.600e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.560e+10, tolerance: 2.600e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.155e+11, tolerance: 2.600e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.667e+10, tolerance: 2.600e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.163e+11, tolerance: 2.600e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.769e+10, tolerance: 2.600e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.169e+11, tolerance: 2.600e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.867e+10, tolerance: 2.600e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.175e+11, tolerance: 2.600e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.961e+10, tolerance: 2.600e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.181e+11, tolerance: 2.600e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.051e+10, tolerance: 2.600e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.186e+11, tolerance: 2.600e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of -0.5 cannot be evaluated. error: 0.0 cannot be raised to a negative power
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:Lambda value of 0 cannot be evaluated. error: Input X contains NaN.
ElasticNet does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of 0.5 cannot be evaluated. error: Input contains NaN.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.827e+01, tolerance: 8.720e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.839e+01, tolerance: 8.720e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.956e+01, tolerance: 8.720e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.189e+01, tolerance: 8.720e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.143e+01, tolerance: 8.720e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.346e+01, tolerance: 8.720e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.270e+01, tolerance: 8.720e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.399e+01, tolerance: 8.720e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.280e+01, tolerance: 8.720e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.447e+01, tolerance: 8.720e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.288e+01, tolerance: 8.720e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.491e+01, tolerance: 8.720e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.299e+01, tolerance: 8.720e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.566e+01, tolerance: 8.720e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.599e+01, tolerance: 8.720e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.630e+01, tolerance: 8.720e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.311e+01, tolerance: 8.720e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.314e+01, tolerance: 8.720e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.317e+01, tolerance: 8.720e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.319e+01, tolerance: 8.720e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.730e+01, tolerance: 8.720e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.751e+01, tolerance: 8.720e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.323e+01, tolerance: 8.720e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.795e+01, tolerance: 9.317e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.748e+01, tolerance: 1.146e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 79}. error: Expected n_neighbors <= n_samples,  but n_samples = 78, n_neighbors = 79
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 81}. error: Expected n_neighbors <= n_samples,  but n_samples = 78, n_neighbors = 81
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 83}. error: Expected n_neighbors <= n_samples,  but n_samples = 78, n_neighbors = 83
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 85}. error: Expected n_neighbors <= n_samples,  but n_samples = 78, n_neighbors = 85
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 87}. error: Expected n_neighbors <= n_samples,  but n_samples = 78, n_neighbors = 87
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 89}. error: Expected n_neighbors <= n_samples,  but n_samples = 78, n_neighbors = 89
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 91}. error: Expected n_neighbors <= n_samples,  but n_samples = 78, n_neighbors = 91
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 93}. error: Expected n_neighbors <= n_samples,  but n_samples = 78, n_neighbors = 93
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 95}. error: Expected n_neighbors <= n_samples,  but n_samples = 78, n_neighbors = 95
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 97}. error: Expected n_neighbors <= n_samples,  but n_samples = 78, n_neighbors = 97
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: Expected n_neighbors <= n_samples,  but n_samples = 78, n_neighbors = 99
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of -0.5 cannot be evaluated. error: 0.0 cannot be raised to a negative power
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:Lambda value of 0 cannot be evaluated. error: test_size=25 should be either positive and smaller than the number of samples 17 or a float in the (0, 1) range
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of 0.5 cannot be evaluated. error: Input contains NaN.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.935e+11, tolerance: 1.711e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.105e+11, tolerance: 1.711e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.979e+11, tolerance: 1.711e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.193e+11, tolerance: 1.711e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.009e+11, tolerance: 1.711e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.251e+11, tolerance: 1.711e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.033e+11, tolerance: 1.711e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.293e+11, tolerance: 1.711e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.053e+11, tolerance: 1.711e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.325e+11, tolerance: 1.711e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.071e+11, tolerance: 1.711e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.349e+11, tolerance: 1.711e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.087e+11, tolerance: 1.711e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.369e+11, tolerance: 1.711e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.102e+11, tolerance: 1.711e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.386e+11, tolerance: 1.711e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.116e+11, tolerance: 1.711e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.400e+11, tolerance: 1.711e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.128e+11, tolerance: 1.711e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.411e+11, tolerance: 1.711e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.140e+11, tolerance: 1.711e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.421e+11, tolerance: 1.711e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.151e+11, tolerance: 1.711e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.430e+11, tolerance: 1.711e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.162e+11, tolerance: 1.711e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.438e+11, tolerance: 1.711e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.172e+11, tolerance: 1.711e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.445e+11, tolerance: 1.711e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.181e+11, tolerance: 1.711e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.451e+11, tolerance: 1.711e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.190e+11, tolerance: 1.711e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.456e+11, tolerance: 1.711e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.198e+11, tolerance: 1.711e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.461e+11, tolerance: 1.711e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.206e+11, tolerance: 1.711e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.466e+11, tolerance: 1.711e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.214e+11, tolerance: 1.711e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.470e+11, tolerance: 1.711e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.221e+11, tolerance: 1.711e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.474e+11, tolerance: 1.711e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of -0.5 cannot be evaluated. error: 0.0 cannot be raised to a negative power
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:Lambda value of 0 cannot be evaluated. error: Input X contains NaN.
ElasticNet does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of 0.5 cannot be evaluated. error: Input contains NaN.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.463e+01, tolerance: 7.336e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.541e+01, tolerance: 7.336e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.489e+01, tolerance: 7.336e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.569e+01, tolerance: 7.336e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.503e+01, tolerance: 7.336e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.586e+01, tolerance: 7.336e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.514e+01, tolerance: 7.336e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.598e+01, tolerance: 7.336e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.522e+01, tolerance: 7.336e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.606e+01, tolerance: 7.336e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.529e+01, tolerance: 7.336e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.613e+01, tolerance: 7.336e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.534e+01, tolerance: 7.336e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.619e+01, tolerance: 7.336e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.539e+01, tolerance: 7.336e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.623e+01, tolerance: 7.336e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.544e+01, tolerance: 7.336e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.627e+01, tolerance: 7.336e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.548e+01, tolerance: 7.336e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.630e+01, tolerance: 7.336e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.552e+01, tolerance: 7.336e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.633e+01, tolerance: 7.336e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.555e+01, tolerance: 7.336e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.635e+01, tolerance: 7.336e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.558e+01, tolerance: 7.336e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.637e+01, tolerance: 7.336e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.561e+01, tolerance: 7.336e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.639e+01, tolerance: 7.336e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.564e+01, tolerance: 7.336e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.640e+01, tolerance: 7.336e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.567e+01, tolerance: 7.336e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.642e+01, tolerance: 7.336e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.569e+01, tolerance: 7.336e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.643e+01, tolerance: 7.336e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.572e+01, tolerance: 7.336e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.644e+01, tolerance: 7.336e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.574e+01, tolerance: 7.336e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.645e+01, tolerance: 7.336e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.576e+01, tolerance: 7.336e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.646e+01, tolerance: 7.336e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.256e+01, tolerance: 9.706e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.222e+01, tolerance: 1.170e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 80}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 80
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 82}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 82
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 84}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 84
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 86}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 86
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 88}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 88
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 90}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 90
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 92}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 92
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 94}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 94
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 96}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 96
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 98}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 98
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: Expected n_neighbors <= n_samples,  but n_samples = 79, n_neighbors = 100
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:Forecaster.typ_set() did not work after the detrend transformation, continuing as is.
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of -0.5 cannot be evaluated. error: 0.0 cannot be raised to a negative power
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:invalid value encountered in log
WARNING:root:Lambda value of 0 cannot be evaluated. error: Input X contains NaN.
ElasticNet does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:invalid value encountered in double_scalars
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Casting complex values to real discards the imaginary part
WARNING:root:Lambda value of 0.5 cannot be evaluated. error: Input contains NaN.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.057e+12, tolerance: 2.884e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.211e+13, tolerance: 2.884e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.610e+12, tolerance: 2.884e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.295e+13, tolerance: 2.884e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.038e+12, tolerance: 2.884e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.333e+13, tolerance: 2.884e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.387e+12, tolerance: 2.884e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.355e+13, tolerance: 2.884e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.682e+12, tolerance: 2.884e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.370e+13, tolerance: 2.884e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.936e+12, tolerance: 2.884e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.380e+13, tolerance: 2.884e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.016e+13, tolerance: 2.884e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.388e+13, tolerance: 2.884e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.036e+13, tolerance: 2.884e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.394e+13, tolerance: 2.884e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.053e+13, tolerance: 2.884e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.399e+13, tolerance: 2.884e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+13, tolerance: 2.884e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.403e+13, tolerance: 2.884e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.084e+13, tolerance: 2.884e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.406e+13, tolerance: 2.884e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.097e+13, tolerance: 2.884e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.409e+13, tolerance: 2.884e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.109e+13, tolerance: 2.884e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.411e+13, tolerance: 2.884e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.121e+13, tolerance: 2.884e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.413e+13, tolerance: 2.884e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.131e+13, tolerance: 2.884e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.415e+13, tolerance: 2.884e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.141e+13, tolerance: 2.884e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.417e+13, tolerance: 2.884e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.150e+13, tolerance: 2.884e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.418e+13, tolerance: 2.884e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.159e+13, tolerance: 2.884e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.419e+13, tolerance: 2.884e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.167e+13, tolerance: 2.884e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.420e+13, tolerance: 2.884e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.174e+13, tolerance: 2.884e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.421e+13, tolerance: 2.884e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.273e+13, tolerance: 5.635e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.747e+13, tolerance: 7.456e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 60}. error: Expected n_neighbors <= n_samples,  but n_samples = 59, n_neighbors = 60
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 62}. error: Expected n_neighbors <= n_samples,  but n_samples = 59, n_neighbors = 62
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 64}. error: Expected n_neighbors <= n_samples,  but n_samples = 59, n_neighbors = 64
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 66}. error: Expected n_neighbors <= n_samples,  but n_samples = 59, n_neighbors = 66
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 68}. error: Expected n_neighbors <= n_samples,  but n_samples = 59, n_neighbors = 68
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 70}. error: Expected n_neighbors <= n_samples,  but n_samples = 59, n_neighbors = 70
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 72}. error: Expected n_neighbors <= n_samples,  but n_samples = 59, n_neighbors = 72
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 74}. error: Expected n_neighbors <= n_samples,  but n_samples = 59, n_neighbors = 74
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 76}. error: Expected n_neighbors <= n_samples,  but n_samples = 59, n_neighbors = 76
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 78}. error: Expected n_neighbors <= n_samples,  but n_samples = 59, n_neighbors = 78
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 80}. error: Expected n_neighbors <= n_samples,  but n_samples = 59, n_neighbors = 80
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 82}. error: Expected n_neighbors <= n_samples,  but n_samples = 59, n_neighbors = 82
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 84}. error: Expected n_neighbors <= n_samples,  but n_samples = 59, n_neighbors = 84
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 86}. error: Expected n_neighbors <= n_samples,  but n_samples = 59, n_neighbors = 86
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 88}. error: Expected n_neighbors <= n_samples,  but n_samples = 59, n_neighbors = 88
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 90}. error: Expected n_neighbors <= n_samples,  but n_samples = 59, n_neighbors = 90
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 92}. error: Expected n_neighbors <= n_samples,  but n_samples = 59, n_neighbors = 92
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 94}. error: Expected n_neighbors <= n_samples,  but n_samples = 59, n_neighbors = 94
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 96}. error: Expected n_neighbors <= n_samples,  but n_samples = 59, n_neighbors = 96
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 98}. error: Expected n_neighbors <= n_samples,  but n_samples = 59, n_neighbors = 98
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: Expected n_neighbors <= n_samples,  but n_samples = 59, n_neighbors = 100
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 100}. error: list index out of range
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.442e+05, tolerance: 1.712e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.063e+05, tolerance: 1.712e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.625e+05, tolerance: 1.712e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.263e+05, tolerance: 1.712e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.774e+05, tolerance: 1.712e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.347e+05, tolerance: 1.712e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.898e+05, tolerance: 1.712e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.393e+05, tolerance: 1.712e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.003e+05, tolerance: 1.712e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.423e+05, tolerance: 1.712e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.094e+05, tolerance: 1.712e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.443e+05, tolerance: 1.712e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.175e+05, tolerance: 1.712e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.459e+05, tolerance: 1.712e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.246e+05, tolerance: 1.712e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.470e+05, tolerance: 1.712e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.309e+05, tolerance: 1.712e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.479e+05, tolerance: 1.712e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.366e+05, tolerance: 1.712e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.487e+05, tolerance: 1.712e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.418e+05, tolerance: 1.712e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.493e+05, tolerance: 1.712e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.465e+05, tolerance: 1.712e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.498e+05, tolerance: 1.712e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.508e+05, tolerance: 1.712e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.502e+05, tolerance: 1.712e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.548e+05, tolerance: 1.712e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.506e+05, tolerance: 1.712e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.584e+05, tolerance: 1.712e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.509e+05, tolerance: 1.712e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.618e+05, tolerance: 1.712e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.512e+05, tolerance: 1.712e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.650e+05, tolerance: 1.712e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.515e+05, tolerance: 1.712e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.679e+05, tolerance: 1.712e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.517e+05, tolerance: 1.712e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.706e+05, tolerance: 1.712e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.519e+05, tolerance: 1.712e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.732e+05, tolerance: 1.712e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.521e+05, tolerance: 1.712e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 67}. error: Expected n_neighbors <= n_samples,  but n_samples = 66, n_neighbors = 67
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 69}. error: Expected n_neighbors <= n_samples,  but n_samples = 66, n_neighbors = 69
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 71}. error: Expected n_neighbors <= n_samples,  but n_samples = 66, n_neighbors = 71
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 73}. error: Expected n_neighbors <= n_samples,  but n_samples = 66, n_neighbors = 73
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 75}. error: Expected n_neighbors <= n_samples,  but n_samples = 66, n_neighbors = 75
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 77}. error: Expected n_neighbors <= n_samples,  but n_samples = 66, n_neighbors = 77
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 79}. error: Expected n_neighbors <= n_samples,  but n_samples = 66, n_neighbors = 79
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 81}. error: Expected n_neighbors <= n_samples,  but n_samples = 66, n_neighbors = 81
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 83}. error: Expected n_neighbors <= n_samples,  but n_samples = 66, n_neighbors = 83
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 85}. error: Expected n_neighbors <= n_samples,  but n_samples = 66, n_neighbors = 85
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 87}. error: Expected n_neighbors <= n_samples,  but n_samples = 66, n_neighbors = 87
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 89}. error: Expected n_neighbors <= n_samples,  but n_samples = 66, n_neighbors = 89
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 91}. error: Expected n_neighbors <= n_samples,  but n_samples = 66, n_neighbors = 91
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 93}. error: Expected n_neighbors <= n_samples,  but n_samples = 66, n_neighbors = 93
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 95}. error: Expected n_neighbors <= n_samples,  but n_samples = 66, n_neighbors = 95
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 97}. error: Expected n_neighbors <= n_samples,  but n_samples = 66, n_neighbors = 97
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: Expected n_neighbors <= n_samples,  but n_samples = 66, n_neighbors = 99
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
WARNING:root:Could not evaluate the paramaters: {'n_neighbors': 99}. error: list index out of range
